training...
iteration = 0, record = 0, loss error = 9.51155
testing...
record 0, ans = 8, expect = 1, sample error = 1
Convolution Layer 0:
strides = 2
padding = 0
Activation function = Relu
pooling height = 2
pooling width = 2
learning rate = 0.5
Kernel 0:
-0.562743 -0.0296546 -0.405163 
0.424472 0.0984809 -0.831806 
-0.156042 -0.603809 -0.214776 
bias = 0.256563
Kernel 1:
0.0913134 0.703529 0.215114 
-0.575044 -0.760162 -0.042303 
-0.986445 0.819974 -0.69436 
bias = -0.106735
Kernel 2:
0.112197 -0.311343 -0.736603 
-0.09412 0.125441 0.280492 
0.221952 0.354234 -0.38889 
bias = -0.0697182
Kernel 3:
0.245535 0.703769 0.243847 
0.342932 -0.342088 0.534206 
0.407754 -0.873435 0.180461 
bias = -0.989621
Kernel 4:
-0.552749 -0.0574566 0.326814 
0.755231 -0.829133 0.758395 
0.347054 0.944556 -0.847345 
bias = 0.679406
Kernel 5:
0.81958 0.681323 0.994003 
0.211438 -0.369504 -0.254021 
0.66098 -0.908169 0.395487 
bias = 0.951086
Convolution Layer 1:
strides = 1
padding = 0
Activation function = Relu
pooling height = 2
pooling width = 2
learning rate = 0.5
Kernel 0:
0.939908 -0.382548 0.718565 
0.866653 0.523361 -0.218899 
0.802078 0.107494 0.712235 
bias = -0.437539
Kernel 1:
-0.811564 -0.122667 -0.280545 
-0.272744 -0.810401 0.209741 
0.968739 -0.832082 -0.790116 
bias = 0.33524
Kernel 2:
0.213453 0.498375 0.636435 
-0.0187017 0.24236 -0.0741099 
-0.519718 0.0203748 0.346371 
bias = 0.706404
Kernel 3:
0.787761 0.212552 0.563648 
-0.0494199 -0.294301 0.882422 
0.808997 0.582293 0.821183 
bias = 0.366119
Kernel 4:
-0.870122 -0.132527 0.623581 
0.529897 -0.0218809 0.247776 
0.367467 0.0108854 0.951517 
bias = 0.139833
Kernel 5:
0.915201 -0.214369 -0.891918 
-0.467435 -0.173208 0.886605 
-0.824724 0.869917 0.696516 
bias = 0.34129
Kernel 6:
0.0654998 0.854463 0.951983 
-0.0190402 -0.00874208 -0.928163 
0.359663 0.862694 -0.702712 
bias = -0.477911
Kernel 7:
-0.248469 -0.0204765 -0.148239 
0.548844 0.415991 -0.431208 
0.685559 0.186962 0.278171 
bias = -0.775891
Kernel 8:
-0.396473 0.474462 0.278223 
0.0991129 -0.208683 0.660694 
0.280273 0.54179 -0.133733 
bias = 0.342876
Kernel 9:
0.712098 -0.762983 0.399412 
0.640366 0.500312 0.823842 
-0.369543 -0.242668 0.0412406 
bias = 0.639582
Kernel 10:
0.304706 0.396091 -0.861061 
0.435975 0.867209 -0.837549 
-0.200292 -0.413711 0.558364 
bias = -0.991509
Kernel 11:
-0.75226 -0.853075 -0.93034 
0.711006 0.513215 -0.0832474 
-0.302654 0.137973 -0.243747 
bias = 0.167973
Kernel 12:
-0.0975023 0.0997508 -0.649727 
-0.384597 0.989522 0.977759 
0.039333 0.694973 -0.583531 
bias = -1.00271
Kernel 13:
0.0653296 0.214449 -0.915591 
0.651569 -0.567626 -0.127999 
0.219176 -0.805036 -0.729459 
bias = -0.518348
Kernel 14:
-0.013145 0.478475 0.482627 
-0.487161 0.65508 0.952401 
-0.996564 0.0736662 0.236276 
bias = 0.42576
Kernel 15:
-0.876301 0.0137759 -0.468347 
0.49628 0.984132 0.313212 
0.149302 -0.68561 0.956254 
bias = -0.24726
NN:
eps: 0
N: 10
Loss function: Scaled Corss-Entropy Error
Layer 1: 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.361151 0.131931 -0.63501 -0.616187 -0.261428 0.172669 0.0445737 -0.850363 -0.0482212 -0.454182 0.556824 0.539424 0.10241 -0.800384 -0.0498158 0.746185 -0.871132 0.88037 0.380568 0.200494 -0.29862 -0.909958 0.329378 -0.14043 -0.200987 0.00759941 -0.276667 0.060448 -0.0498261 0.57269 -0.80082 0.621588 -0.975557 -0.183625 -0.185863 0.204989 -0.743665 -0.783154 -0.473104 0.533546 -0.698803 -0.779345 -0.444372 -0.564836 0.805294 0.582041 0.371051 0.258229 0.055416 -0.624092 0.878847 0.782627 -0.38932 0.705917 0.344056 0.542957 -0.519929 -0.438578 0.812197 0.589871 -0.0350925 0.200265 -0.137924 -0.0873099 0.582522 0.450854 -0.496972 -0.610846 -0.483597 0.184941 0.305327 -0.374343 0.420047 -0.273894 0.664254 0.121835 -0.32555 0.478147 0.214482 0.794618 -0.854739 0.405509 -0.618433 -0.00112015 -0.826292 0.508311 -0.824514 0.400909 0.0742412 -0.227916 -0.589081 -0.682103 -0.107758 0.912279 0.670109 0.514072 0.0147534 -0.0390133 0.304209 0.833433 -0.487651 0.05156 0.569187 0.33186 -0.424128 -0.32572 -0.369509 -0.335885 0.775716 -0.53984 0.915107 0.205785 0.627092 -0.468984 -0.206139 -0.573473 -0.363994 0.349599 -0.292961 0.210215 -0.911861 0.358096 0.524285 -0.345737 -0.804117 -0.800737 0.0192364 -0.694275 -0.673977 0.471996 0.843781 -0.574252 0.538499 0.545763 0.644293 0.62794 -0.211342 -0.0298156 0.888604 0.761937 -0.132249 -0.709023 -0.542464 0.812906 0.509651 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.300692 0.262918 0.855199 -0.667249 -0.445843 0.718598 -0.52497 0.835543 0.968322 0.587016 -0.0163554 -0.885184 0.712399 -0.706795 0.890309 -0.574033 0.227599 -0.750115 0.813805 -0.376675 -0.784178 0.323925 0.215259 -0.134203 0.455977 -0.388049 0.0647986 -0.930625 0.982917 -0.114097 0.366905 0.575931 -0.324375 0.232795 0.587063 0.766845 0.364351 -0.351798 -0.670794 -0.0267085 -0.890339 0.0764324 0.599831 -0.63627 0.210807 -0.964279 -0.640889 0.579376 -0.433958 0.46872 -0.230301 -0.674038 -0.557735 0.153919 0.922296 -0.976659 -0.705197 -0.253771 0.873695 0.20013 -0.416524 -0.525101 0.626597 -0.783155 -0.481541 0.73581 0.75866 0.795813 -0.767454 -0.602839 0.0911981 0.765877 0.0895258 0.659287 0.640176 -0.554942 -0.901796 -0.486108 -0.0209622 -0.310892 0.84502 0.244312 0.158 -0.49451 0.762316 0.248887 -0.951914 -0.810276 -0.305832 -0.116532 -0.55563 -0.473787 -0.944279 -0.494307 0.190548 0.535454 -0.619 0.458911 0.923775 -0.11039 0.679878 0.711331 -0.663852 0.64306 -0.0934369 -0.394591 0.117349 0.287918 -0.955456 -0.356502 0.271482 0.794026 -0.805858 -0.0505865 -0.207129 0.777241 -0.90992 0.968323 0.604594 -0.582483 0.20437 0.840595 -0.11158 0.672642 -0.911825 0.957753 0.949612 0.134049 0.968991 -0.175006 0.672093 -0.13578 -0.0593703 0.162612 -0.986532 -0.645075 0.220926 -0.889418 -0.440599 0.858417 -0.582529 -0.564008 0.723631 0.0690974 -0.68001 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.93366 -0.0172426 0.203282 0.553877 -0.993542 -0.454144 -0.794871 0.603643 -0.575121 -0.0580557 0.257062 0.449344 0.116696 -0.681943 0.577642 0.421222 -0.520529 -0.535362 0.174789 -0.325082 0.347013 0.252815 -0.946287 -0.252599 0.56902 -0.483723 0.0673604 0.125989 -0.506369 -0.546148 0.894679 0.877209 -0.739975 -0.751993 -0.75038 0.357627 0.637512 0.657471 0.111811 -0.794378 0.884286 0.192397 -0.380539 0.277243 -0.371716 0.570036 0.591975 -0.681864 -0.0923609 -0.310136 -0.463286 -0.449243 -0.42642 -0.838876 -0.984996 -0.83493 -0.673672 -0.411249 0.145064 0.0957135 0.656348 -0.758692 0.656967 -0.354693 0.678711 -0.908422 0.148883 0.284166 -0.0188529 -0.86118 0.150245 -0.825488 0.0208501 0.428227 -0.786109 -0.126988 -0.281835 -0.795518 -0.270424 0.980504 -0.671188 -0.657334 0.190942 -0.842216 0.869664 0.435919 0.484803 0.08415 0.309145 -0.204392 0.789515 -0.627363 -0.0913792 0.18929 -0.602927 0.601323 0.443299 0.526761 -0.731727 -0.127741 -0.939406 -0.597206 0.7532 -0.960556 -0.0587203 -0.911464 -0.972773 0.608922 0.151097 -0.515301 -0.658117 -0.975563 -0.283192 0.390397 -0.60592 0.309356 -0.647949 -0.0718729 0.0319381 0.784269 -0.78822 0.392606 0.521734 0.790209 -0.959092 0.544661 0.119308 -0.790444 -0.986557 0.942522 0.968718 -0.756265 -0.55065 -0.778391 -0.417893 0.466986 0.626241 -0.775712 0.612531 0.807869 -0.143552 -0.684666 0.811085 -0.100939 -0.476131 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.340516 0.955419 -0.279422 -0.24292 -0.748876 -0.351962 0.581478 0.897403 0.659513 0.436216 -0.518483 -0.141161 -0.495321 -0.862266 -0.0988285 0.989311 -0.644336 0.652316 -0.529807 -0.458035 -0.189336 -0.168158 -0.230362 0.297937 -0.572358 0.372428 -0.607133 -0.0843619 0.129842 0.247711 -0.722324 -0.0999623 -0.0671778 0.943012 -0.79154 0.594772 0.333453 0.3362 0.519464 0.639617 0.0449942 0.217772 0.0959311 0.313188 -0.253334 0.221341 0.0848479 0.0393226 0.895553 -0.442369 -0.892336 0.509589 0.655677 -0.0380558 0.396695 -0.74504 0.108583 0.949019 0.169547 -0.416722 0.151196 -0.841272 0.748615 -0.0195665 -0.854574 -0.82859 -0.111801 0.964586 -0.200469 0.71215 -0.896392 0.344636 0.2961 0.556278 -0.642112 0.0200984 -0.206538 0.713318 0.730546 0.28359 0.30068 -0.477485 0.904801 0.991735 0.0938261 0.934821 -0.460083 -0.610741 -0.7234 -0.177279 0.47592 0.792228 0.968344 0.960866 -0.719291 0.869847 -0.488099 0.518601 0.132722 0.653194 0.237394 -0.119401 -0.775942 0.750562 0.697083 -0.123421 -0.344165 -0.37882 -0.825187 -0.92427 -0.208243 0.0681801 -0.0970812 0.355931 0.125829 0.812207 0.766105 -0.0671791 0.920911 -0.254253 0.765342 -0.89452 -0.198478 0.178722 -0.214379 0.931034 -0.115278 0.523193 -0.696679 0.914832 -0.424796 0.453208 -0.936335 -0.977793 0.231771 -0.632014 -0.256209 -0.106802 0.981552 0.950555 -0.0150797 0.555922 -0.626279 0.12268 -0.125574 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.515953 0.376545 0.586377 -0.765592 0.698162 0.00415591 -0.151587 0.269344 0.866076 0.140834 -0.999604 -0.344941 0.579694 0.918465 0.63588 -0.772873 0.316584 0.824863 -0.534388 0.547146 -0.112251 -0.610431 0.478992 0.410482 0.979322 -0.54018 -0.797 0.824957 -0.939734 -0.102368 -0.505433 -0.811451 -0.0653168 0.220534 0.508054 0.861341 0.562875 0.241277 -0.857437 -0.938894 0.00769884 -0.605643 0.95667 0.753726 -0.120343 -0.602425 -0.964621 -0.38546 -0.420197 -0.25166 0.354587 -0.448096 0.845279 0.599875 0.0940086 0.00181879 0.568335 0.00292082 -0.909701 0.647718 0.201859 0.63643 0.473591 -0.363614 0.73277 -0.336027 0.399787 -0.781564 0.251395 -0.801264 -0.850842 -0.098769 -0.0107291 -0.32422 0.833122 0.280249 0.146355 -0.212017 0.628367 0.956782 0.641118 -0.73043 -0.334136 0.183893 0.69598 -0.660741 0.933897 0.011978 -0.685458 -0.485322 -0.806122 -0.492536 -0.0572434 -0.0906346 0.703905 0.529523 -0.309116 0.681049 0.387934 0.0139061 -0.280986 -0.533463 0.0932114 0.603982 -0.866583 -0.65846 -0.732139 0.938268 -0.52587 -0.289354 0.826619 0.987976 0.919295 0.593552 -0.176894 0.937872 0.808537 -0.918911 -0.136609 0.00901931 -0.412533 0.557903 0.67619 0.72035 0.928428 0.0967026 -0.719974 -0.604409 -0.302371 0.0445206 0.257008 -0.45911 -0.2636 -0.325322 0.304928 0.931372 -0.427041 0.713767 0.273914 -0.334686 0.934424 0.865668 -0.721092 0.613886 -0.423282 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0964724 0.587719 -0.209917 -0.0810318 0.0987752 0.115117 0.775238 -0.569334 -0.804789 -0.0969424 0.689644 0.852725 -0.259189 -0.185657 -0.335724 -0.515155 -0.208323 0.719806 -0.216449 0.137391 -0.870799 0.475942 -0.83627 0.804072 0.0343003 0.485171 0.265072 -0.933442 -0.367556 0.483102 -0.505013 0.239778 -0.0427869 0.880408 -0.986389 -0.233974 -0.406529 -0.535388 -0.259856 0.592316 -0.95016 0.659088 -0.707584 -0.369971 -0.100786 0.085361 0.662166 -0.97868 -0.677745 -0.853787 0.403218 0.880479 0.214662 -0.18193 0.297426 0.831158 -0.734069 0.506968 0.610733 0.596268 -0.522552 -0.528774 0.895029 0.760651 0.266111 0.526546 -0.348307 -0.00271732 0.329997 0.259532 -0.0527422 -0.438476 0.530038 0.345142 0.799497 -0.847678 -0.925915 0.140334 0.593514 -0.816982 0.988331 0.871656 -0.0786005 0.962112 0.213006 -0.00351472 0.928169 -0.259658 -0.0728371 -0.172481 -0.890703 -0.0517712 -0.119041 -0.715655 -0.0154916 -0.366518 -0.0629676 -0.296013 0.91544 -0.202979 0.538319 -0.470754 0.0346087 -0.331394 0.26831 -0.506131 -0.550583 0.355509 -0.960072 0.0772758 0.774654 -0.392821 -0.142635 0.725956 -0.865643 -0.862796 0.987234 0.447052 -0.393313 -0.41924 -0.168064 -0.650813 -0.219509 0.716188 0.976653 0.60779 -0.86554 0.862464 -0.559672 -0.404512 -0.640932 -0.14389 -0.367111 -0.0415258 0.0764071 0.174484 0.54802 0.572756 0.318351 0.525292 0.585517 0.78524 -0.470913 -0.631366 0.636453 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.891632 0.91293 -0.382335 0.0982782 -0.238139 -0.399878 -0.75303 -0.180894 -0.290312 0.732974 -0.901114 0.493494 -0.184105 -0.626785 -0.719484 -0.729369 -0.875317 0.209419 -0.641824 0.45955 -0.0268652 0.720325 0.844978 -0.156227 0.52004 0.640277 -0.661742 0.292116 -0.0547286 0.818325 0.0887213 -0.137376 -0.385052 0.866045 0.316664 0.857431 -0.389421 -0.17952 0.203136 -0.560833 -0.402424 -0.260231 -0.374351 -0.101474 0.0479302 -0.8744 -0.322897 0.0658088 -0.961985 -0.838686 -0.750063 0.832823 0.470967 0.80317 0.0918985 -0.356957 0.622865 0.492127 -0.819975 0.679286 0.764955 0.591953 0.951189 0.626904 0.378727 -0.733371 0.226064 -0.54683 -0.572752 -0.236112 -0.326214 -0.684791 0.710346 0.789102 -0.545442 -0.291572 0.63915 -0.866233 0.135339 -0.25839 0.26543 0.183783 0.036869 -0.0441396 0.38004 -0.295142 -0.206212 0.438284 0.562469 -0.430474 -0.672738 -0.304046 -0.0979763 -0.687713 -0.390557 -0.0923777 -0.592574 0.601015 -0.73411 -0.192381 0.657075 -0.784097 -0.58102 0.456439 -0.859934 0.947849 0.272747 -0.0416846 -0.636097 -0.981358 0.321822 0.858134 0.652605 0.336739 -0.419838 -0.22152 0.904974 -0.103398 0.185424 0.428628 -0.0425175 -0.591834 -0.955965 -0.909346 0.619692 -0.836597 -0.677627 -0.87397 -0.0608908 -0.70837 -0.565193 -0.447015 -0.224657 -0.856734 -0.472949 -0.0327413 0.656305 0.514786 0.00409373 0.803248 0.186964 0.308929 0.167617 -0.867557 0.96948 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.0145989 0.608715 0.676658 0.599031 -0.0848525 -0.115129 -0.970569 -0.350782 0.407158 -0.89305 0.50559 0.363865 0.119614 -0.919987 0.455987 0.449815 0.763434 -0.313659 0.983295 -0.988317 0.575112 -0.733556 0.289748 -0.935606 0.677697 -0.73394 0.119771 0.459898 0.688349 -0.317308 -0.128386 0.671618 0.782864 0.609982 0.474291 -0.081022 0.619108 -0.403356 -0.0420356 0.788296 -0.181598 -0.72898 -0.685837 -0.122993 -0.210332 -0.207937 -0.258787 0.488522 0.519376 0.598748 0.996096 -0.974836 -0.554041 -0.338674 -0.592878 -0.78702 0.557402 0.263641 -0.985049 0.278812 -0.0128017 0.842066 0.604125 -0.466251 -0.281912 -0.0910325 0.0164289 0.12031 0.0551744 -0.683677 -0.56109 -0.231628 -0.964649 -0.856844 0.900233 0.218155 0.278123 0.439812 -0.00118862 -0.238846 -0.423884 -0.510648 -0.899281 -0.958379 -0.0861485 -0.761763 0.407451 -0.609578 0.0465387 -0.29512 -0.821393 -0.0928525 -0.572388 -0.117002 -0.454252 -0.618791 -0.0148084 -0.884248 0.446 -0.0820819 0.448861 0.462947 -0.746518 -0.091172 0.111193 -0.912709 0.517949 -0.637197 0.713693 -0.780111 0.682158 -0.967948 -0.299499 0.318443 0.0665078 -0.204015 -0.881081 -0.335034 -0.910371 -0.60682 -0.820549 -0.973836 0.741681 -0.568496 -0.708027 0.188608 -0.0712818 -0.0335994 -0.304519 0.473134 -0.137676 0.466349 0.326194 0.347508 -0.876634 0.673642 -0.0609659 -0.653441 -0.380768 0.435905 0.251108 0.365796 -0.065776 0.502669 0.359806 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.748667 -0.843619 -0.711156 -0.393606 0.671451 -0.928735 0.753891 0.643039 -0.450961 0.696172 0.555021 0.232592 -0.828396 -0.850052 -0.820676 0.89603 -0.424269 -0.691459 0.650967 0.798532 0.931139 -0.35483 0.370182 -0.346715 0.758206 -0.827947 0.694662 -0.814453 -0.50611 -0.193293 -0.681387 -0.0659027 0.373098 0.664576 -0.468047 -0.461816 0.25801 0.373876 -0.262711 0.624076 0.84327 0.836667 -0.13325 0.462499 -0.777587 -0.907827 0.153785 0.667941 0.0896177 0.204166 -0.589671 -0.597972 -0.117655 0.569954 -0.791336 0.0140815 0.666941 -0.720954 0.927501 0.514574 0.437664 -0.177582 -0.624728 0.195712 -0.665869 0.744988 -0.979861 -0.524822 -0.687646 0.732136 -0.996669 0.990894 -0.0375602 0.726096 -0.497102 -0.792744 0.359522 0.488377 0.152348 0.513074 -0.773591 0.251641 -0.672432 0.435444 0.511376 0.700968 -0.837054 -0.372294 0.855712 -0.0568023 -0.675932 -0.395608 -0.98823 0.825868 0.361773 0.321062 0.0833077 0.151775 0.881427 0.142826 0.472196 0.204314 -0.0895528 0.885375 0.491309 -0.562704 0.637121 0.0882356 0.975502 -0.74488 0.805753 0.290796 -0.590686 0.343642 -0.406843 0.187276 -0.453477 0.412349 0.348584 0.645367 0.675156 -0.648774 0.0629 -0.839687 -0.626953 0.803464 -0.176263 -0.448601 0.359945 -0.406955 0.314895 0.446088 -0.604933 0.891022 -0.588512 0.879419 0.397243 0.468036 0.28818 -0.555378 -0.233554 0.650884 -0.598005 -0.671778 -0.568523 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.891636 0.667441 -0.319002 0.530736 0.0745841 -0.46511 0.893538 -0.304001 0.661182 0.477737 -0.674232 0.970469 -0.170489 -0.357858 0.593716 -0.314788 0.408477 0.426845 -0.879464 -0.155233 0.778893 0.442804 0.0515962 0.877332 0.854403 -0.257026 -0.359785 0.555421 0.792331 -0.709938 0.31471 0.118695 -0.906411 -0.0117764 0.780024 0.568155 -0.104727 0.895918 0.164692 0.300576 0.560186 -0.778667 -0.734765 -0.154037 -0.119819 -0.891249 0.0612796 -0.595877 0.547297 0.521092 -0.414015 -0.516692 -0.0418331 -0.954451 0.571883 -0.60528 -0.94626 0.215277 0.161071 -0.886352 -0.910453 0.0169758 -0.688292 -0.124901 0.785183 0.574943 -0.929269 -0.230797 0.999175 -0.872052 -0.572577 0.700937 0.648769 -0.141753 -0.90259 -0.453032 -0.417737 0.42393 0.27471 0.771844 -0.0533642 0.867305 0.764075 -0.464773 0.120363 0.82457 0.149959 -0.0387355 0.738488 -0.869809 0.850125 0.0359757 0.643571 0.494579 0.388019 -0.56171 -0.66662 0.123966 -0.500079 -0.824343 -0.732554 -0.632359 -0.711348 -0.474428 -0.288173 0.321778 -0.432482 -0.980955 0.974281 0.504207 0.198892 0.783475 -0.136969 -0.0373049 -0.983065 -0.378601 0.847571 -0.87105 0.257357 -0.597911 0.912092 -0.477109 -0.776674 0.446539 0.983436 0.615028 0.775835 -0.538982 0.183163 -0.894343 0.277802 -0.114362 0.768737 -0.463941 -0.818516 0.248574 -0.878586 -0.386712 0.534164 -0.308546 0.262043 0.158953 -0.484295 0.458614 -0.0780261 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.659268 0.340885 -0.753381 -0.074213 0.702914 -0.119481 -0.119682 0.501565 -0.203106 0.400828 0.717837 -0.357314 -0.103475 0.0770771 0.6747 0.906153 0.89727 -0.318611 0.361746 0.988478 -0.275636 -0.411961 0.598781 0.0135924 0.598817 0.694583 -0.035144 -0.57514 0.0300773 0.567701 0.106788 0.013849 -0.51643 0.952687 0.981797 0.235444 0.439147 0.192059 0.627562 -0.004168 0.900792 0.046063 0.735327 -0.191357 0.812105 0.0982263 0.279426 0.133969 -0.580327 0.807438 0.546482 0.856492 -0.656786 -0.207471 -0.660762 0.628531 -0.285049 -0.811585 -0.302782 -0.854643 0.0137022 0.292426 0.802906 0.437416 -0.348677 -0.21507 -0.683173 -0.0882778 0.314741 -0.154051 0.858788 -0.35396 0.995459 0.685794 0.0248226 0.929399 0.421161 0.158443 0.61513 0.522808 0.73965 -0.626682 -0.39144 -0.611218 -0.56818 -0.93635 0.977953 0.659982 0.672241 0.363435 0.571523 0.129078 -0.578033 0.991996 0.476499 0.517728 -0.546917 -0.0406654 0.536344 0.339555 0.896495 0.887331 0.804099 -0.233692 -0.157904 -0.194763 0.134153 0.485637 0.00681918 0.40506 -0.161315 0.772499 -0.612507 -0.398534 -0.167052 0.354228 -0.491885 0.89299 0.479495 0.868033 -0.972997 0.84004 0.550763 0.674532 0.867053 0.568055 -0.706879 -0.508916 -0.0565344 0.973697 0.771857 -0.0991521 0.845107 -0.549563 0.597242 -0.699153 -0.962768 0.750514 -0.11304 0.137052 -0.562276 -0.171276 -0.627466 0.172435 0.109444 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.576392 0.573358 0.424886 -0.941216 0.984702 -0.118801 -0.695484 -0.999856 -0.580666 0.750298 0.250829 -0.319319 -0.794968 0.977433 -0.285968 -0.265533 -0.819249 0.876151 -0.536794 0.105432 -0.00641767 0.138239 -0.618605 -0.898035 0.724502 0.709511 0.746455 -0.326485 0.76934 0.301481 0.9937 -0.888131 -0.813805 0.3853 -0.26118 0.35314 -0.782814 -0.756302 0.837046 0.231216 0.0441194 -0.484736 -0.951346 0.733387 0.0299368 -0.85212 0.422841 0.681927 -0.85745 0.839776 0.11905 0.875845 0.330939 0.0962524 -0.286132 0.975828 0.741186 -0.887817 0.464706 0.309589 -0.740415 -0.148084 -0.854007 0.704836 0.172541 -0.102763 0.863629 -0.991683 0.791822 0.144361 0.269553 0.37697 -0.27048 0.036722 -0.81306 0.896863 -0.428467 0.756624 0.581384 -0.674351 0.188596 -0.26943 -0.307177 -0.719916 0.369207 -0.738451 0.857812 -0.74928 0.850758 0.697098 0.119024 0.433436 0.762851 -0.761401 -0.86079 0.709432 -0.583699 -0.225882 -0.400009 -0.95764 0.939564 -0.753521 -0.422687 -0.104249 -0.119723 -0.182069 -0.0289001 0.275934 -0.371249 0.424455 -0.188449 0.729806 -0.158365 0.365055 -0.527234 0.774876 -0.658406 0.165279 -0.149717 -0.285995 -0.713327 -0.885336 0.162036 -0.662742 -0.704824 0.0247774 0.433478 -0.542246 0.478809 -0.664232 0.254645 -0.180689 -0.839728 0.691464 -0.55943 -0.332562 0.62871 0.726773 0.875427 -0.706642 -0.524375 0.829675 0.356101 0.982564 -0.0535915 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.712819 -0.347925 0.421307 0.914185 0.708885 0.231243 0.499802 0.171441 -0.587066 -0.821332 -0.130432 -0.172455 -0.451425 0.901202 0.496484 0.398949 -0.85599 -0.625307 0.457251 -0.977184 0.464107 0.239885 -0.257076 -0.668623 0.457555 0.132026 0.962962 0.50632 -0.277953 0.439305 -0.606426 -0.201617 -0.572572 0.785978 -0.0616252 0.265532 0.789587 0.595632 0.792623 -0.389432 0.818588 0.0064449 0.31951 0.000758144 0.74212 0.804414 -0.219329 -0.261565 -0.128002 0.67022 0.386703 -0.675602 -0.842361 0.438574 -0.884137 0.31478 0.510971 -0.112278 0.941478 -0.585531 0.983366 -0.575331 0.40441 0.913746 -0.667499 -0.660233 -0.538788 0.587503 0.160604 -0.730283 0.130607 -0.883562 -0.0311116 -0.891994 0.254441 0.39061 0.981438 -0.977768 0.652375 0.471797 -0.514984 0.668588 0.958425 0.255147 0.256685 0.103536 0.121163 0.388293 0.0430748 -0.0412854 0.116175 0.560741 0.369599 -0.154048 0.914355 -0.435664 -0.206753 -0.898395 0.672074 -0.460496 0.4378 0.0977937 -0.380506 0.842245 -0.395714 -0.770544 -0.537702 0.850539 -0.990782 -0.0652027 0.138354 -0.683113 0.923124 0.943102 0.721736 0.215336 -0.843869 -0.908891 0.261422 -0.287951 0.403807 0.783967 0.131778 0.792775 0.174361 0.493379 0.220311 0.764326 0.0234586 0.268214 -0.132028 -0.999918 0.372244 0.309622 -0.185228 0.879531 0.276339 0.427894 -0.385171 0.423997 0.114614 0.313603 0.720259 -0.610987 -0.860074 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.623472 0.749242 0.513099 -0.351593 0.769178 -0.433459 0.850558 -0.679182 0.980294 -0.191348 0.0130816 0.517803 0.584022 -0.24403 0.535056 0.663109 0.953956 -0.986977 -0.244646 0.457545 -0.762602 0.652772 0.27571 -0.684646 0.988414 -0.469561 0.0205763 -0.190499 -0.563463 -0.616462 -0.601737 -0.339675 -0.548545 -0.695498 0.00866533 0.874328 -0.370166 -0.871826 0.576529 -0.582056 0.0655131 -0.915808 -0.293634 -0.988292 0.462515 -0.088383 0.106605 -0.745735 0.0260235 -0.432577 0.959489 0.881092 0.895794 -0.28694 -0.257438 0.192531 -0.132149 0.979172 0.947666 -0.585465 0.0950074 0.789021 -0.926836 0.661184 0.525368 -0.135325 -0.41559 -0.825843 0.0634961 -0.82073 -0.00131022 -0.0209065 0.62472 -0.33888 -0.162185 -0.0536301 -0.302695 0.45685 0.244279 0.60921 0.357563 0.49084 0.0222636 -0.406596 0.108941 0.0126713 0.62974 -0.270694 -0.240882 -0.33219 0.265771 -0.354098 0.667913 -0.38945 0.513078 -0.702653 0.510153 0.134208 -0.35976 -0.486384 -0.653045 -0.424739 0.85739 -0.00174138 -0.000439425 -0.613175 -0.405645 0.881654 0.187447 0.938033 -0.476386 -0.618675 -0.0718652 0.160885 0.000866607 0.565069 -0.887821 0.394738 0.361763 0.148005 -0.480264 0.206891 -0.79029 -0.406328 0.846668 -0.0462394 0.853828 0.282837 0.561561 -0.560968 -0.698109 -0.217909 0.51665 -0.888994 0.0746908 -0.164734 -0.812979 0.256773 -0.422399 0.737409 -0.371693 0.960822 0.536812 0.203084 -0.773974 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.176438 0.606806 0.582534 0.646623 -0.21074 0.100684 0.190803 0.824618 -0.649587 0.399687 -0.457925 -0.353598 -0.927647 -0.957199 0.355581 0.245315 -0.998746 0.083957 -0.934103 0.536202 -0.056003 0.757968 -0.834563 -0.497524 0.108113 -0.937347 0.0127203 -0.209317 0.00736168 -0.272326 -0.978835 0.720191 0.251638 -0.720674 -0.363482 0.96017 -0.418446 -0.814306 -0.0367185 0.872697 -0.578917 0.141022 0.157381 -0.895035 -0.85665 0.29138 -0.781428 0.545789 -0.920217 -0.0833765 0.691206 -0.901875 0.188762 0.526901 -0.381624 0.0392828 0.226743 0.864408 0.0992505 0.103915 0.498637 0.585717 0.151972 0.191715 0.154926 -0.167096 -0.383987 0.337786 -0.823421 0.764451 0.131131 -0.0792882 -0.59634 -0.684791 0.720348 0.894337 -0.881903 -0.136758 -0.484384 0.963542 0.258305 -0.66934 0.406183 0.721256 0.152423 -0.230121 0.353655 -0.112089 0.117653 -0.604969 0.291272 -0.592293 -0.667631 -0.879666 -0.550901 -0.992186 0.321593 -0.994537 0.808712 0.0159932 0.79702 -0.483947 0.304239 -0.662533 0.808981 0.54552 0.554983 -0.392516 0.98539 -0.558346 -0.124013 -0.288757 0.8676 -0.239045 0.368301 0.0360052 -0.859846 0.567237 -0.454288 0.78916 -0.585406 -0.915661 0.48082 -0.858058 0.624361 -0.36815 0.495418 0.494345 0.463017 -0.0778421 -0.291754 0.496305 -0.597313 0.954122 -0.0780673 -0.0765545 -0.65189 -0.308706 -0.415076 -0.183011 0.136774 0.759888 -0.570324 0.560247 0.0712838 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.092872 -0.919979 -0.0878428 -0.374116 0.238423 -0.828588 -0.0775213 -0.899902 -0.649158 -0.400272 0.624146 -0.614101 0.351549 -0.0162349 0.676173 -0.0249878 -0.467412 -0.242946 0.358793 -0.290434 0.462779 -0.390509 0.539238 0.70993 -0.545492 -0.296037 0.128627 -0.546131 0.994403 -0.865314 0.687001 0.740392 -0.225311 -0.873976 -0.642006 0.0847468 0.717231 0.946063 -0.323114 0.547802 0.276105 -0.453438 0.181016 -0.171471 -0.559134 0.0599785 -0.313767 -0.808487 0.427428 0.774362 -0.556818 0.43241 0.463042 -0.626784 0.595554 0.294164 0.0132325 0.397952 0.37293 -0.162293 0.345952 0.407018 0.74766 -0.0867426 0.117106 0.202788 0.265266 0.333472 0.662122 0.279114 -0.932345 0.071088 0.776607 0.432363 -0.560732 0.389007 0.840949 0.435891 0.599909 -0.528972 0.278575 0.828698 0.866052 -0.509333 -0.692977 0.980099 0.216457 -0.313146 0.735084 0.132514 0.926718 -0.751417 0.932717 0.170629 -0.233656 0.946692 -0.951373 0.269314 0.365251 0.774695 0.304637 -0.284162 -0.261336 -0.717769 0.15681 -0.683818 0.780989 -0.0429311 0.400677 0.0546649 0.75332 -0.948928 -0.637958 -0.164289 0.787936 0.837488 -0.331323 -0.543506 -0.702211 -0.0617778 -0.298763 0.696378 0.0230258 0.994198 -0.509235 -0.720894 -0.0679685 -0.347144 -0.107918 0.484228 -0.884174 0.0452938 -0.395206 0.389233 0.0725133 -0.822159 0.571004 0.862323 -0.932564 0.390425 -0.129779 0.805311 0.868643 -0.715147 0.525128 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.176753 -0.687858 -0.83575 -0.443527 -0.363388 0.540299 0.797905 0.389035 0.507617 -0.487604 0.842884 0.354947 -0.414013 -0.30929 -0.230345 0.593821 0.34526 0.787239 -0.880246 -0.286184 0.10084 0.816472 0.437162 -0.620043 0.932446 -0.377446 0.263823 0.0706472 -0.633337 -0.493225 0.364974 0.113232 -0.917378 -0.370135 -0.866437 -0.212062 -0.12417 -0.927699 0.166968 0.224785 -0.0350817 0.382291 -0.832047 -0.218726 -0.13271 -0.448738 0.0557835 -0.447162 0.551988 -0.739252 -0.6073 -0.883025 -0.993972 0.318126 0.742401 -0.467458 -0.558454 0.0705217 -0.741103 0.275823 -0.237979 0.294302 0.341311 0.417639 -0.734298 0.65785 0.484996 -0.679662 0.921466 -0.914875 -0.298235 -0.440228 -0.905751 -0.955995 0.599768 0.306544 0.0863848 -0.131201 0.899291 0.380946 0.559153 -0.318039 0.723744 -0.0325385 -0.874118 0.693292 0.158757 0.224388 -0.705888 0.148567 0.97158 -0.658671 -0.287518 -0.311205 -0.422847 -0.788584 0.260473 -0.229107 -0.603048 0.572243 -0.306731 0.779718 0.717771 -0.427247 -0.735972 0.521505 0.928976 -0.705326 -0.408308 -0.427078 0.0997722 0.871358 0.916577 0.914274 0.210358 -0.507177 -0.130346 -0.71805 -0.258103 0.0606465 -0.714901 0.665747 -0.794558 -0.136098 0.603046 -0.608902 0.183731 -0.035047 0.965011 0.945507 -0.868857 -0.878487 -0.73131 0.880961 0.306783 0.103347 0.953941 0.886961 -0.852343 0.671427 0.673936 0.843462 0.0720414 0.799141 -0.830937 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.440679 -0.128484 0.567658 0.630017 0.690383 -0.73744 -0.154646 0.85985 -0.50594 0.658244 -0.888269 0.733245 -0.451329 0.407533 -0.688502 0.244108 0.617607 0.0193484 -0.906068 -0.393963 0.198462 -0.939449 0.215249 -0.790743 -0.512118 0.370291 0.987961 0.160321 0.05888 -0.781016 -0.951901 -0.958122 0.419225 -0.523468 -0.291201 -0.577951 0.0408741 0.644725 -0.279402 -0.0908295 -0.706564 0.57067 -0.929152 -0.369631 -0.525571 0.607203 -0.819288 -0.0533862 0.457045 -0.64988 -0.799872 0.30793 -0.839072 -0.481179 0.604365 -0.683203 -0.598181 0.364768 0.647997 0.885393 0.794988 -0.633448 -0.365167 0.630654 -0.590152 -0.690532 0.230951 -0.40046 -0.531547 0.29739 0.240768 0.581345 0.663883 -0.120602 0.766964 0.0722834 0.613575 0.0562657 -0.643004 0.772829 0.663843 0.958263 -0.704539 0.348296 -0.672343 -0.516498 0.736615 -0.190309 -0.997858 0.488496 -0.319621 -0.312245 0.0983035 0.186097 -0.262534 -0.410935 -0.591843 0.89056 -0.365372 -0.800676 -0.96568 -0.243148 -0.663683 -0.605889 0.754476 0.432218 0.225223 -0.700458 -0.611869 0.296544 0.00810815 0.273642 -0.906006 0.764672 -0.158184 -0.593947 -0.467349 -0.732343 -0.480446 -0.862486 0.193805 -0.724008 -0.39667 -0.832477 0.564297 0.137483 0.681874 0.257753 -0.296378 0.40376 -0.273449 -0.201833 -0.5535 -0.962241 -0.753583 0.206745 0.47214 -0.746167 -0.827772 -0.358585 -0.732612 0.987381 0.919778 0.707775 -0.428903 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.576183 0.0923126 -0.502507 0.368592 0.926218 0.948622 -0.514454 -0.423157 0.00425029 -0.565339 0.348245 0.952779 -0.650428 0.264075 0.302944 -0.417492 -0.78072 0.431414 0.783276 0.51765 0.135153 -0.478038 -0.377492 -0.508061 -0.975246 -0.963844 0.678864 -0.336583 -0.955479 -0.739697 -0.0817013 0.846241 0.766383 0.599935 -0.88681 -0.621258 0.515812 -0.7423 0.171023 0.388799 0.53996 -0.884681 -0.831256 -0.915933 -0.092691 0.14161 0.031019 -0.663043 0.239357 0.876712 0.90655 0.389832 -0.0910252 0.139319 -0.47334 0.569944 -0.959306 0.950072 -0.134484 -0.270085 0.677052 -0.787483 0.766111 0.0278643 0.31581 -0.183221 0.612544 -0.969189 0.841881 -0.511458 -0.0812574 0.306586 0.79525 -0.227578 -0.904257 0.157995 -0.581086 -0.308696 -0.257187 -0.539673 -0.281456 -0.432351 -0.524077 -0.157128 -0.850629 -0.517094 -0.794288 0.40664 0.396796 0.944313 -0.933695 -0.619763 -0.364876 -0.477458 -0.632598 -0.0726832 0.41321 0.826819 0.345786 -0.371155 -0.0102244 0.158406 0.327876 0.619921 -0.99086 0.623787 -0.0196134 0.358156 -0.477775 0.037629 0.430516 -0.322415 -0.830321 0.791574 -0.0149633 0.512044 -0.0715109 0.116909 0.888399 -0.672634 -0.964424 0.917753 0.681742 0.0418365 -0.853433 0.35766 -0.802621 0.344683 -0.905861 -0.798541 0.921381 -0.34325 -0.996874 -0.456371 -0.224028 0.76104 0.79659 0.287728 -0.155361 0.840362 -0.0317615 0.183787 0.915919 -0.141427 -0.963004 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.755583 0.602996 0.561503 -0.821812 -0.1992 0.0510274 -0.381659 -0.542608 0.392194 -0.391298 -0.538108 0.859778 0.883093 0.818465 0.560235 0.503901 -0.261923 0.453407 -0.991292 0.0641268 0.739977 -0.108288 0.921577 -0.036181 -0.956661 0.361387 0.999799 0.811962 -0.433209 -0.550311 -0.437901 0.455074 -0.896474 -0.259105 -0.468801 -0.831055 0.631602 -0.583932 0.929335 0.507781 -0.869017 -0.293158 0.076519 0.730134 0.212692 -0.50931 0.518825 -0.333437 -0.292267 -0.795435 0.80229 -0.390123 0.601545 -0.52532 0.329135 -0.648562 -0.379029 -0.341215 -0.801745 -0.92166 -0.338187 0.0904424 0.065636 -0.856184 0.122695 0.138598 -0.589452 -0.92141 -0.13707 0.25974 -0.553463 -0.0518684 0.248066 -0.759876 0.489976 0.869862 -0.619493 0.0592384 -0.473382 -0.537608 0.136112 -0.796648 0.160982 0.636553 -0.341674 0.368545 -0.786302 -0.293005 0.432241 -0.0724735 0.933113 -0.357257 -0.416346 0.467249 -0.952409 0.866944 0.727199 0.0268966 0.0518789 -0.0715341 -0.273902 0.943534 0.442383 -0.282836 0.78404 -0.388373 -0.989951 0.0735202 -0.270486 0.111699 -0.68105 -0.404151 -0.560203 0.666759 0.210389 0.0130727 -0.287417 -0.609862 0.0507663 -0.770014 0.378051 -0.090435 0.0586311 -0.586816 -0.621389 0.308197 -0.132352 -0.444761 -0.888652 0.75413 0.421664 -0.894461 0.997811 0.0527885 -0.422444 0.0659018 -0.516778 0.520318 0.983208 0.769307 -0.262503 0.117611 0.681141 -0.0596113 0.112638 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.898065 0.224006 0.867959 -0.213899 0.997579 0.304508 -0.138485 0.490493 -0.286774 0.181042 0.774605 0.780965 -0.323854 0.983302 0.35723 -0.0345152 -0.096148 0.0410077 -0.783744 -0.382211 0.172297 -0.19813 0.0329248 -0.63347 -0.731911 0.769902 -0.25555 0.964286 0.758206 -0.827931 0.957738 0.696758 0.41119 0.872241 -0.243468 0.0281865 -0.269172 0.023169 -0.598661 0.305188 -0.703157 0.0358069 -0.193566 0.730999 -0.0973297 0.178966 -0.117854 -0.77067 -0.643903 -0.0728549 -0.472669 -0.154105 -0.0495093 -0.103501 0.464187 -0.414042 -0.809817 -0.598048 0.611045 -0.165277 0.191337 -0.196048 -0.97757 -0.0132627 -0.905867 -0.912305 0.888093 0.177787 0.0648087 -0.760934 0.98524 0.920499 0.819066 0.0351728 -0.851297 0.254164 -0.268146 -0.728484 0.375721 0.740246 -0.685014 0.963926 0.702162 -0.768397 -0.440577 -0.775324 -0.877119 0.25386 0.632505 0.510274 0.171991 0.66029 -0.506223 -0.0835181 0.312021 0.136681 -0.806764 0.721396 0.509271 -0.677524 0.851592 0.705939 0.709062 -0.797679 -0.598912 0.0862742 0.0106151 0.408403 0.0317185 -0.907069 0.887851 0.119971 0.352412 0.991614 0.0648398 -0.236755 0.860138 0.342558 -0.629699 0.653666 0.159167 -0.885621 -0.624869 -0.172406 0.367119 0.175388 -0.254079 -0.301053 0.203836 -0.121928 0.759572 0.125824 0.7166 -0.0995146 -0.541795 0.0508991 -0.538825 -0.040078 0.408448 0.790141 -0.106171 -0.422796 0.0696552 0.694321 -0.549475 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.994919 -0.172502 0.757642 -0.307668 -0.977377 -0.783383 -0.313003 -0.640678 0.128337 0.954529 0.769367 0.175845 -0.976999 -0.887159 -0.900297 0.274563 0.130149 -0.995194 -0.634679 0.460727 -0.591965 0.721978 0.294972 -0.464205 -0.0410319 0.353504 -0.836238 -0.826511 0.82086 0.560346 -0.0763237 -0.314921 -0.703506 0.266962 -0.757326 0.0407467 -0.654501 0.387586 -0.581625 -0.173456 0.148573 0.198382 -0.592112 -0.0933157 -0.944208 0.174117 0.0438784 0.252464 -0.0630792 0.912124 0.914186 -0.311929 0.442211 -0.658369 -0.151703 -0.745514 0.142403 -0.630171 0.713877 0.125398 -0.440145 0.485496 -0.272623 0.024263 -0.211405 0.921576 0.929597 -0.261552 0.0884754 -0.99456 0.429915 -0.412953 -0.500574 0.849738 0.370023 -0.287085 -0.150367 -0.506699 0.609006 0.47139 -0.515097 -0.310696 -0.846643 0.421221 -0.675418 0.271723 0.738238 -0.556086 -0.17721 -0.596937 -0.775336 0.989882 0.94508 -0.0420061 0.0033194 -0.210893 -0.476352 -0.0459257 0.126547 0.869574 0.934838 -0.462944 0.983377 -0.786142 -0.960517 0.417593 0.215254 -0.344071 -0.861343 -0.700369 0.902861 0.383136 -0.626624 0.337474 -0.0693423 0.563512 0.950928 0.241085 -0.0823704 -0.399876 -0.721365 0.0209965 0.888822 0.431408 0.6751 0.402342 0.15839 0.059929 -0.286153 -0.961863 0.774158 -0.23187 -0.555983 0.338305 0.27889 -0.112715 0.315285 0.990529 -0.180337 -0.916137 0.486403 0.974412 0.944688 -0.635707 -0.320116 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.183632 -0.295197 0.622089 -0.550016 -0.125497 0.768589 -0.326287 0.0879086 -0.519439 -0.215162 -0.224592 -0.718728 0.335324 -0.214834 -0.714155 -0.803626 -0.535793 0.921952 -0.761034 -0.705961 0.919859 0.0649925 0.328165 -0.523629 -0.63641 -0.139264 -0.605152 -0.784616 0.952362 0.351061 0.280086 -0.59948 0.54424 -0.965294 0.309898 0.452475 0.752802 0.344533 0.571168 -0.372229 -0.055124 -0.468978 -0.105664 0.108651 0.0971321 0.499992 -0.627167 -0.791751 -0.953078 -0.376669 -0.668457 -0.758339 0.595553 -0.533352 -0.0476502 -0.85752 -0.333506 0.763078 -0.940426 0.255062 0.828623 0.666409 0.329233 -0.583979 -0.929201 0.913904 -0.020856 -0.526417 0.513019 0.302615 0.0572796 0.697757 -0.791527 0.797741 -0.36555 0.204626 -0.848014 -0.574848 0.532532 0.272849 -0.226502 -0.813823 0.0722297 -0.035781 0.629041 0.294609 -0.511333 0.0316744 0.352478 0.0977153 0.300438 -0.536569 -0.116717 0.336221 0.872105 -0.530725 0.109602 0.0754163 -0.477886 0.176205 -0.517016 0.507754 -0.177698 -0.568172 0.73216 -0.579476 0.744229 0.259745 -0.469971 -0.806744 -0.954357 0.119834 0.0509744 0.726558 -0.747415 0.188151 0.26077 0.766308 -0.663632 0.337294 0.899474 -0.547987 -0.0127798 -0.789609 -0.964489 -0.168578 0.710597 -0.999305 0.673656 0.134039 0.78648 0.363774 -0.0440208 0.143143 -0.191347 0.0343864 -0.0669822 0.229727 -0.971258 0.0722491 0.290954 0.0686206 -0.6944 -0.785625 -0.00169807 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.539411 0.116353 -0.455362 0.729782 -0.557697 0.780952 -0.533194 0.610545 -0.573928 -0.00824384 -0.554214 -0.679308 0.866862 -0.655658 0.352034 0.63629 0.119356 0.0174098 0.607011 0.0350897 -0.247365 0.543515 0.854481 -0.739016 -0.644089 0.800589 -0.503655 -0.924269 -0.190711 0.712826 0.45884 -0.267774 -0.475559 -0.719215 0.146046 0.589787 0.54486 -0.542166 -0.190004 0.598153 -0.836103 -0.37975 -0.460317 -0.540533 -0.740658 -0.23287 0.154379 0.641444 0.743787 0.824083 0.371345 -0.800045 -0.354395 -0.311552 -0.254854 0.671674 0.820112 -0.382513 -0.896419 -0.12047 -0.731574 0.44319 0.697848 0.728713 -0.513063 0.945865 -0.841848 -0.943216 -0.62874 0.761054 -0.971358 0.383146 -0.457558 -0.183226 0.516828 0.323662 -0.21121 0.197428 0.175429 0.435737 -0.560406 -0.743065 -0.6993 0.863877 -0.811493 -0.770927 -0.96337 0.643415 -0.117253 -0.665716 -0.681044 -0.305945 -0.0240375 0.00234142 -0.647755 -0.823632 -0.787546 -0.294018 0.445234 -0.958713 0.90451 0.0936333 -0.304732 0.366347 -0.810547 -0.855206 0.545674 -0.862158 -0.291673 -0.14618 -0.841809 -0.280322 0.621915 0.531844 0.694816 -0.231845 -0.614476 0.495767 0.358346 0.729236 0.277076 0.823392 0.742143 -0.799447 -0.302644 -0.542577 0.907075 -0.783291 -0.775121 0.534692 0.574148 -0.294548 -0.468516 -0.344066 -0.709941 0.0296807 0.843424 -0.571411 0.288351 0.321893 0.055803 -0.119675 0.619195 0.80985 -0.851179 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.259576 -0.865779 0.853047 -0.842386 0.0113483 0.731084 -0.668548 -0.282431 -0.810234 0.397414 -0.656998 -0.883769 -0.00749942 -0.611363 0.302372 -0.568384 0.603483 0.238873 0.223805 0.886599 0.567295 -0.0978346 -0.776954 -0.815015 -0.616219 0.705778 -0.66621 0.314211 0.464134 0.664398 0.292453 -0.643163 0.0958361 0.366372 -0.338231 -0.609796 -0.680378 -0.871657 -0.849563 0.393182 -0.515365 -0.819372 -0.188027 -0.737716 0.487304 -0.540644 0.978468 -0.394983 0.0057136 0.89518 -0.136412 0.0451355 -0.593806 0.793753 -0.574611 -0.817302 -0.40133 0.8477 -0.706151 -0.285838 -0.0761066 0.876984 -0.534965 0.837612 -0.259902 -0.174042 0.869625 -0.214061 0.271498 -0.937858 -0.584312 -0.523459 0.22909 0.317347 0.193978 0.622867 -0.847841 0.753884 0.913679 0.854852 0.0545735 -0.116459 -0.540311 0.446603 -0.581019 0.369805 0.69361 0.878507 0.55363 0.0988836 -0.599648 -0.675557 -0.0930957 -0.65974 -0.253011 -0.35619 -0.484788 0.164384 0.804856 -0.792997 0.104096 -0.816222 -0.64067 -0.240437 0.630889 -0.86464 -0.335687 -0.0347842 -0.681954 0.263272 0.811348 0.324889 0.406139 -0.0196036 0.522322 0.658869 -0.385133 -0.924317 -0.996843 0.0575712 -0.400556 -0.148662 -0.566547 0.0466744 0.456486 0.16622 -0.343534 0.220277 0.329127 -0.326914 0.0714279 0.623832 0.884443 -0.719728 -0.469412 0.838648 -0.42448 -0.242705 0.853446 -0.138835 0.599178 0.380125 0.763549 0.970499 -0.822532 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.289281 0.0543573 -0.416122 0.237399 -0.0429532 0.085173 -0.496651 0.791572 -0.0530464 0.449167 -0.847009 0.325367 0.443022 -0.128035 0.116473 -0.437959 -0.774569 -0.173795 -0.974542 0.877594 -0.279995 0.116794 0.949823 -0.319682 -0.891522 0.197376 -0.69743 0.289301 0.28922 0.925021 0.836246 0.783745 0.396549 0.804931 0.46708 0.214117 0.663049 -0.13486 -0.584165 -0.0642883 -0.493271 -0.400821 -0.596263 0.613056 -0.368244 0.924916 -0.930526 0.654222 -0.482515 0.372249 0.394303 -0.94636 0.529117 0.870766 0.969403 0.753225 -0.553256 -0.56915 0.300714 0.0973928 0.881491 -0.774928 -0.219384 0.819478 0.96799 -0.995502 0.605513 0.860916 -0.592101 0.553827 0.178538 0.6894 0.740515 -0.159213 0.109902 -0.874541 -0.404708 0.0664049 0.0671087 -0.104633 -0.573128 -0.559114 0.979367 0.219354 0.682264 0.810266 0.138269 -0.107512 -0.954318 0.774463 0.397726 0.578127 0.584219 0.970958 0.882952 -0.233813 0.296746 -0.594136 0.352062 -0.900217 0.0502455 0.475801 0.785124 -0.423576 0.953568 0.619776 0.580743 0.55273 -0.261405 0.560622 0.372732 0.505458 -0.761182 0.817776 0.36369 0.54105 -0.573575 -0.0775464 0.677036 0.944166 0.598431 -0.167423 0.120086 0.293743 0.939963 -0.0349897 -0.0715313 -0.226622 -0.831273 0.787353 -0.953315 -0.367366 -0.312782 -0.934548 -0.941315 -0.678777 -0.212596 0.904494 -0.168096 0.808557 -0.586838 -0.988258 0.34284 0.112565 -0.128214 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.885534 0.823416 -0.841635 0.643202 0.299601 -0.611261 0.534295 -0.0958439 -0.848342 -0.0819352 0.915603 0.543044 0.938969 -0.742566 -0.310904 0.643663 0.040099 -0.0557295 -0.645105 -0.273168 0.866941 0.684201 -0.641711 0.756239 0.104641 0.70292 -0.0182079 -0.0207036 0.0344338 0.729601 0.40888 0.049646 0.399977 0.405913 0.172523 -0.399273 -0.577013 0.145081 0.372923 -0.275196 0.78182 0.0446398 0.260856 0.21309 -0.588116 -0.462845 0.962861 0.803521 0.782405 -0.121856 -0.0329288 0.565005 0.0393404 -0.805261 -0.0158037 0.387921 -0.213168 -0.718371 0.333719 0.818284 0.895356 0.251585 0.389045 0.686966 -0.167651 0.294448 0.78137 0.48 -0.640576 -0.15592 -0.542328 -0.898304 0.209642 -0.546638 0.659398 0.502711 -0.929044 -0.436009 -0.0104128 0.991732 0.0341891 0.616876 -0.172638 0.475254 -0.409749 -0.646279 -0.00405527 -0.156915 0.729732 0.600999 0.994878 0.917091 -0.444036 -0.920881 0.755063 0.337721 0.0790873 -0.77958 -0.4032 -0.587288 -0.546042 0.66851 -0.346183 -0.30491 -0.616893 -0.121555 -0.98071 -0.794313 -0.0121804 -0.716399 -0.518899 0.863145 0.874294 0.253226 -0.0230499 0.600944 0.0594548 -0.742423 0.0966441 0.298051 -0.650687 -0.102147 -0.787532 -0.0482697 0.731781 -0.951596 0.518652 0.984888 -0.986281 -0.432704 -0.458437 -0.948063 -0.0973938 -0.896925 -0.61759 0.165688 0.722462 0.415018 -0.792014 0.622504 0.417863 -0.980411 0.231782 -0.444635 -0.978485 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.498927 -0.0169891 0.463754 0.305759 0.898123 0.752772 -0.162772 0.291741 -0.709214 0.243325 -0.441443 0.959783 0.67652 0.086085 0.506865 0.579211 0.60349 0.477588 0.449482 0.366862 -0.142022 -0.571449 -0.436914 0.955414 0.139522 0.952147 -0.678299 0.451887 0.788686 -0.0653906 0.128203 0.805439 0.251355 0.0432901 -0.16478 0.804463 0.477016 0.835914 0.0993763 -0.592637 -0.130207 -0.934255 -0.834338 -0.893387 -0.838829 -0.100731 0.364302 -0.377307 -0.574545 -0.751997 -0.248083 0.573071 -0.598419 -0.0872567 -0.765691 -0.698647 -0.159827 -0.22053 -0.441076 0.83905 -0.0925277 0.886552 0.279454 0.791611 0.600127 0.32989 0.461971 0.348077 0.131122 -0.232262 0.366053 0.253582 -0.0551302 -0.574363 -0.658456 0.328914 0.425559 -0.564313 0.750703 -0.601222 -0.106479 0.672371 0.405466 0.808258 0.833211 -0.398447 -0.351593 -0.847757 -0.207626 -0.773632 -0.327521 0.982872 -0.862627 -0.170228 0.971706 -0.540292 -0.691325 0.892564 -0.674339 0.3851 0.381288 -0.568821 -0.932499 -0.911061 0.88876 0.0539731 0.186003 0.624904 0.966302 -0.910815 -0.0602939 0.640761 -0.72485 -0.546057 0.421886 0.635037 -0.939823 0.40015 -0.682741 -0.82259 0.735741 -0.397138 -0.70474 -0.561436 -0.0543211 -0.974423 0.87324 0.540247 -0.0824744 0.14668 -0.00216868 -0.488955 0.103768 -0.983656 0.0794911 -0.369545 0.119761 0.816959 0.63735 -0.0609873 0.987251 0.719379 0.595563 -0.376449 -0.978074 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.48202 0.684339 -0.319346 0.753341 -0.594472 0.708467 -0.799247 -0.947589 -0.134329 0.330226 0.107163 -0.919184 -0.727557 -0.0575055 -0.494533 0.390517 -0.585276 -0.73835 0.556557 0.0537876 0.00836216 0.542832 -0.621027 0.400665 -0.0150211 -0.459146 -0.858717 -0.458733 0.0762287 -0.824659 -0.0477743 -0.942762 -0.998703 0.792243 -0.764276 0.81786 -0.219064 0.192954 0.9718 -0.959757 -0.63501 -0.612619 -0.280197 0.728696 -0.810966 0.0914974 -0.202832 0.998163 0.119135 0.298585 0.32237 0.0765636 0.80405 -0.333617 0.89375 -0.741124 -0.0761442 0.244613 -0.788247 -0.0724216 0.809439 0.233175 0.96737 0.580949 0.00237476 -0.0874499 0.229696 0.50868 -0.613773 0.317294 0.767354 0.922674 -0.623557 -0.116446 0.900153 0.870185 -0.798297 -0.983267 0.224379 -0.866297 0.150062 0.0848961 0.848225 0.115184 -0.098688 -0.649301 -0.799821 -0.598661 0.305298 -0.861628 0.614281 0.227536 0.18974 0.968099 0.837591 -0.613748 0.73948 0.441798 -0.703826 0.79916 -0.520591 0.4345 0.644962 -0.120011 0.982049 -0.702043 0.769771 -0.453164 -0.320473 -0.193845 0.0496251 0.0485413 -0.166926 0.471136 0.375203 0.0429584 0.00177792 -0.118523 -0.0164422 -0.343988 0.59484 -0.516431 0.340319 -0.256018 -0.888896 0.321601 -0.85396 -0.509538 0.19879 -0.92931 -0.918829 -0.750857 0.352864 0.577025 0.0675617 -0.49122 0.0718 0.742265 -0.758799 0.860236 -0.0108679 -0.657527 0.946192 0.643122 0.947924 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.239576 -0.54969 -0.642828 -0.0123809 -0.0850875 -0.065974 -0.824477 -0.98469 0.316762 -0.187703 -0.719124 -0.322897 -0.935794 0.10283 0.265842 -0.000883807 -0.854144 0.408078 0.567081 0.936964 -0.438686 -0.996242 0.153165 0.243108 -0.0857181 -0.663473 -0.986495 -0.0169465 -0.819273 0.482531 -0.0983107 -0.308643 0.643847 -0.857199 -0.951922 -0.959963 -0.0975679 0.176076 -0.698053 -0.17997 -0.757677 -0.269636 0.223973 0.312396 0.444672 -0.401823 0.566243 0.846401 -0.546308 0.204099 0.29025 0.23994 0.671054 0.397673 -0.307286 -0.548829 -0.170353 0.876227 0.743084 -0.993922 -0.845658 -0.971087 0.938798 0.373542 0.11877 0.172119 0.804887 -0.25844 0.39808 0.538471 0.0806109 0.827392 -0.0187793 0.376717 -0.517804 -0.731677 0.712216 0.222169 -0.0116071 0.919959 -0.249568 -0.483007 0.104927 -0.4959 -0.583618 -0.868539 0.461664 -0.815401 -0.450757 0.133998 0.106916 0.93763 0.745853 -0.447812 -0.370571 -0.191762 -0.951008 0.406362 -0.278176 0.688095 0.805566 -0.854966 0.584597 -0.681982 -0.075469 -0.407198 0.215334 -0.888871 0.748827 -0.469181 0.47379 0.992192 -0.231354 -0.374765 -0.679347 0.220028 0.00922731 -0.916635 0.120186 -0.0272816 -0.521422 0.46357 -0.77603 -0.736714 0.0450512 -0.825219 0.536665 -0.268014 -0.515202 0.999132 0.414152 0.654993 0.473132 -0.0778631 -0.64502 -0.856376 0.889653 0.404467 -0.12563 0.543693 -0.151776 -0.904296 -0.496243 -0.350948 -0.38 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.656315 -0.684117 0.044322 0.920001 0.458781 0.739122 0.431428 -0.989759 -0.886494 0.689497 0.375788 -0.127607 -0.691657 -0.681376 0.112945 0.274633 -0.242601 0.604768 0.335093 -0.086664 -0.562554 -0.846201 -0.0944579 0.445328 0.626142 -0.430316 -0.317412 -0.735717 0.797457 0.862603 -0.226334 0.00856897 0.0186166 0.889141 -0.208484 0.0123677 -0.135804 -0.456559 0.619863 0.0433665 0.86073 0.283628 0.931876 0.0451285 0.474036 -0.875125 -0.228477 -0.00680144 -0.311785 -0.171326 0.531731 0.804779 -0.0815302 -0.277365 0.323508 -0.79842 0.961575 -0.809561 -0.290273 -0.622681 0.604955 -0.52035 0.481234 0.0998507 0.190305 0.453862 0.0568027 0.682491 0.624275 0.18549 -0.477057 0.0971718 -0.833264 -0.659919 0.736858 0.368961 -0.870179 0.902545 -0.933395 0.438513 0.086054 0.309541 0.451466 -0.213937 0.362844 0.326814 0.758675 -0.952506 -0.775263 0.153113 -0.63786 -0.505303 -0.62096 -0.479945 -0.428259 0.258877 0.952352 0.1737 -0.629269 -0.127291 0.61495 -0.536428 0.256817 0.327383 0.320588 0.129384 0.560761 0.703691 0.931052 0.194349 0.421167 0.561078 0.0313508 0.91265 0.916537 0.242772 0.268136 0.556178 -0.311665 -0.147019 -0.95629 -0.367425 0.692392 -0.965874 0.55497 -0.614347 0.678322 0.564402 -0.103352 0.956666 0.688423 0.328353 0.626766 0.0586782 0.204711 0.584352 -0.791937 -0.0926101 -0.497307 -0.232245 0.65854 0.0838 0.426971 0.0986446 -0.080962 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.728115 0.577258 -0.0318072 -0.58376 0.741961 0.133415 0.301258 -0.757135 0.837675 0.801901 -0.442325 -0.156313 0.849337 0.802597 -0.745049 -0.0412297 -0.947321 0.37247 0.102453 -0.0792621 -0.158016 0.220572 -0.847977 0.0536253 -0.720004 0.891432 0.296392 -0.539125 0.93281 -0.25901 0.823535 -0.84541 -0.802403 0.015501 0.525988 0.276939 0.510058 0.539648 -0.131792 0.974062 -0.948146 0.512862 -0.325041 -0.965863 0.744462 0.17858 -0.605617 -0.598604 -0.743 0.396486 -0.267329 -0.999122 -0.248656 0.843075 -0.442988 0.693553 0.541023 0.96733 -0.0841989 0.868836 0.527427 0.472285 -0.313293 0.482899 0.0894516 -0.587203 0.879734 -0.303397 0.808993 0.741524 0.78735 0.987173 -0.580707 0.0643476 -0.510151 -0.103388 0.35557 0.0601426 0.817187 0.462034 -0.596224 -0.736635 -0.630351 -0.317652 -0.773764 -0.650486 -0.725805 -0.5965 0.621357 -0.849406 0.0312266 0.825389 0.314591 -0.674236 0.112552 -0.334971 0.149178 -0.757985 0.53918 -0.00167574 -0.164184 0.564068 0.286205 0.251707 0.434733 0.560182 0.973886 0.10053 -0.387047 0.907959 0.0693889 0.219234 0.669416 0.869609 -0.483335 0.582359 -0.294574 -0.90075 -0.913029 0.719325 -0.299805 -0.825564 0.750646 0.108287 -0.0186902 -0.126099 0.661068 0.566459 0.482453 0.594686 0.880737 0.555041 0.570769 0.91943 0.85592 -0.548476 -0.231641 0.802172 0.106408 0.395383 -0.803772 -0.988828 0.769938 0.351619 -0.33411 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.619102 -0.750697 -0.959984 -0.449567 0.132516 -0.803024 -0.428304 -0.496946 -0.178001 0.345314 -0.30711 0.409523 0.850489 0.176806 -0.42435 -0.0437146 -0.711144 -0.200247 0.444045 -0.943645 0.16405 -0.809594 -0.845304 0.98046 0.586716 0.929594 -0.305709 -0.0477253 -0.119788 0.725871 -0.285706 0.131697 -0.576057 0.215215 -0.877473 0.312237 -0.225498 0.0617698 0.164838 0.428991 0.0587008 0.584744 -0.203731 -0.108702 -0.959504 -0.385792 -0.0120753 -0.948986 0.396722 -0.298155 0.916286 0.0129168 -0.90792 0.592534 0.720736 -0.593686 -0.0760513 -0.194793 0.109784 -0.859965 0.563044 -0.914151 -0.132958 -0.628489 0.984648 0.974467 -0.137467 -0.410064 0.0496501 0.46924 0.515338 -0.720375 0.654395 0.413038 -0.0661202 0.717777 -0.322452 0.555011 0.0767689 0.254242 -0.952017 -0.544803 -0.499667 0.0983311 0.650232 0.454454 0.00709202 -0.80442 0.118807 0.790214 -0.866756 0.427486 0.750899 0.363813 0.60131 0.223002 0.00110012 0.489664 -0.211654 0.728395 0.139617 0.541343 0.355394 -0.893952 -0.647099 0.21075 0.076881 0.138534 0.348932 0.50378 -0.976605 0.203945 -0.298149 -0.989657 0.834055 -0.0431576 0.64982 -0.482605 0.857816 -0.693854 0.401374 -0.106011 0.279258 -0.508988 -0.568191 0.408571 0.859135 -0.513422 0.91139 -0.264169 0.106738 -0.0610591 -0.22075 -0.138221 0.914082 0.975689 0.398832 -0.83243 -0.652174 0.911605 -0.6469 -0.442961 -0.837194 -0.716276 -0.448762 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.339589 0.526857 0.882321 -0.826616 -0.942599 -0.263199 0.406106 -0.569641 0.0465709 0.716825 -0.316404 0.194238 0.551542 -0.238056 0.987142 0.899936 -0.783274 -0.479332 -0.126143 -0.078305 -0.0714621 0.936455 0.999423 -0.705715 -0.95721 0.171786 -0.788102 0.365868 -0.855741 -0.439906 0.49867 -0.85177 0.298957 0.568643 -0.825493 -0.0546743 -0.911428 -0.377468 -0.100761 0.514324 0.248334 -0.250971 -0.0640139 0.118496 -0.44378 -0.604106 0.789793 0.0540736 0.815052 0.580025 0.477284 -0.282412 -0.491889 0.828485 0.345045 -0.831033 0.832616 -0.227531 -0.110851 0.932806 -0.335943 -0.192922 -0.445727 0.6668 0.913557 0.157186 -0.171639 -0.730109 -0.944021 -0.162959 -0.85136 -0.811083 0.12351 -0.168888 -0.493735 -0.208438 0.780135 -0.278787 0.425549 0.197805 0.509357 0.756908 -0.639522 -0.439399 -0.977459 -0.152872 0.678677 0.517623 -0.306348 -0.787742 0.415072 0.120697 0.559357 -0.889463 0.797974 -0.452991 0.575675 -0.635342 -0.200897 -0.47014 0.349278 0.318036 -0.764566 -0.0685645 -0.363242 0.98762 0.927333 -0.315504 -0.678831 0.893069 -0.181633 -0.699474 -0.0593184 -0.964592 0.107602 0.460456 0.883639 -0.687101 -0.112139 -0.725983 0.410696 0.571171 -0.324614 0.220779 0.633803 0.321739 -0.535477 0.244822 0.719437 -0.414229 0.0475825 -0.281499 0.849971 -0.539249 0.834827 0.932274 0.727236 0.648326 0.415333 0.502259 -0.536102 -0.272253 0.239731 -0.846195 0.000303735 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.895133 -0.504617 0.905482 0.428299 0.422111 0.41367 0.556595 0.694548 -0.729847 -0.538229 -0.0174261 -0.880073 0.611482 -0.822327 -0.846618 0.896606 -0.746995 -0.742571 -0.39056 -0.147945 -0.51087 -0.196772 0.849953 -0.839766 0.0468376 -0.800888 -0.52053 -0.548056 0.820496 0.0830854 0.416499 0.104355 -0.0980876 -0.558966 -0.549551 -0.302493 -0.00451683 0.0856191 -0.999725 -0.371939 0.818716 0.162437 0.0863119 0.643706 0.763162 0.457442 0.219402 -0.50478 0.166471 -0.114493 -0.283709 -0.290299 0.940984 -0.88981 0.971727 -0.180921 -0.73917 0.777749 -0.377581 -0.00889217 0.549273 -0.37406 -0.822335 -0.978633 0.117195 -0.29757 0.747004 0.891679 0.4485 -0.0594566 0.713184 0.478179 0.760465 -0.866206 -0.316252 0.756012 0.289583 -0.970364 -0.899776 -0.531311 0.25135 0.446715 -0.0538289 -0.702968 -0.784605 -0.862529 -0.517174 -0.142834 -0.606559 -0.445061 -0.142619 -0.990839 0.960759 -0.528607 -0.299092 -0.837695 0.863803 -0.0627577 -0.769419 0.368928 0.577624 0.122364 0.577493 -0.0801951 0.160851 -0.57481 -0.828476 -0.1929 -0.0743657 0.134848 0.386095 -0.894054 -0.366223 0.883282 -0.676982 -0.0321436 -0.236903 0.366829 -0.702913 0.137967 0.811938 0.238206 -0.465283 -0.00461333 0.463823 -0.523259 -0.418015 0.421079 -0.930034 0.925803 -0.0357554 -0.941197 -0.702369 -0.71188 -0.572281 -0.332981 -0.415445 -0.385596 -0.717236 -0.59248 0.192523 -0.261816 -0.338902 0.0786874 0.49915 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.792582 -0.926778 -0.362038 -0.769445 -0.0574836 -0.127225 -0.27801 -0.516295 0.629642 0.388543 0.24632 -0.0937097 -0.978276 0.117892 -0.592342 0.50448 0.790028 0.00690662 0.0795584 -0.862315 -0.935186 0.335119 0.348513 -0.535382 -0.167865 0.687478 0.434797 -0.367261 -0.561476 -0.723695 0.861633 -0.538757 -0.88788 -0.598381 -0.994326 0.36625 -0.430104 -0.758934 0.60272 -0.0858578 0.987286 -0.684362 -0.0665098 0.170628 -0.259123 0.922729 0.308908 -0.178215 0.740661 0.281503 -0.778563 0.690028 -0.691867 -0.20847 0.241039 -0.86471 0.819745 -0.540582 0.436509 0.410236 0.833224 0.00117377 -0.272486 0.33107 0.288575 0.0790824 -0.861319 -0.18386 -0.129273 -0.68802 0.447483 0.844075 0.361119 -0.679996 -0.693218 -0.913315 -0.0900099 -0.79677 0.681526 0.409979 0.509828 0.685474 0.769059 -0.422907 0.207887 -0.0408738 -0.96594 -0.557564 -0.974007 -0.129438 0.530848 -0.031685 -0.529589 -0.797861 0.351121 -0.715916 -0.405866 0.617392 0.50823 -0.177818 -0.587266 -0.175651 -0.174128 -0.568705 -0.228766 -0.874615 0.340897 -0.547203 -0.842722 0.369522 0.559594 -0.89958 0.762369 -0.859736 0.412929 0.10229 -0.807707 0.875206 -0.418062 -0.374268 -0.326216 -0.70946 0.103238 -0.878932 -0.21072 0.426042 0.479732 0.849072 0.353698 0.599281 0.113369 -0.614813 0.836363 0.752984 -0.591349 -0.80632 0.178674 0.975326 0.297676 -0.956706 0.640434 -0.219837 -0.805566 0.857909 0.873612 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.732897 0.527919 0.72768 0.113321 0.577646 0.504307 -0.11537 0.970739 -0.795411 -0.46809 0.817655 -0.321596 -0.118516 -0.842013 -0.731256 0.774269 0.19151 -0.345954 0.511089 -0.997709 0.19164 -0.201204 0.983686 -0.41174 0.846535 0.388433 -0.583674 -0.766764 -0.374587 0.113083 0.759976 0.491426 -0.377097 0.526198 -0.532583 0.535768 0.0861683 -0.480984 -0.209194 -0.0649302 0.071138 -0.358317 -0.372765 0.0139282 -0.549741 -0.270168 0.0799992 -0.648602 -0.229518 0.616744 0.289538 0.675343 0.707721 0.734184 -0.377956 0.20014 -0.250699 0.497554 0.392164 -0.90416 -0.209315 0.0430499 -0.460012 0.581434 0.164793 -0.329759 -0.266784 0.159968 0.583279 -0.826835 -0.6147 0.732755 -0.588646 0.622899 -0.210328 -0.0577153 0.53767 -0.415638 -0.605042 -0.406222 -0.653756 0.815692 -0.400091 0.424404 -0.111731 0.709492 -0.678165 0.977997 -0.0905553 -0.816472 0.293253 -0.837762 -0.273024 -0.715712 -0.9761 0.685366 0.939786 0.986795 -0.93528 0.746491 0.282086 -0.326146 -0.806299 -0.537479 -0.776704 0.328324 0.762819 0.974656 -0.841173 0.675546 -0.100748 0.731803 -0.579609 0.509722 0.905852 0.654489 -0.00590994 0.671689 -0.917454 0.342599 0.0612445 -0.664246 0.0194313 0.582626 0.197919 0.420399 -0.345983 -0.932156 0.749595 0.126407 -0.698962 0.0328561 -0.295985 0.289807 0.523393 -0.0478227 -0.789571 -0.322429 0.928486 -0.939981 -0.259783 -0.167721 -0.892233 0.232705 -0.932583 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.155455 0.47894 -0.447914 -0.0852818 0.668082 0.456531 0.914358 -0.38329 0.0441252 -0.387579 -0.0411296 0.817936 -0.287235 0.920449 0.582264 0.693882 0.569226 -0.374561 -0.603244 -0.328966 0.366199 -0.299548 0.892454 0.648988 0.439784 0.761064 0.0304182 0.0318707 -0.960555 0.523158 0.742748 0.261239 0.61156 0.213327 0.157785 0.660763 0.542099 0.360521 0.849751 -0.900126 -0.343844 0.128344 0.411504 0.617493 0.27132 0.331873 0.661395 0.0639935 -0.496966 0.471523 -0.92772 0.386488 0.528719 -0.786677 -0.819424 0.36411 -0.394947 0.118625 -0.269786 -0.300391 -0.675018 0.970419 -0.167274 0.624885 0.436687 -0.599089 -0.894868 -0.0482665 0.785126 -0.390032 0.724528 -0.855813 0.355209 -0.00665834 0.197916 0.194064 -0.0128399 -0.0298896 -0.667214 0.507911 0.582473 0.0587158 -0.397105 -0.940559 0.972453 -0.509159 -0.406727 -0.847544 0.606354 -0.360967 0.448188 0.318902 -0.220715 0.444671 -0.414533 0.948875 -0.256643 0.605878 0.990105 0.700532 -0.160461 0.194815 -0.779611 -0.248494 0.64383 0.297511 -0.611471 0.597986 0.184405 0.921228 -0.917687 0.436943 -0.293475 -0.433023 0.174897 -0.513998 -0.756508 -0.630787 0.363441 0.348276 -0.52359 0.016826 0.793761 0.748671 0.907295 0.9026 -0.00149307 0.90632 -0.476709 0.698285 0.112255 -0.305406 0.0596342 0.106698 -0.0594099 0.800251 -0.415892 0.0993674 0.0678328 0.0650421 -0.837152 -0.0185238 0.671202 0.897306 -0.979282 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.787394 0.260681 -0.726885 -0.758232 0.397872 -0.959196 0.790787 0.764061 -0.431937 0.43618 0.870152 0.65298 0.63933 -0.775971 0.255654 0.773512 0.418424 0.456093 -0.447845 -0.928294 0.162379 -0.897478 0.0806606 -0.337049 -0.781442 0.312125 -0.11242 0.564124 -0.767133 0.799485 0.943295 -0.0371611 -0.566611 0.96579 0.0356415 -0.973618 0.404046 0.802541 0.313705 0.435141 -0.577 0.355704 0.317878 0.575235 -0.0258299 -0.123467 0.890479 0.277802 -0.980855 0.762029 -0.581924 -0.388569 -0.68419 0.817539 0.37171 -0.675473 -0.669057 -0.833036 -0.842216 0.869914 0.645128 0.664173 0.760954 -0.642304 0.802302 0.294942 -0.903692 -0.353894 0.0994627 -0.330861 -0.777353 -0.96581 -0.366932 0.979046 0.822665 0.537374 -0.350864 -0.977499 -0.821604 -0.699169 -0.934737 -0.12552 0.38289 -0.771563 0.34642 0.284759 -0.050156 -0.971213 0.828496 0.524347 0.699694 -0.249453 -0.553008 -0.413442 -0.712236 -0.543785 0.597741 0.234931 0.481046 0.946153 -0.0137297 -0.755559 -0.683057 -0.137962 -0.73153 -0.818971 -0.445637 0.176069 -0.813226 0.10994 -0.245598 0.235022 0.0213071 0.10901 0.1361 -0.574996 0.0403347 -0.0942561 -0.16288 0.472768 -0.195783 -0.523239 -0.0703677 -0.670372 -0.941622 0.164663 -0.51507 -0.774141 -0.980517 0.458843 -0.225934 0.725456 0.746837 0.0896509 0.763438 -0.89933 0.958352 -0.979228 0.116739 0.0321189 -0.177644 0.339609 -0.199793 0.0818452 -0.426969 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0683878 0.606051 -0.10171 0.564152 -0.290053 -0.920025 -0.867474 0.357581 -0.141353 0.27987 -0.218643 -0.738207 0.954353 -0.187908 -0.166656 -0.98165 -0.591432 -0.197582 -0.767773 0.0396203 -0.101675 -0.857432 -0.858282 0.846917 0.129176 -0.946971 0.256272 -0.840724 -0.0428784 -0.658037 0.36752 0.916631 -0.180262 0.34322 0.494969 0.938017 -0.745284 0.00599991 0.840475 -0.140347 -0.815876 -0.434655 0.753255 -0.0392041 -0.904149 -0.0305138 -0.844642 0.0991791 0.902348 -0.234901 0.0118114 0.514518 -0.49671 -0.211033 -0.832934 0.873762 -0.680809 -0.354349 0.457498 -0.82564 -0.526946 -0.383325 -0.542696 0.909066 0.671698 -0.769035 0.825213 -0.639425 -0.823144 -0.582678 0.924636 0.352021 0.41089 -0.168942 0.584131 -0.516788 0.338652 -0.271931 -0.341432 -0.449365 -0.475504 0.200508 -0.0592429 0.30483 -0.726237 0.132505 -0.982264 -0.906728 0.629965 -0.183322 0.910043 -0.910395 0.993722 -0.509256 0.930519 -0.761052 0.991707 -0.384897 -0.968604 0.673569 0.67799 0.970222 0.527212 0.850836 -0.00477386 -0.234208 -0.334193 -0.774367 -0.7908 -0.97639 -0.188255 -0.00857073 -0.0482316 -0.628131 0.997945 0.455533 0.144578 -0.0850025 -0.636691 -0.867455 0.681671 0.838454 -0.103738 0.48332 -0.846906 0.0542589 -0.0703504 -0.37873 0.682516 -0.958611 0.623446 0.264194 0.314603 -0.470578 0.988875 0.0267236 -0.857089 0.911067 0.295127 0.193327 -0.746521 -0.78486 0.864743 -0.257233 0.687567 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0595818 0.609346 -0.720803 -0.528616 -0.442768 0.39159 -0.538702 0.0381204 0.689636 0.716186 0.932559 -0.476108 0.0540744 0.827621 -0.170287 -0.0205682 0.3097 -0.867705 0.476938 -0.101301 -0.574297 -0.217357 0.88926 -0.206514 -0.884501 0.194403 -0.670113 -0.586341 -0.634689 0.779468 0.520473 -0.406103 0.618524 -0.461546 0.794017 -0.954872 -0.530073 -0.932464 0.0787292 -0.798121 -0.0145847 0.875102 -0.166692 0.400803 0.287857 0.00886446 0.984917 -0.492015 0.704768 -0.959919 0.642368 0.284718 -0.748472 0.438102 -0.811983 -0.992324 0.0101683 0.898188 -0.155935 -0.796669 0.386657 0.547881 0.241375 0.789717 0.767074 0.215019 -0.181578 0.21499 -0.658001 0.983675 0.623616 -0.884456 0.950806 0.194036 -0.843162 0.983261 -0.33257 0.487913 0.361964 -0.46432 0.177485 0.993024 -0.246087 0.0234549 0.206307 -0.595933 0.161983 0.449701 0.120774 -0.152391 0.756617 0.456428 -0.806676 0.194022 0.922564 -0.468889 -0.622285 -0.745136 0.50748 -0.788603 -0.0560566 -0.143411 -0.304699 0.926308 0.45512 -0.805614 0.0453126 -0.431856 -0.199809 -0.197979 0.570954 0.0189224 0.0292342 -0.661516 -0.102596 -0.323261 0.950888 -0.431169 -0.652221 0.125368 -0.933097 -0.553628 -0.829447 -0.512946 0.91138 -0.441734 -0.2226 0.765391 -0.0749427 0.438696 -0.831937 -0.372564 0.316136 -0.709286 -0.964597 0.0164714 0.834451 0.615267 0.790763 0.346148 -0.286748 0.623185 -0.129592 -0.0519631 0.656699 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.864388 0.237502 -0.295967 -0.312833 0.212159 -0.243281 -0.815846 0.080821 0.358134 -0.850263 -0.37186 0.150811 0.683206 0.645781 -0.35194 0.943573 0.62471 -0.50465 0.34322 0.490523 0.224554 0.0708926 -0.507275 0.228684 -0.509165 0.462782 -0.0298142 0.912897 -0.944769 -0.733329 0.940987 -0.832959 0.46222 0.536139 0.895389 0.798961 0.141948 -0.2768 -0.177424 0.0350322 0.786861 0.780458 -0.842278 -0.165295 -0.121185 -0.763004 0.190704 -0.830331 0.632808 -0.390534 0.302478 -0.248087 0.400731 -0.917655 0.980281 -0.414071 0.710865 -0.498345 0.318693 0.266044 -0.605351 -0.132455 -0.178045 -0.403983 0.265054 0.755976 -0.313141 -0.958504 0.423151 -0.095271 0.780863 -0.0381421 0.946187 0.567456 -0.759412 0.568169 -0.779166 0.563521 -0.909794 -0.912437 0.669943 -0.262129 0.404392 0.618676 0.0948122 -0.492091 -0.566062 0.197118 0.961361 -0.406404 -0.426948 0.283345 0.177326 0.31268 -0.781619 -0.664869 -0.456273 -0.588332 -0.104314 0.797718 -0.752 -0.868277 0.872386 0.198938 -0.448116 0.506147 0.804439 0.204187 -0.225698 0.698403 0.0634589 0.552989 0.081807 0.930001 0.523863 0.561569 0.286151 -0.657608 -0.41472 -0.199783 0.249658 0.00628434 -0.379069 0.98218 -0.506605 -0.512974 0.440608 -0.702766 0.60606 0.0426555 0.910193 -0.39428 -0.659692 0.556987 -0.721268 -0.356362 0.618438 0.0828587 0.606951 -0.966326 0.966491 -0.179881 0.735501 -0.438112 0.652184 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.746234 0.0403631 0.383418 0.114481 0.0880024 -0.943631 0.39233 -0.115389 0.650734 0.887508 0.341496 -0.468859 -0.108343 -0.921664 -0.402222 -0.15174 -0.29711 0.468437 -0.978841 0.614535 0.491498 0.607477 -0.140263 0.602465 -0.367461 0.0833754 -0.710396 0.371218 -0.933012 0.862976 0.0363582 -0.927208 0.419858 0.559307 0.265962 0.0291042 -0.845731 -0.194662 0.320999 -0.96253 0.757145 -0.657778 0.725697 0.786261 0.688245 -0.661618 0.19326 0.112597 0.425612 -0.745494 0.478436 -0.923699 -0.61601 0.727462 0.453961 -0.28288 -0.364981 -0.240254 0.0590763 0.895756 0.974796 -0.600201 0.416576 -0.606422 -0.141322 0.794548 -0.0306194 -0.621009 0.704329 -0.348841 -0.972644 0.766402 0.910079 -0.307342 0.50645 -0.0967598 -0.242215 -0.914341 0.67285 0.590961 0.27329 -0.821175 0.504393 -0.660699 -0.363655 0.054615 -0.0853693 -0.801381 -0.815495 -0.0297266 0.38524 0.733163 0.273514 0.955705 0.536347 0.378107 0.851609 0.999114 0.114606 0.17769 0.43503 -0.453012 0.221735 0.699727 0.304012 -0.463707 0.483733 0.107794 -0.31029 0.95348 -0.8639 0.436094 -0.570619 -0.401515 -0.255643 -0.596057 0.0693841 0.138983 -0.119064 0.892635 0.518212 -0.412894 0.49793 0.703755 0.0081641 -0.78602 -0.64076 0.744134 0.655167 -0.610372 -0.521112 -0.321704 -0.884715 0.600675 -0.454748 -0.949397 -0.519566 -0.346141 0.403377 -0.447066 0.160103 0.856229 0.640673 -0.205818 0.821368 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.709841 -0.812127 0.581376 -0.808761 -0.841378 0.964767 0.835458 -0.464451 -0.035859 -0.68269 0.0351251 -0.985782 0.434932 0.43239 -0.33778 -0.565449 -0.978603 -0.911549 0.0680569 0.389771 -0.792494 0.993595 -0.348738 -0.861912 0.304863 0.161467 0.260803 -0.174564 0.405339 0.412774 -0.433264 -0.0971451 -0.618647 0.574404 -0.177691 -0.638009 0.68598 0.894719 0.378111 -0.159929 0.747848 0.0891651 -0.476079 -0.931856 0.968021 0.144918 0.0288431 0.157172 0.98776 0.33005 0.47318 -0.0632803 -0.450733 -0.445612 -0.310761 0.281187 -0.0898034 0.67471 -0.154089 0.217902 0.279645 -0.0131645 0.743665 0.781151 0.799431 0.0314919 -0.715631 0.390932 0.390821 0.521414 -0.594662 -0.481921 0.347567 -0.434841 0.973906 -0.103112 0.270605 -0.468895 0.785995 -0.520239 -0.314865 -0.697431 -0.591825 -0.437977 -0.626146 0.631964 -0.156795 -0.819128 -0.755995 0.544158 0.0140915 -0.946689 0.99218 -0.431287 -0.639101 0.627093 -0.456242 -0.0626196 -0.448009 0.318421 -0.305358 0.172573 0.798823 0.279879 0.252633 0.204301 -0.00436328 0.805733 0.010839 0.302632 0.341267 -0.322062 -0.896806 -0.623572 -0.373573 -0.642339 0.21293 0.710268 -0.518085 0.539271 -0.470118 0.728654 0.480779 0.447822 0.53793 0.995824 0.815218 -0.632044 0.972673 -0.464936 -0.803596 -0.302032 -0.510341 0.154759 0.883797 -0.393189 -0.852372 0.178882 0.474777 -0.421885 -0.615361 -0.374178 -0.80837 -0.270828 0.199425 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.272347 0.667304 -0.629362 0.3126 -0.127739 -0.901354 0.93952 0.506277 0.996386 0.255588 -0.3319 -0.241849 -0.750825 0.890222 -0.0384406 -0.0710164 0.426838 -0.129679 0.479998 -0.67545 -0.288304 0.480357 -0.643292 0.198832 -0.228772 -0.971412 -0.518467 0.126172 0.572446 -0.89567 0.472378 -0.747393 0.563551 -0.397684 0.131192 0.948596 -0.949396 -0.504195 -0.00592537 0.41223 0.341793 0.514958 0.892071 -0.963701 -0.915514 0.959509 0.474825 0.385953 0.715131 -0.792821 -0.941753 -0.036582 -0.833363 -0.327061 -0.916621 0.345648 -0.686681 0.9567 -0.743429 -0.817455 -0.960474 -0.693645 -0.0904559 -0.292475 0.364932 -0.587354 0.345979 0.863843 0.608353 0.595914 -0.474693 -0.173564 0.912972 0.32772 -0.00435471 0.810323 -0.908009 -0.912649 -0.889755 -0.120461 -0.586723 0.944573 -0.558849 -0.574645 -0.0570332 -0.557514 -0.140091 -0.515036 -0.210861 0.0571717 0.885092 -0.258639 -0.950933 -0.322605 -0.0152309 0.0148403 -0.578409 0.675459 0.432293 -0.448131 0.270009 0.046295 0.0804059 -0.617478 0.0453161 -0.373111 -0.877172 -0.62443 -0.801156 0.969806 -0.463113 0.455373 -0.544031 0.475561 0.755765 0.135425 0.087068 -0.648744 0.565165 0.729404 -0.899796 -0.865669 0.693965 -0.523859 -0.504765 0.415115 0.841036 -0.702622 -0.975608 0.956116 -0.55646 -0.420816 -0.648866 0.507644 -0.0289473 -0.516579 -0.150752 0.318319 -0.0181083 -0.346189 -0.403491 0.533127 0.273806 -0.137772 0.469565 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0559259 0.709615 0.501127 0.445617 -0.517424 -0.338942 -0.591672 -0.238556 0.589151 -0.145178 -0.00703879 0.500376 0.382921 0.394281 -0.732391 -0.701641 0.142663 0.298576 0.740525 0.666569 -0.181338 -0.822632 0.778144 -0.876139 -0.294288 0.701716 0.735723 0.307616 0.859312 0.727451 0.769547 -0.0930478 0.671226 -0.0874493 0.425755 -0.14656 0.817993 -0.0346462 0.712847 -0.0642621 0.754306 0.827148 0.981742 0.782438 -0.746368 0.522536 0.733913 0.551826 0.233243 -0.625146 0.761403 0.333931 -0.299341 0.21826 -0.390674 -0.560755 -0.603044 0.644903 0.890095 -0.180471 0.825596 -0.216215 0.081114 -0.716278 -0.490993 -0.117494 -0.719462 0.0062094 0.36137 -0.446369 -0.115949 -0.747906 -0.0530467 0.443607 -0.660489 0.912761 0.305125 0.000326033 -0.717129 0.724803 -0.622229 -0.322767 0.609648 -0.807032 -0.832786 0.102808 0.818316 0.36393 -0.622439 -0.265062 -0.0709229 0.665177 -0.366662 -0.480189 -0.531107 -0.321952 0.951876 0.180441 0.670793 0.0226232 0.22759 -0.502437 -0.0152333 0.531749 -0.507516 0.406968 0.273497 0.827896 0.524257 -0.656804 -0.905045 0.910127 0.511093 -0.0608928 0.574203 0.63668 0.686744 0.110801 0.234657 -0.127809 -0.0788315 -0.920707 -0.314447 -0.915962 -0.575281 -0.741483 -0.104358 0.0523981 0.745833 -0.584734 0.0413014 0.233537 -0.866106 -0.894164 0.0214407 0.317504 0.0555224 -0.835407 -0.685824 -0.643407 0.263731 0.526958 0.590254 0.401814 -0.704347 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.131997 -0.865208 0.455673 0.499078 0.00625809 -0.820351 0.355533 -0.557092 0.957987 0.892694 -0.497396 0.0425121 0.934565 -0.538257 -0.118426 -0.0407248 -0.215642 0.128751 0.329869 0.238071 -0.532357 0.520537 0.979616 0.458931 0.987862 -0.793187 0.569773 -0.206389 -0.477178 -0.233178 0.031576 0.766499 -0.478333 -0.651006 0.462214 0.355244 0.87679 0.738081 0.10254 0.290295 0.733251 0.385509 0.149043 -0.803552 0.447401 -0.572011 0.906098 0.130777 -0.723692 -0.615578 -0.460849 0.510739 0.306006 -0.395173 0.669155 0.329663 0.63915 0.189307 -0.310925 0.276199 0.0778701 0.763183 0.813901 -0.760499 0.295225 -0.15462 -0.697898 0.431392 0.403791 0.513378 0.344291 0.494366 0.8047 0.599182 -0.0743081 0.244018 0.955031 0.274577 -0.203962 -0.200477 0.0708428 0.513969 0.519094 0.497449 0.422307 0.109572 -0.541777 0.211753 -0.888397 0.153991 0.240943 0.110563 0.228557 -0.638501 0.713686 0.918966 -0.945796 0.00741375 0.602928 -0.581836 -0.914141 0.930564 0.770647 0.718225 0.147819 -0.261638 -0.380028 0.408618 -0.555943 -0.168363 0.319539 0.49479 -0.0665416 -0.365228 -0.388401 0.137529 -0.548324 0.314574 -0.956909 -0.76928 0.712002 0.623714 0.754934 0.171288 0.840876 0.599972 -0.263518 -0.951464 0.924036 0.154482 -0.245844 0.298743 -0.826516 -0.0982598 0.33483 0.0265926 0.0127602 0.461481 0.111183 0.65984 -0.0760278 0.20011 -0.756502 -0.526618 -0.868599 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.544885 0.109666 -0.851244 -0.859469 0.912512 0.596676 0.337762 0.760952 -0.681326 0.954891 0.846806 0.26675 -0.73134 0.36896 -0.895317 0.403169 0.0623106 -0.745711 0.837687 -0.987366 -0.655841 -0.727407 0.462789 0.093232 0.950002 0.682107 0.164045 -0.892506 -0.356631 0.0976764 -0.352782 0.793481 0.0406712 -0.43839 -0.0125983 0.259748 -0.422246 -0.689312 0.726898 0.968339 0.865588 -0.0603242 0.130654 -0.0948051 0.610253 0.523587 -0.0679634 -0.261669 0.126154 0.272743 -0.00372927 -0.67783 -0.295545 0.774962 0.779235 0.604659 0.503128 0.0740386 0.366048 0.165519 -0.118322 -0.645171 0.610557 -0.367781 0.697096 0.0899723 0.165167 -0.0441049 0.72931 -0.492775 -0.0670681 0.786686 -0.171711 0.0517322 -0.53767 -0.620148 -0.827094 -0.966052 -0.435924 -0.569312 -0.429186 0.664586 -0.299733 0.389856 0.306069 0.103613 -0.570503 -0.439663 0.584786 0.501268 0.815254 -0.0320808 0.818091 -0.339329 0.894519 0.17575 -0.164459 -0.0634766 -0.851017 0.959221 -0.38067 0.0791136 -0.337969 -0.251967 -0.801378 -0.753698 0.592649 0.644864 0.234605 -0.996379 -0.14256 0.000636277 0.693912 0.57603 -0.665779 0.24701 -0.510636 -0.262597 0.528372 0.354805 -0.787547 -0.300451 0.321172 -0.0662882 -0.105899 0.158964 -0.289183 -0.304328 -0.837344 0.763148 0.228113 -0.100866 0.748069 0.800306 0.739916 -0.225786 -0.791644 0.84705 0.366907 0.60049 0.441204 -0.677704 -0.168823 0.590436 -0.541722 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.725792 -0.393312 -0.394587 0.175969 -0.494048 0.528407 0.932986 0.69809 0.798332 -0.441682 0.646143 -0.27705 -0.372968 -0.47936 -0.60305 0.535037 0.362625 0.632016 0.295044 0.797307 0.332056 0.871399 -0.393888 -0.080439 0.061665 0.404046 0.794339 0.462103 0.560764 0.757661 0.0156392 0.848651 -0.727523 0.523947 -0.0261003 -0.667676 0.367625 0.670787 -0.0896539 -0.813495 -0.416363 0.190007 -0.547016 0.304011 -0.495075 -0.719721 -0.358338 -0.580019 -0.377608 -0.452319 -0.118728 0.539595 0.978491 -0.50477 0.327616 0.248565 -0.370125 -0.684083 0.618402 -0.520163 -0.379625 -0.356401 -0.0261734 0.104476 -0.0698058 0.774209 0.125749 -0.534304 -0.0472691 -0.451652 -0.916986 0.208084 -0.724747 -0.826651 0.484714 0.590691 -0.25774 0.165606 -0.66326 0.597325 -0.759151 0.947445 -0.283659 0.543976 0.606124 -0.873674 0.15849 -0.258947 -0.127825 -0.360252 -0.756493 -0.370623 0.942594 0.180397 -0.075905 0.265332 -0.564967 0.605803 -0.271787 0.0737228 -0.940246 -0.717917 -0.0379813 -0.351915 -0.641943 0.86597 0.353213 0.454206 -0.156583 0.303061 -0.446233 0.16813 -0.233663 0.826604 0.732805 0.261251 0.837627 -0.00579551 0.594863 -0.136774 -0.761578 0.158162 0.229003 0.860288 0.856169 -0.375205 -0.0737943 -0.260663 -0.966446 0.934922 -0.758927 0.705965 -0.839357 0.932696 -0.171821 0.198886 0.680214 0.353454 0.506074 -0.412906 0.290468 -0.0999332 0.422283 -0.683717 0.765311 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.6655 -0.40352 0.0437133 0.689763 0.83901 -0.757785 -0.0885157 0.315857 0.613097 0.319412 0.361263 -0.424406 -0.510484 0.578127 -0.997707 -0.0774365 0.823214 0.228611 0.727483 0.99639 0.753812 -0.613641 -0.924771 -0.345707 -0.32437 0.751456 -0.38101 0.213799 -0.1538 0.956051 -0.39756 0.449667 0.73351 -0.984082 0.624293 0.58203 0.625419 0.108168 -0.748643 0.539482 0.894213 -0.234694 0.48854 -0.834054 -0.132471 -0.417923 0.692093 -0.511519 0.336522 0.507165 -0.391155 -0.0280639 0.749772 0.0739451 -0.752878 0.350597 0.485272 -0.0272611 -0.177296 0.180115 -0.810013 0.109587 -0.17952 0.810203 -0.91156 -0.586414 0.147763 -0.554233 -0.999501 -0.607127 0.0194001 0.0578368 0.0630726 0.061387 -0.671648 0.89396 0.660819 -0.402833 0.706764 0.492127 0.806983 0.941943 -0.421367 0.40251 -0.987431 0.861563 0.412192 -0.190329 -0.453467 0.279688 -0.931199 0.128173 0.209962 0.834711 0.990223 0.67741 -0.767534 0.0542973 0.574433 0.493484 -0.0173465 -0.608772 -0.814842 -0.564219 0.132392 0.478045 -0.497407 -0.36434 0.345093 -0.451704 0.206131 0.451225 -0.256257 -0.904731 0.1779 -0.0344637 0.76937 0.804998 -0.391162 -0.264122 0.901083 0.498286 0.697032 -0.984432 0.65761 0.457264 -0.760801 -0.778791 -0.783814 0.502039 -0.719708 0.241474 0.821855 0.215013 -0.306335 0.111518 -0.495257 0.217429 0.328273 -0.72286 0.893264 -0.91068 0.203703 -0.37096 -0.728456 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.933474 0.26279 0.710539 0.0326666 -0.972284 0.822947 -0.731038 -0.550287 -0.667859 -0.711347 0.389675 -0.779373 -0.361799 -0.375144 -0.543395 -0.369385 0.135834 -0.494008 -0.251811 0.0897837 -0.174507 -0.454001 0.534114 -0.460119 -0.813039 0.0997578 0.952252 0.776874 -0.155752 0.473044 0.0634721 -0.68228 0.458846 -0.895687 0.593542 0.0664663 -0.154183 -0.37663 -0.617382 0.807949 -0.864912 0.320663 0.534107 -0.891078 -0.418706 0.936332 -0.275674 0.467128 0.704434 0.174519 -0.942275 -0.491327 0.878473 -0.681445 -0.405538 0.301893 -0.0874768 -0.221901 0.515229 -0.552074 -0.712618 -0.967779 0.539704 0.807999 0.0316617 0.138943 -0.779296 0.364827 -0.346768 -0.138023 0.253782 -0.693204 -0.67566 0.186713 -0.0852905 0.0516649 0.420179 -0.575245 -0.757479 -0.824702 -0.90802 -0.907429 -0.616356 -0.367937 0.536552 0.843146 -0.712983 -0.592653 0.0909801 -0.766035 0.00219624 0.0825051 0.663184 0.134318 -0.517871 0.142829 0.525979 0.131994 0.430221 0.729081 -0.332175 0.124891 -0.0721917 -0.753372 -0.899562 0.464758 0.232055 -0.279884 -0.196803 -0.0768143 0.981513 0.287005 -0.31491 -0.685715 -0.819064 -0.0147772 -0.361227 0.853306 -0.48961 -0.880096 0.231919 -0.141976 -0.193533 -0.717492 -0.892475 0.17481 0.0396425 0.271335 0.972374 -0.932587 -0.233484 0.505339 -0.110253 0.521236 0.697393 0.0522373 -0.582333 0.736451 -0.475731 0.38952 0.667123 0.338029 -0.738776 -0.611615 0.593627 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.906236 0.887003 -0.133773 -0.318092 -0.179012 -0.653325 -0.436823 0.317875 0.523456 -0.279836 0.791721 0.461206 -0.510241 0.385168 -0.485152 0.0491097 -0.61359 -0.61239 -0.432206 -0.0870079 -0.342203 0.60186 -0.535214 0.661305 0.545589 -0.286072 -0.0137721 0.532711 -0.729511 -0.885963 -0.374527 -0.671541 -0.594042 -0.0613298 -0.770578 0.894793 0.782445 0.556095 0.296431 0.120435 0.148368 -0.376087 -0.895247 -0.419244 -0.235934 0.653488 -0.828863 -0.697756 0.81917 -0.206273 -0.836452 -0.25236 0.581897 -0.0613061 -0.370948 -0.522669 -0.498593 0.149132 0.457108 0.614407 0.340561 -0.185914 -0.662172 0.869408 0.147147 -0.907722 -0.0763597 0.623352 0.677179 -0.655001 -0.606602 0.832424 0.551856 -0.962974 -0.70212 -0.53443 -0.173255 0.0974255 -0.569129 0.651648 0.251813 0.224139 -0.903013 -0.936458 0.949393 0.448581 -0.701597 0.256351 0.49037 -0.358947 -0.816049 0.664658 0.902836 -0.0397693 -0.402544 0.448284 0.312129 -0.0469285 -0.727665 0.138203 0.783789 -0.860462 0.21331 -0.897263 -0.294259 0.387966 0.536535 -0.450569 -0.721257 -0.168279 -0.265438 0.789962 0.886922 0.495924 0.993657 0.396336 -0.787623 0.413113 -0.808141 -0.424308 0.654617 0.142616 0.951442 0.878016 0.811415 -0.545672 0.887422 0.895653 -0.75984 -0.635565 0.0529647 0.178338 -0.671822 0.68049 -0.999357 -0.196856 -0.551061 0.317703 -0.373099 -0.678304 -0.249234 -0.869919 -0.730341 -0.847611 0.208298 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.865773 0.428017 -0.322563 0.681911 0.874857 -0.278729 -0.60539 -0.793267 -0.439649 0.816243 0.599823 -0.912942 0.0869275 0.876377 -0.840346 0.192005 0.920893 -0.652547 0.544235 0.839453 0.17904 0.588506 0.514741 0.736457 -0.898419 -0.229461 0.912493 -0.272866 -0.562779 0.96484 -0.380161 0.252703 0.72956 -0.766445 -0.0322783 -0.896078 -0.753578 0.254354 0.748055 0.356622 -0.400356 0.9973 -0.584916 -0.793165 -0.867277 -0.452887 0.242694 0.650475 0.221534 -0.909324 0.705328 0.18682 -0.355389 0.758413 0.412624 0.705069 0.102834 0.332914 -0.722039 0.683468 -0.960291 0.382306 -0.582809 0.733675 0.874381 -0.276637 0.561226 0.527086 0.734836 0.386521 0.266041 -0.65306 0.0131881 -0.348072 -0.335168 0.515991 -0.019205 0.902898 0.682198 -0.567721 0.0168513 0.952213 -0.400316 -0.618531 -0.1841 -0.661508 -0.484178 -0.105781 -0.36459 -0.211571 -0.382688 -0.324557 -0.828583 0.00277728 0.677805 -0.138552 -0.649919 0.815964 -0.0928762 -0.970718 -0.864263 0.257274 -0.0758991 0.26388 0.969007 0.0632169 0.41929 0.979017 0.333347 0.531784 -0.306819 -0.701047 -0.494822 -0.465417 -0.258232 -0.105348 -0.586996 0.359197 -0.970469 -0.665655 0.334474 -0.488707 0.300149 0.608859 -0.902098 0.444549 -0.466325 0.476207 -0.770307 -0.94729 0.600099 -0.51557 0.434737 0.305144 0.157391 0.923099 0.205154 0.0236919 0.189506 -0.964808 0.468293 0.599743 -0.124814 0.249653 -0.0741394 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0613803 0.381889 0.404639 0.770894 0.416009 -0.133243 0.592229 -0.407211 0.00599383 0.738372 -0.182331 -0.44291 0.0157239 0.271876 -0.580749 -0.648212 -0.49961 -0.945553 0.0956586 -0.265755 -0.540891 -0.762094 -0.513236 0.0427988 -0.679755 -0.647799 0.443225 -0.721389 -0.37818 -0.0645245 -0.462445 -0.316229 -0.857835 0.36405 0.596234 0.897733 0.204183 -0.302396 -0.371921 -0.868699 -0.218304 0.96288 -0.870025 -0.513376 -0.312657 -0.818626 -0.647988 -0.735079 -0.480229 0.789266 -0.800399 -0.303093 -0.079715 0.229431 0.0448008 0.967231 0.243306 -0.75649 -0.329926 0.939093 -0.671928 0.904781 0.654967 0.0228023 -0.762193 -0.175259 0.415033 -0.537187 -0.507114 0.927153 0.667884 -0.866968 0.866472 0.794219 0.431003 -0.126015 0.0644454 -0.866598 -0.904802 0.984441 -0.494853 -0.997422 0.329081 0.86727 0.211636 0.973467 -0.940118 -0.570487 -0.173519 -0.34119 -0.384145 -0.32836 -0.749405 0.744182 -0.54011 0.368081 0.329327 -0.99784 -0.691829 0.422132 0.76678 -0.721479 0.0954749 0.646805 0.853988 0.983143 -0.321079 -0.370222 -0.327088 0.627461 -0.256662 0.28088 0.751915 -0.566078 -0.065895 0.502453 0.721139 0.176718 0.107564 -0.16509 -0.668692 -0.709294 0.900116 0.254266 -0.559149 0.389086 -0.623703 -0.582347 0.500016 -0.232311 -0.447263 0.846638 -0.560213 0.504205 0.17053 0.0905307 -0.450657 -0.185383 0.268466 0.113307 0.357882 0.923216 0.487182 0.0750342 -0.899437 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.842042 -0.195088 -0.842789 -0.761529 0.981527 0.530467 -0.437396 0.684647 0.86924 -0.691556 -0.978859 0.317227 -0.365998 0.672497 0.658526 -0.15935 -0.189031 0.952495 0.576739 -0.740647 -0.0467433 0.386056 0.447216 0.361224 -0.905476 -0.341285 0.0150179 0.406302 0.715572 0.611597 -0.881919 -0.419728 -0.364652 -0.702487 -0.695865 0.598424 -0.282158 -0.223888 -0.88028 -0.870971 -0.40269 -0.0132029 0.0993046 -0.988023 0.302044 0.44883 -0.507822 -0.956797 -0.886522 0.231545 -0.426347 0.38257 -0.145476 0.976494 -0.0648833 -0.49404 0.667356 0.254877 -0.28502 -0.327226 0.307851 0.0475369 0.953067 0.191215 -0.250971 -0.0653757 -0.769079 0.0808943 -0.409229 0.0882939 -0.0448248 0.629289 0.457564 0.27971 -0.918976 0.77875 0.450036 -0.242925 -0.84658 -0.469709 -0.395364 -0.890843 -0.406679 0.949734 0.176528 0.911713 -0.831652 0.431621 0.261236 0.595322 -0.415716 -0.945912 0.0551416 0.764752 -0.818247 -0.272315 -0.791346 -0.160556 -0.467264 0.701887 0.608458 0.346438 0.58238 0.0688515 -0.81202 0.375712 0.596851 -0.720369 0.763213 -0.685555 -0.12972 -0.210789 -0.726783 0.963538 0.185113 -0.810735 -0.01479 -0.574778 -0.286781 0.0635683 0.392405 -0.854921 -0.662334 0.147068 -0.220157 -0.174205 0.144452 -0.198044 -0.524112 -0.748395 -0.267447 -0.987975 -0.894454 0.907388 0.468187 0.817647 0.194675 -0.104632 -0.543779 0.707592 0.499325 0.157349 0.559404 -0.0927854 0.55558 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.364824 0.407204 -0.127177 0.530516 0.389522 0.704267 0.616372 -0.635917 0.141912 -0.893064 0.274062 0.160752 -0.241826 -0.37735 -0.126528 -0.552465 0.713279 0.0794075 0.602692 -0.550916 0.748839 -0.263817 0.0253511 0.0758463 0.748107 -0.562456 0.809703 0.670757 -0.580602 -0.178946 0.461776 -0.932768 0.964181 0.994252 0.39615 0.0965894 -0.621876 0.134619 0.537071 0.558662 -0.57489 -0.168898 -0.669876 -0.597898 -0.873247 -0.658656 -0.0338965 0.302358 -0.276776 0.227591 -0.884431 -0.637715 -0.075215 -0.137742 0.972597 0.437704 0.486094 -0.220294 -0.472966 0.865318 -0.593279 0.75914 0.858633 -0.959656 -0.932649 0.960907 -0.0329344 0.470791 0.587447 -0.782129 0.753908 0.935917 -0.0438532 0.958539 0.160258 -0.55185 -0.937725 -0.346424 -0.345241 -0.473871 -0.346717 0.723285 0.250442 -0.816286 0.688659 0.286477 0.810817 -0.594464 0.839731 -0.647464 0.0648745 0.345683 -0.0976682 0.490636 0.113119 -0.808526 -0.898187 0.174718 0.48736 -0.933884 0.212435 0.399995 0.712331 0.140005 -0.939698 0.492952 -0.95204 -0.937013 -0.384382 -0.306785 -0.142479 -0.642882 -0.913572 -0.398317 -0.507614 0.530132 -0.0665434 -0.395626 0.718829 -0.633542 0.0545634 -0.953376 0.605611 0.509431 0.00144205 0.236473 0.407726 0.649219 -0.572313 -0.869432 -0.541596 -0.596801 -0.431879 -0.590001 -0.145944 -0.88799 -0.442055 0.385846 0.90929 0.441018 0.197415 -0.0507217 -0.480189 -0.531796 0.102723 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.55105 -0.180771 -0.212724 0.754215 0.0876871 -0.242506 0.206716 0.278797 -0.255685 0.698349 -0.851313 -0.214354 -0.180254 0.729674 0.0339061 0.232789 0.770608 0.0570828 -0.164453 0.201137 0.857276 0.232838 -0.227566 -0.497059 -0.171287 -0.465088 -0.921901 -0.620285 -0.683145 0.185495 0.800125 -0.123944 -0.0288154 0.531109 0.369586 -0.330129 -0.0769727 0.95633 0.282317 -0.146685 0.461604 0.869461 -0.0193548 0.960367 0.679995 0.672808 0.592049 -0.00211499 -0.155682 -0.00234643 0.210875 0.264087 0.883961 -0.646162 0.366362 -0.63822 -0.567405 -0.371674 -0.716778 -0.895543 0.608726 0.859561 0.63714 0.411527 0.538454 -0.200231 0.725403 -0.160161 0.175383 -0.337351 0.136881 0.563208 -0.159331 0.116431 0.400365 0.162132 0.780185 -0.25526 0.918732 0.999333 -0.630035 0.937385 0.943346 -0.937489 -0.432409 -0.959317 0.786095 -0.0915426 -0.230489 -0.22281 -0.503584 0.980852 -0.821681 0.000902291 -0.835196 0.852885 0.430578 0.721372 0.101408 0.362185 -0.764105 0.613034 0.077342 0.363346 -0.282003 -0.269521 -0.842251 -0.177164 0.204478 0.228117 -0.0401958 0.429003 0.252763 0.195739 -0.214162 0.579969 -0.463085 0.926192 0.506228 0.180534 0.230401 0.346893 0.233799 -0.538721 -0.291198 -0.157413 0.355438 -0.147352 -0.255566 0.689702 -0.715402 0.560495 0.54555 0.302388 0.132197 0.475122 0.538865 0.700436 0.223964 0.164525 -0.830297 -0.80878 0.83065 0.742217 0.438826 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.65688 -0.17971 -0.386352 0.583478 0.509421 -0.160219 -0.808079 0.624191 0.772094 0.587631 0.309615 -0.295188 0.773608 0.0215621 0.39354 0.235143 0.0474289 -0.862244 0.264331 0.605757 0.953825 0.935737 0.935544 -0.313871 0.774946 0.512434 0.481461 -0.0823055 0.691041 0.330924 -0.153143 0.130711 0.856631 -0.603918 -0.0486041 -0.888726 -0.814151 0.556518 -0.607353 0.222171 0.0276343 0.450429 0.355518 -0.811245 -0.600145 -0.634539 -0.701912 0.959151 0.453843 -0.265221 0.42866 0.487688 0.567161 0.282192 0.802491 -0.531042 0.77244 0.406943 -0.504935 -0.446659 0.996499 0.166474 -0.0655469 0.353618 -0.734614 -0.661091 -0.963507 0.342478 0.0361088 0.88077 -0.902529 -0.80821 0.4131 0.979264 0.483215 -0.608355 -0.629567 0.862204 -0.929322 0.89146 0.773159 0.479854 0.897828 -0.210273 -0.0618962 -0.289697 -0.938472 -0.903677 -0.0955614 -0.101226 0.689614 0.346202 0.615163 -0.962109 -0.172262 0.78924 0.753138 -0.00775516 -0.340925 0.0740052 -0.195025 0.221487 0.536129 0.726871 0.527307 0.448151 0.0685594 0.27842 -0.594168 -0.177815 -0.534626 0.547512 0.0272691 0.312082 -0.836327 -0.155128 0.762985 -0.503117 0.104904 -0.88606 -0.00543256 0.694939 -0.164713 -0.327721 -0.00411342 0.865791 -0.656949 0.653206 0.435605 -0.793379 -0.315552 0.523803 -0.439862 -0.763068 -0.892215 0.549 -0.964413 -0.891988 0.365372 0.807219 0.931274 -0.0707982 0.0951984 -0.000696412 0.295407 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.891594 -0.694318 0.592254 0.0151313 0.311193 0.223979 0.413388 -0.19171 -0.0707451 0.987545 -0.325176 0.903027 -0.73218 0.360551 -0.119245 -0.0518233 -0.891524 0.241574 0.227991 -0.0518658 0.745137 -0.00564824 -0.482297 0.491708 0.624443 -0.528998 -0.387473 0.233824 0.326697 -0.842609 0.679094 -0.112998 -0.746604 0.250879 0.883072 0.144632 -0.843305 0.88569 -0.0382571 -0.805706 0.622796 -0.477164 0.488033 0.471335 -0.136591 0.435129 -0.706136 0.245259 0.34126 -0.234657 0.380273 -0.512136 0.748389 0.36769 -0.0129734 0.198632 0.400802 0.280124 0.0495298 0.446859 0.361655 0.330738 0.708405 0.162288 -0.433622 0.106679 0.961521 0.287965 -0.1757 -0.983594 0.740943 -0.97603 -0.14046 -0.70895 0.942056 -0.573303 0.749569 0.290914 -0.316436 -0.090517 0.943719 -0.670901 0.378015 -0.237724 -0.956417 -0.0565869 -0.5823 -0.240169 -0.0684319 0.363844 -0.407052 -0.886938 -0.759735 -0.86942 -0.340536 0.608977 -0.931152 0.131888 0.644385 0.173507 0.134132 0.420418 0.0339508 0.701511 0.365783 -0.244127 -0.980449 -0.374277 -0.467875 0.456574 -0.353094 -0.44632 0.702283 -0.735231 0.972178 -0.602303 -0.911248 0.657864 0.725766 -0.0511475 0.363598 0.997784 -0.246944 -0.379819 0.374822 -0.361845 0.474398 -0.801225 0.144275 -0.805947 0.717179 -0.0426659 -0.747123 -0.621312 -0.0366231 0.794445 0.524961 -0.972113 -0.302725 0.100111 0.571553 0.0968912 0.449799 -0.221758 0.920381 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.806582 -0.618633 0.638863 -0.629498 0.0313858 -0.499151 0.770543 0.516367 0.577451 -0.789327 -0.215121 -0.461888 -0.19968 0.833206 0.471632 -0.483788 -0.188216 -0.582839 0.979808 0.526823 0.0441451 -0.140443 -0.746921 0.314765 0.221747 0.634337 -0.705558 -0.287297 -0.90692 0.426015 -0.638268 -0.519116 0.591862 0.93129 -0.892887 0.170818 -0.325247 0.188997 -0.179839 0.938247 0.187643 -0.67392 0.919846 0.706941 0.635944 -0.707876 -0.648921 -0.177378 -0.945279 0.379214 -0.417298 0.393719 -0.992373 0.842837 -0.692046 0.783979 0.329269 0.0173213 -0.880938 0.0708079 0.0687797 -0.0195664 -0.852696 0.740479 -0.766523 -0.959382 -0.336332 -0.737645 0.394316 -0.727832 -0.672762 0.882573 -0.601614 0.679898 -0.774994 -0.989497 -0.438802 -0.588507 -0.623588 -0.630049 0.924439 -0.966235 0.290234 -0.239962 0.894095 0.693786 0.356422 0.285405 0.54725 -0.267446 0.807978 -0.753391 -0.242292 -0.202624 0.500619 -0.0899154 0.792374 -0.570591 0.0706503 -0.580885 -0.927 0.431808 -0.0136286 -0.311383 -0.905687 0.426551 -0.460743 0.520336 -0.615923 0.397891 -0.646689 -0.905332 0.0845759 -0.532169 -0.168031 -0.0895374 -0.855494 -0.292525 -0.470486 0.542989 0.0114663 0.714161 0.902363 0.0165285 -0.205207 -0.908901 0.0974278 -0.53093 -0.550289 0.228971 0.52692 0.721819 0.401335 -0.438076 0.243267 -0.790756 0.120927 0.417553 -0.179891 0.576078 0.137144 0.971771 0.550578 -0.428263 0.184793 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.184351 -0.38628 -0.211418 0.698039 -0.0527078 0.139235 0.123407 0.107605 0.517635 -0.101281 -0.234617 0.785724 -0.328546 0.126512 0.279137 -0.538992 -0.83968 -0.4999 0.187917 0.320538 -0.72236 -0.696723 0.176476 0.037195 -0.864099 -0.907081 0.695495 -0.815786 -0.915197 0.288672 -0.288321 0.184364 0.597561 -0.794453 -0.376761 -0.228331 0.445106 0.898787 -0.0911457 0.114261 0.387053 -0.795964 0.236359 0.492926 0.613972 -0.970442 -0.210708 0.626099 0.848672 -0.367682 0.36837 -0.804596 -0.851911 -0.0603334 -0.0237444 0.92771 0.0284568 0.273785 -0.500023 0.111503 0.0299655 -0.370391 0.836776 -0.299282 -0.0245297 -0.271227 -0.505113 0.566062 -0.188008 0.148624 -0.0690013 0.295702 -0.142281 0.691167 0.447253 0.980149 -0.634114 0.438804 0.984751 0.704971 0.445945 0.993937 -0.90238 -0.301361 -0.981055 -0.591195 -0.210329 0.999926 -0.250513 -0.370865 0.870409 0.964621 0.385272 -0.73671 0.117132 0.637809 -0.338317 -0.100299 0.271055 -0.386762 -0.304933 0.999036 0.793029 0.443709 -0.590887 0.968411 0.0804911 0.813605 0.256029 -0.917526 -0.865949 -0.0040006 0.761901 -0.73394 0.665825 0.520366 -0.209236 -0.635562 0.117063 -0.527177 -0.264234 -0.974929 0.364317 -0.92112 0.744346 0.219734 -0.935535 0.456514 0.632781 -0.849832 0.875843 0.297975 0.0590887 -0.895749 -0.858528 0.725582 0.85609 0.312782 0.931401 0.063124 0.925438 -0.164757 0.923076 0.146503 0.279508 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.316778 -0.0888969 -0.0893842 -0.2804 -0.677168 0.837465 -0.721405 -0.649942 0.41732 -0.101653 -0.48341 -0.667387 -0.774736 -0.98102 -0.000695199 0.315786 -0.578515 0.901941 0.917198 -0.658983 0.480914 0.72816 0.17711 0.696131 -0.130444 -0.373045 0.235065 0.736794 -0.706398 -0.425345 -0.779936 -0.378821 -0.845442 0.655934 0.285184 -0.918361 -0.898692 -0.310444 0.374362 -0.0896801 0.747007 0.947606 0.417534 -0.503824 0.227026 -0.367142 -0.55719 -0.685378 0.851015 -0.991872 -0.394982 -0.464518 0.849619 -0.452948 -0.696348 0.483559 -0.816247 -0.669469 0.226633 -0.974288 -0.862545 -0.78806 -0.928757 0.382029 0.756573 -0.28224 0.393803 0.652502 0.605813 -0.106291 -0.428209 -0.910103 -0.102228 -0.141979 -0.240961 0.163512 0.139273 0.755011 -0.529816 -0.621653 -0.118335 -0.853024 -0.77002 0.266072 -0.133108 0.857681 -0.952904 0.544978 -0.559841 0.753279 0.359002 -0.261488 -0.83172 -0.72593 -0.703781 -0.454251 -0.604828 0.648606 -0.884353 0.677835 0.37467 -0.927923 0.390572 0.348175 -0.226358 -0.396665 -0.744978 -0.843232 -0.195015 0.390349 0.595446 -0.332697 0.362553 -0.565935 0.331964 -0.686941 0.590963 0.321437 0.399297 0.988336 0.954913 -0.77961 -0.908471 -0.66689 -0.425643 0.215993 0.200969 -0.309979 0.182684 0.372324 -0.356671 -0.567675 -0.906303 -0.23738 0.358356 0.887689 -0.608865 0.808745 0.572714 -0.393958 0.745042 -0.0772772 -0.797867 0.251741 -0.98275 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.853715 0.678017 -0.570151 -0.521566 0.0401975 -0.399826 0.120111 0.700902 0.0618538 -0.423708 0.742842 0.456074 0.301365 0.236401 0.304648 -0.651219 0.150372 0.377468 -0.82405 -0.537926 0.366552 0.192285 0.954441 0.68378 -0.0967134 -0.172781 -0.256935 -0.597412 0.535119 0.0350525 -0.148622 0.144393 -0.414368 0.680831 0.868588 0.484605 0.64342 -0.31757 0.508756 0.770055 -0.163231 0.862808 -0.685258 0.0778609 0.142702 -0.231009 0.323088 -0.69431 -0.0772203 0.551452 -0.732002 -0.0395276 0.166474 0.269068 0.706409 -0.554897 -0.153736 0.158758 0.246944 0.386018 -0.196894 0.80126 0.776507 0.752857 -0.728621 0.0652671 0.943657 0.0453992 -0.97612 0.354936 -0.585629 -0.669908 0.85615 -0.686455 -0.174918 -0.549971 -0.474789 -0.431899 0.489082 0.870467 -0.996561 -0.382402 -0.475983 -0.475018 -0.0432178 0.804479 0.40264 0.700631 0.826238 0.396328 0.449874 0.0778279 0.0537381 -0.823518 -0.871745 0.578066 -0.439157 -0.91022 -0.0689787 0.674936 -0.347263 0.30261 0.797983 0.749362 -0.747808 0.032686 0.0534524 0.691604 -0.0751073 -0.0293962 -0.0626551 0.95545 0.245133 -0.054207 0.942239 0.21448 0.772798 0.417908 -0.22213 0.664999 0.643822 0.715496 -0.652079 0.500656 0.522529 0.150447 0.568292 -0.722162 0.586264 -0.494989 -0.138994 -0.134265 -0.650607 0.551959 0.997931 -0.052149 0.882536 0.790027 -0.0153203 0.51224 -0.78143 0.49844 -0.723835 0.504424 -0.142092 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.143661 -0.514315 -0.0930275 0.486839 0.296028 -0.665278 0.676839 -0.3698 0.763571 -0.662632 -0.857175 -0.534198 -0.262059 -0.419101 0.168217 -0.779524 0.547641 0.201669 -0.544238 0.990338 0.611024 -0.515444 0.92762 0.510626 0.0982278 0.915001 0.422218 0.217476 -0.877069 -0.902003 0.0352585 0.589115 -0.74208 -0.131017 -0.00630364 0.0546976 -0.697347 -0.311579 -0.700393 0.48847 -0.27967 -0.417223 -0.269711 0.970971 -0.887485 0.0325883 -0.287944 0.531533 -0.519331 -0.389364 -0.0370717 0.935676 -0.0927002 -0.0115525 -0.163495 0.140802 0.456275 0.621876 -0.124726 -0.273307 0.526466 0.308656 -0.413314 -0.565713 0.062293 0.958249 -0.710687 -0.514283 0.444268 0.81907 0.112607 0.583579 0.213222 -0.383741 0.470563 0.75791 0.199679 0.00249435 -0.0774348 0.553674 -0.398842 0.665008 0.79581 -0.820658 -0.796722 -0.513782 0.86228 0.337846 0.174739 0.830875 0.522713 -0.758763 -0.528415 0.931915 0.696611 -0.0574033 -0.776895 0.725805 0.603575 0.288803 -0.0833826 0.588493 0.796194 -0.375486 -0.797431 -0.418848 0.418921 0.813199 -0.556137 -0.98678 -0.805651 -0.582628 -0.23475 0.56277 0.467336 0.524427 0.0475666 -0.548503 -0.693209 -0.770421 -0.473074 -0.954798 0.715635 -0.325801 0.266652 -0.373923 -0.51894 0.170871 -0.169219 -0.059943 0.538181 -0.792274 0.243587 -0.0269056 -0.203022 -0.186231 0.0238951 -0.394909 0.756693 -0.256995 0.690317 0.152937 0.417751 -0.862731 0.0783554 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.898603 -0.921714 0.747552 0.109107 -0.236892 0.552705 -0.680445 -0.235631 -0.247429 -0.539905 -0.184637 -0.694999 -0.499174 0.766358 0.538242 0.595396 -0.791218 0.352752 -0.948155 0.772533 -0.322884 -0.914109 0.259537 -0.211384 -0.912406 0.906188 0.134572 -0.397313 0.0591905 0.201743 0.219488 0.244751 -0.925591 -0.807936 0.34976 -0.242388 -0.566074 -0.798921 -0.845065 -0.333281 -0.953468 -0.204412 -0.862439 -0.615803 0.699693 0.19524 -0.312872 0.592115 0.705514 0.356121 0.296574 -0.595935 0.931943 -0.0735228 -0.894051 0.599488 -0.405963 0.974935 -0.275065 0.978055 0.178749 0.226371 0.613111 0.554047 -0.135978 0.623063 -0.179631 0.939811 -0.601397 0.320056 -0.812665 -0.465234 0.820396 0.388163 0.856111 -0.273064 -0.453421 0.433568 0.0869211 -0.19055 0.410073 -0.985485 -0.223987 -0.814944 -0.952086 -0.0310922 -0.780906 -0.901159 -0.0514186 -0.310979 -0.884504 -0.231276 0.945199 -0.0421496 -0.408752 0.105877 -0.525442 0.900716 0.329511 0.0862663 -0.121821 0.789012 -0.810353 0.732685 0.466186 -0.669475 0.3575 0.600602 0.369647 0.759446 0.00498706 -0.182458 -0.563355 -0.306444 -0.411698 0.587108 -0.472448 -0.425717 0.974309 -0.795271 -0.116767 -0.495346 0.719039 0.892581 -0.384215 0.490907 0.670649 -0.408433 0.749007 -0.0940194 0.832647 -0.430985 -0.296268 -0.309513 -0.61173 -0.145967 -0.174913 0.228899 -0.902038 -0.55989 -0.0704464 0.00679945 0.278351 0.241895 -0.477668 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.158142 0.0998919 0.883721 0.701891 0.688349 -0.915821 -0.198491 -0.0306018 -0.324061 -0.488914 0.828294 -0.869339 -0.979077 0.659526 0.659487 -0.0084627 -0.23253 -0.124358 -0.0785168 0.368839 -0.921877 0.00830726 -0.379819 0.389129 0.0892319 -0.279074 -0.388764 0.0428067 -0.548538 0.714757 0.922057 -0.993277 -0.00267715 -0.994806 0.28759 -0.470386 0.225705 -0.574856 0.392065 -0.567373 0.169176 -0.666391 -0.0341474 0.0847428 0.272269 0.0306704 -0.523225 0.163578 -0.742809 -0.387331 0.134406 0.963191 0.353857 -0.722849 -0.91704 -0.697771 0.565502 0.390937 0.483845 -0.0204361 0.530198 -0.966453 0.818951 0.114128 0.146301 0.882989 0.387772 -0.709044 -0.908237 -0.737161 0.539313 0.226742 0.85331 -0.421333 0.655568 0.13275 -0.878225 -0.332154 -0.517551 -0.475243 0.5906 0.221487 0.531841 0.644163 0.45559 -0.892122 0.112113 0.288786 -0.374617 -0.19568 -0.789056 0.335805 -0.131869 -0.32809 -0.205337 0.899355 -0.533991 -0.778823 0.315041 0.895334 -0.117209 0.0653926 -0.947027 -0.679167 -0.763314 0.986592 -0.356405 -0.103764 0.0388445 0.85903 -0.283199 0.271357 0.704323 -0.447594 -0.716455 0.538446 -0.337286 -0.764343 -0.320563 0.294273 -0.157213 -0.27639 0.717889 -0.438253 0.277507 0.0580873 0.273503 0.76039 -0.120694 -0.508313 0.778917 -0.740063 -0.230848 0.132248 0.687156 -0.974116 0.0258239 0.0218807 -0.250969 -0.0348841 -0.297857 -0.0807704 0.491685 -0.250549 -0.979835 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0848864 -0.685499 0.818507 0.644547 0.902844 0.0962217 -0.801937 -0.153637 -0.183179 -0.683411 -0.0928431 -0.414545 0.737109 0.593886 -0.56293 0.834836 -0.915378 -0.75818 -0.738472 0.498801 -0.650698 -0.276581 -0.501754 -0.979691 0.337641 0.732216 0.356307 0.454482 0.476909 -0.590997 -0.893702 -0.442366 -0.849494 0.547441 0.839211 0.612766 0.764553 -0.162454 -0.369188 -0.94552 0.638073 0.0921903 -0.558431 0.443949 -0.54708 -0.771833 -0.205584 0.750268 -0.240072 -0.895543 0.616803 0.606558 0.421832 -0.261537 0.354243 -0.23435 -0.724554 0.428227 -0.790726 0.265717 -0.0889748 0.600904 -0.603094 -0.205416 -0.427512 0.812483 -0.593938 -0.311025 0.603438 -0.0197409 0.215249 -0.313395 0.76678 -0.727506 0.811378 0.830707 -0.306613 0.75237 -0.919652 -0.594577 0.94708 -0.430771 0.0298081 0.98428 0.801308 -0.409394 -0.68642 -0.663006 0.85199 -0.608307 0.179961 0.604859 -0.137215 -0.173494 0.0851278 0.742251 -0.99525 0.840581 -0.358862 0.604687 0.982415 -0.551816 -0.364021 -0.100402 0.547297 0.4154 -0.377146 -0.69252 0.808989 0.68292 -0.167608 -0.985479 -0.952894 0.703274 -0.076538 -0.373474 -0.98343 -0.511344 -0.163218 0.798478 0.013982 0.994853 0.493685 -0.638375 0.831188 -0.217074 -0.369823 0.387107 0.106683 -0.984383 -0.522844 0.568287 -0.793882 -0.771912 0.469866 -0.968073 -0.396011 0.23883 0.0240088 -0.484054 0.496895 -0.683949 0.871927 0.470555 0.616848 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.637415 0.972167 -0.787413 -0.043013 -0.919216 0.732846 0.938153 -0.459077 0.298521 -0.755227 0.90159 -0.981553 -0.952982 -0.761635 -0.793571 0.444738 0.719477 0.248226 -0.0678779 -0.824607 0.831737 -0.989206 0.416194 0.976769 0.55233 -0.986698 0.560817 -0.347894 0.943295 -0.0414969 0.561454 0.360442 -0.0565316 -0.126667 -0.899343 0.739824 0.222652 0.104933 -0.396865 -0.104447 0.561208 0.220433 0.821221 0.258787 -0.563428 0.461043 0.754349 0.349758 0.387477 0.324201 0.843727 0.524478 0.909892 0.54807 -0.587599 0.218414 0.886679 0.40627 0.185539 0.346433 0.50324 -0.0412622 0.506962 0.505578 -0.745453 -0.835661 -0.951947 0.634428 0.825024 0.174647 -0.69979 0.625184 -0.536467 -0.403916 -0.618844 -0.903133 -0.949353 0.219509 -0.706656 -0.763627 -0.280508 -0.498599 0.0480307 -0.748039 -0.295145 -0.501843 -0.473087 0.823059 -0.852944 0.572734 -0.0586922 -0.439189 0.543515 0.856484 0.934658 0.790874 0.215023 -0.115242 -0.870717 -0.14729 0.502193 0.35872 -0.986393 -0.299027 0.251376 0.873174 -0.559753 0.231038 -0.938917 -0.375762 0.568889 -0.681696 0.731863 0.416093 -0.726719 0.0373629 -0.0411273 0.773103 -0.464789 0.286799 0.227338 0.867181 0.704747 0.687738 0.811146 0.933113 0.822589 -0.742926 -0.354551 -0.940946 -0.479385 0.973997 -0.0301101 -0.0601974 0.261587 0.487999 -0.195041 -0.0530931 -0.33563 -0.930253 -0.753921 0.842393 0.104466 -0.234895 0.116106 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.612917 0.699813 -0.239375 0.823271 0.723879 0.235747 0.196868 0.761403 0.891892 0.0217385 -0.640751 0.901506 -0.382989 -0.898553 0.0157412 0.561906 -0.053396 0.573818 0.156979 0.342731 0.285186 -0.886367 0.827786 0.604114 -0.663898 -0.137214 -0.147839 -0.734003 -0.383503 0.459883 -0.748415 -0.610649 0.816939 0.300957 0.181803 -0.440708 -0.980592 -0.805836 0.319804 0.950232 0.554719 -0.833777 0.710601 -0.932953 -0.148976 0.15596 -0.777702 -0.835587 0.291961 0.9874 -0.776277 -0.890685 0.25939 -0.43966 0.640745 0.996453 -0.606693 -0.683638 0.103839 -0.781147 -0.736475 0.0584759 0.804843 0.990729 -0.811163 0.786281 -0.978445 -0.730296 -0.0872788 -0.895584 -0.0832815 0.288333 0.0145515 0.566863 -0.740678 -0.571486 -0.959563 0.621574 0.787179 0.11679 0.88319 -0.23241 -0.115235 -0.749847 -0.67769 0.070789 -0.248642 -0.929178 -0.693353 0.808429 -0.740138 0.493939 -0.371877 -0.132832 -0.509312 -0.00230559 -0.750021 0.393354 -0.894121 0.504369 0.928151 -0.569817 -0.915381 -0.8114 0.804568 0.38261 0.528405 0.906204 0.575779 -0.883081 0.0575663 -0.483344 0.444615 0.640355 0.445579 0.844649 0.0159468 0.0185155 -0.810809 0.731629 0.491544 -0.613659 0.237338 0.932919 -0.423632 0.0133081 -0.330091 0.157335 0.325881 -0.917308 0.803976 0.43254 -0.301626 0.568621 0.813258 0.424101 -0.14189 -0.750257 0.429095 -0.203798 0.762939 0.711428 0.972486 0.563805 -0.132672 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.250318 -0.908653 0.274596 -0.867098 0.678501 -0.435986 0.384709 -0.191496 -0.475515 0.0274358 -0.885784 0.848809 0.68483 0.517895 0.954369 0.748713 0.215691 -0.143965 -0.888569 0.325034 0.620459 -0.476555 0.403245 0.988743 -0.797998 -0.18198 0.794105 -0.179765 0.529049 0.685714 -0.764267 0.22169 0.322929 -0.368535 -0.836891 -0.48569 0.445528 -0.386033 -0.316913 -0.843309 0.704479 -0.513486 -0.632227 0.740845 -0.427002 -0.25423 0.102044 -0.667975 -0.417526 -0.179251 -0.220577 -0.428608 -0.557677 0.372671 0.554232 -0.348886 0.269074 0.333184 -0.178378 -0.00132359 -0.245649 -0.614405 -0.300991 -0.759029 -0.997319 0.0656586 -0.475994 -0.0346324 -0.0660608 -0.283344 -0.154551 0.462283 -0.406894 -0.663031 0.809166 -0.240233 -0.995619 0.698847 -0.495258 0.824818 -0.881144 -0.697116 0.55765 0.0990854 0.769281 -0.776238 -0.729207 -0.296309 -0.323508 -0.0417025 0.802732 -0.421408 -0.601832 -0.991369 0.0595002 0.0203506 0.0325521 -0.896037 0.30847 0.458345 -0.587262 -0.985826 0.244891 0.63476 -0.442293 -0.135587 0.372195 -0.888132 -0.99138 -0.470188 -0.457151 0.664346 -0.336965 0.621842 -0.699385 -0.566939 -0.549922 -0.53593 0.619512 0.137072 -0.235697 0.637548 -0.728582 0.72514 -0.579273 0.152535 -0.348897 0.0920684 0.739498 -0.149917 0.656164 -0.488834 -0.477663 0.0446579 -0.402335 -0.419269 -0.59782 0.434946 0.145708 0.906919 0.589209 0.832492 -0.306496 0.717258 0.957439 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.322387 -0.3508 0.111854 -0.0768724 0.00562725 0.577125 -0.253745 -0.687965 -0.631432 -0.473639 -0.448512 -0.14597 0.682953 0.393324 0.590872 0.791758 -0.924471 0.416902 0.869328 0.798303 -0.919357 0.368781 0.107716 0.37488 0.605072 -0.558029 -0.786069 0.533495 0.455182 0.248833 0.131509 0.273204 -0.267535 -0.468082 0.942128 0.340065 -0.527462 0.943242 -0.928725 0.911639 -0.0813036 -0.470087 -0.751769 -0.988542 -0.426048 -0.597111 0.347181 -0.92232 0.566041 -0.556395 0.664937 -0.411517 -0.366008 0.503854 0.282267 0.0571677 0.817926 0.884063 0.444192 -0.458037 -0.223662 0.907103 -0.315306 0.658458 0.710538 0.0174365 -0.94482 0.41499 0.735806 0.684669 -0.762436 -0.26017 -0.681186 -0.690264 0.725729 -0.670276 0.672254 0.571956 0.85842 -0.530437 0.95151 0.0326557 0.844375 -0.581278 0.458685 -0.888277 0.726837 -0.049246 0.322374 0.135684 0.440502 -0.491013 -0.463153 -0.217413 -0.0584507 -0.380356 -0.644176 -0.667372 -0.520426 -0.792132 0.638644 -0.306827 -0.839902 -0.238259 -0.415043 0.371127 -0.461674 0.63912 -0.306384 0.611725 -0.742487 -0.986885 -0.582566 0.814876 -0.378311 -0.280483 -0.07178 -0.407155 0.943812 0.64845 0.492217 0.685098 0.448249 -0.286745 0.681523 0.353081 0.230109 -0.565218 0.3826 0.359277 0.374603 -0.0552337 -0.312432 0.957566 -0.19136 -0.189542 0.373823 0.850249 0.131168 0.536052 -0.569285 0.0280614 -0.371679 -0.814389 0.565163 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.760162 0.575115 -0.035845 -0.447445 -0.201999 0.999021 0.540629 0.350041 -0.862527 -0.498344 0.337171 -0.620094 -0.932776 -0.304583 -0.174973 0.150173 0.819962 0.0881216 0.0334848 -0.429898 -0.346652 0.533499 -0.450268 -0.793364 0.581329 -0.636768 0.441964 0.659203 0.247857 -0.356953 0.182474 -0.996292 0.765336 0.263869 0.896819 0.901524 0.212516 0.217579 -0.967454 -0.00489848 0.215442 0.759109 0.337655 -0.174961 -0.0301671 -0.336838 -0.0808045 0.899954 0.481718 -0.0422854 0.437221 -0.208967 -0.499926 -0.481924 -0.0588027 -0.989237 -0.106529 -0.432101 -0.327139 -0.22901 -0.96297 -0.631949 0.833378 0.584063 0.354508 0.221922 -0.160287 0.0538422 0.92519 -0.331438 -0.479953 -0.57098 -0.464227 -0.266129 0.230081 -0.172447 0.933177 0.709522 -0.313242 0.607734 -0.732108 0.776848 0.052728 -0.922975 0.246976 0.00498847 0.581937 -0.658699 0.177283 0.0638474 -0.0221068 -0.357693 0.255589 -0.309923 -0.88374 0.98892 0.779792 -0.0280379 0.766379 0.528121 0.122488 -0.0556477 -0.0577384 0.585571 -0.998445 0.70744 -0.722664 -0.108493 0.426748 0.0690036 -0.257321 -0.796406 0.797333 0.772994 -0.289617 0.409964 0.267994 0.167821 0.564603 -0.711983 -0.299749 0.120269 -0.644581 0.522685 0.767053 -0.139923 0.316654 0.0026424 0.641452 0.924102 0.386821 -0.451667 -0.921647 0.743678 0.964832 0.397233 -0.903877 0.547537 0.447608 0.943608 -0.785683 -0.973843 0.625772 -0.643138 0.777151 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.419846 -0.354068 -0.819006 0.964865 0.48679 -0.517304 -0.335297 0.660546 -0.20881 0.526725 0.660806 0.172219 0.486696 -0.103146 0.425767 -0.13468 0.432258 0.966942 -0.601201 -0.384275 -0.513154 -0.575268 -0.526352 -0.393638 0.131619 0.12079 0.121187 0.791539 -0.603929 -0.232665 -0.394427 0.859881 0.0227151 -0.227242 0.740027 -0.36765 0.910017 0.662645 -0.918772 0.197997 -0.268778 0.655078 -0.107744 -0.85689 0.245632 0.337445 -0.558256 -0.602113 0.28645 0.367344 -0.0516916 -0.780246 0.40146 -0.657866 -0.757651 0.166199 -0.699681 0.461579 -0.246782 0.340094 -0.0345887 0.666988 0.0720451 0.862347 -0.53176 0.703631 -0.0700187 -0.804133 0.944405 0.622703 -0.225987 -0.156873 -0.560323 0.656837 -0.535135 -0.0121415 -0.0623963 -0.695171 0.266289 -0.486082 0.414654 -0.917604 -0.162747 0.710655 -0.0175657 0.773801 -0.734345 -0.140972 0.686035 0.196312 -0.580199 0.598737 0.975535 -0.190115 0.730328 0.618455 0.365265 -0.983501 0.296121 0.897852 0.193114 -0.34122 -0.88018 0.806627 0.985274 -0.50118 0.672383 0.734851 0.641552 0.556405 -0.498031 -0.413613 0.405109 0.668859 -0.488162 -0.53356 0.455559 0.584889 0.230958 -0.281264 0.788967 0.166447 -0.517723 0.626371 -0.587709 0.368887 -0.123415 -0.243471 -0.0136376 0.792888 0.0683272 0.375034 -0.802929 -0.821049 0.629378 -0.0466133 0.571006 0.903834 0.743864 0.121054 0.550521 0.602739 0.228167 0.809497 -0.776414 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.762235 0.923262 -0.740731 0.54091 -0.923192 -0.0892272 0.358417 -0.0811398 0.28395 0.343576 0.479427 0.886126 -0.0684589 0.333126 -0.298283 -0.371066 0.414398 -0.382574 0.901477 0.0997499 0.561175 -0.0688539 0.7786 0.0781028 0.982883 -0.625924 0.441878 -0.975256 0.881431 -0.492223 0.827082 -0.130677 -0.623355 -0.923606 0.12414 -0.41289 -0.469819 0.598137 0.357416 0.711325 0.418478 -0.891709 0.656199 -0.329515 -0.977176 -0.342898 -0.402911 0.706883 -0.959922 0.429554 -0.167652 0.350054 -0.714077 0.307446 -0.845153 -0.316738 0.591309 0.122859 0.889363 -0.476902 0.703603 -0.540603 0.091742 -0.0924075 0.907571 -0.454438 0.265172 0.740994 -0.120859 0.730575 0.773411 0.724688 -0.16279 -0.0181831 0.761905 -0.12667 -0.730981 0.966931 -0.166016 -0.0339542 -0.316386 0.668866 -0.410866 0.698199 0.910521 -0.903243 -0.575054 -0.68966 0.970254 -0.479246 -0.569839 0.59437 -0.427231 -0.477483 0.951571 -0.938443 -0.408768 -0.17199 -0.643072 -0.110643 0.415193 0.718232 -0.0488066 0.516941 0.776739 0.993074 -0.870397 -0.527227 0.998618 0.00695671 0.921441 0.657555 -0.470677 -0.67019 0.120242 0.904291 0.421501 0.165071 0.349173 0.547555 0.757 0.895449 -0.196086 0.383172 -0.0197982 -0.748584 0.544919 0.45996 -0.408742 -0.539587 -0.431188 0.0546306 -0.795392 0.369183 0.105733 -0.10092 0.404176 0.985504 -0.640275 0.894029 -0.0476037 -0.075368 -0.710035 0.447768 -0.363542 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0527654 -0.828214 0.211264 0.711307 0.940228 0.409433 -0.655476 -0.587464 0.488343 -0.4194 -0.848502 -0.764799 0.0249033 0.549806 0.591046 -0.286017 0.917942 -0.156686 0.572886 0.494943 0.499553 -0.0183273 -0.0265707 -0.574516 0.107944 0.214669 -0.0622338 0.0363574 -0.941045 -0.138951 0.649097 -0.627471 0.0966285 0.0344279 0.630457 0.08818 0.0414244 0.220105 -0.689451 0.397551 -0.360471 -0.435246 0.818212 -0.316682 -0.479514 0.815218 -0.624365 0.30136 0.961098 -0.830165 -0.583243 -0.557762 -0.305942 0.02494 -0.83418 -0.069649 -0.591107 -0.730175 -0.0474296 0.850442 -0.623315 -0.0585826 -0.598224 -0.348731 0.874003 -0.629411 -0.502939 -0.891414 0.00165176 -0.238827 0.0290696 0.573334 0.0184 -0.750856 0.355478 0.510647 0.439739 0.697924 0.0160573 -0.125367 0.954103 -0.398948 0.874132 -0.4701 -0.964114 0.12819 0.49035 -0.692491 -0.693504 0.277036 0.151513 0.486107 -0.00514662 -0.49917 0.455626 -0.301152 0.530496 0.0466649 0.296844 -0.941583 0.819104 0.674775 0.942901 -0.656485 0.455235 -0.858773 0.596264 -0.585538 0.855107 -0.216604 -0.45561 0.555384 0.343014 -0.963379 0.494041 -0.647477 -0.148895 -0.477462 -0.701439 0.920932 0.108796 0.540259 0.125166 -0.336158 0.185331 0.864356 -0.763309 -0.938792 -0.275133 -0.162622 0.809202 0.261871 -0.726317 0.794728 -0.999467 -0.035661 0.645615 0.847253 -0.221595 -0.340734 -0.710061 -0.0024987 0.00443041 0.461838 0.112396 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.953439 -0.448601 0.369368 -0.0354576 0.0637033 0.660846 0.846821 0.517883 0.053206 0.232538 0.270116 -0.161717 0.0246815 0.821934 0.248722 0.275705 -0.230197 -0.912745 -0.504664 0.109258 0.299885 0.159052 -0.816151 0.94893 0.662768 -0.860922 0.480936 -0.91657 -0.796535 0.644126 -0.166356 0.0629302 -0.331631 0.280102 -0.32144 -0.444299 0.669383 0.314485 -0.458648 -0.503144 -0.348431 -0.0809001 0.311885 -0.155303 -0.174173 0.68037 0.983537 0.305931 -0.221961 -0.498098 0.461268 0.532686 0.84774 -0.031127 0.84839 0.882933 -0.549138 0.639261 0.0674325 -0.661754 -0.0922125 0.184628 -0.951786 -0.674319 0.724233 0.176791 -0.678926 -0.704887 0.958935 0.828262 0.591346 0.751942 -0.103226 -0.921104 -0.998793 -0.710059 0.031139 -0.646156 0.0535129 -0.609337 0.880147 0.637982 0.567128 -0.274905 -0.320344 -0.0290868 -0.86125 0.96945 -0.457736 0.823469 0.0482233 0.489714 0.624734 -0.0912614 0.169189 -0.436358 0.124522 0.836373 0.916947 -0.874688 -0.87482 0.898938 0.448949 -0.50737 0.628004 0.856253 -0.960135 -0.989396 -0.773568 0.646606 -0.486416 0.813634 0.748934 -0.667629 -0.842757 -0.218692 0.442513 -0.684385 -0.464246 -0.579766 -0.121597 0.323025 -0.922097 0.315936 -0.0667355 0.376592 -0.621908 -0.402943 -0.267445 -0.948499 0.582149 0.180633 -0.100548 0.0955926 0.62481 -0.811587 -0.350147 -0.921337 -0.909708 0.541828 0.495585 -0.70358 0.937306 -0.704337 0.214979 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.849684 -0.639832 0.338065 -0.143487 0.415627 -0.554356 0.940098 0.228615 0.339858 -0.0104939 -0.370917 -0.0101045 0.174228 0.252893 0.371548 0.60632 0.415592 0.860091 -0.454135 -0.650381 -0.945712 -0.589663 -0.45932 0.2058 0.873842 0.654401 0.518459 -0.252114 0.721467 -0.305175 0.929699 -0.542991 -0.0547774 -0.64428 -0.422216 -0.186359 -0.128685 -0.811236 -0.442334 -0.306579 -0.676196 -0.819589 -0.827582 0.827812 -0.963699 -0.884161 -0.100111 -0.570254 -0.261618 0.980684 0.357679 -0.48102 -0.504526 0.428039 0.05268 -0.607299 -0.872365 0.160496 -0.547425 -0.576119 -0.83848 -0.336042 0.145289 -0.127359 -0.522472 0.813746 0.624132 -0.21359 0.192441 0.352917 -0.527403 -0.0633411 -0.574201 -0.593604 -0.702758 0.740892 0.17567 0.478683 -0.769807 -0.145726 0.785849 -0.23662 -0.87502 -0.463083 0.97207 -0.419258 -0.461068 0.837474 -0.571561 -0.227451 -0.763181 -0.786227 -0.121882 -0.474806 -0.0585135 0.562849 -0.191709 -0.0540279 -0.0477392 -0.3522 0.579714 -0.741354 0.057379 0.368061 0.00321804 0.085604 0.745605 -0.611565 -0.578468 -0.312855 -0.159594 -0.288217 -0.06865 0.199555 -0.0856436 0.588386 -0.99113 0.0767599 0.103929 0.733224 -0.700621 0.665899 -0.229231 -0.6799 0.915555 -0.26866 0.62881 0.407048 -0.750686 -0.777598 0.907048 0.758944 -0.42035 -0.820603 0.127932 0.149736 0.608676 0.0163321 0.49277 -0.0170967 0.655941 0.392076 -0.375251 -0.841201 -0.0669418 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.888076 0.454887 -0.717625 0.881909 0.247845 -0.468251 0.0984008 -0.178332 0.767508 -0.499492 -0.970004 -0.346653 0.163282 0.677288 -0.459445 0.478309 -0.67293 0.425244 -0.573284 -0.767929 -0.826086 -0.181147 -0.806173 0.437016 0.790355 -0.756944 -0.0816369 -0.181517 0.976706 0.922737 0.0121129 0.916676 0.149253 0.144233 -0.513698 -0.346491 -0.183935 -0.164717 0.234985 0.0889751 -0.0891674 0.122095 0.748621 0.476908 -0.0973217 0.773033 0.652506 -0.281935 0.570264 -0.777457 0.281193 0.908573 -0.786627 -0.0719754 -0.867524 0.461656 -0.951846 0.319445 0.910811 0.000516071 0.673613 -0.588601 -0.623651 0.301955 0.954698 -0.386956 0.431143 0.216793 -0.36175 0.0753909 -0.905111 -0.208574 0.499656 -0.285708 -0.875719 0.887708 0.660585 -0.446708 -0.688029 -0.756119 0.918567 -0.707713 0.309223 0.897355 -0.312861 -0.547705 0.549897 -0.0405423 0.367112 -0.0178594 -0.388105 0.788472 -0.157507 0.784639 -0.570999 -0.77772 0.856054 -0.296892 0.137705 0.408525 0.0801464 -0.732568 0.00244073 -0.629114 0.718055 0.493193 -0.665497 -0.901223 -0.81579 -0.87763 -0.329945 0.617225 -0.295003 -0.1197 0.209641 -0.562604 0.32231 -0.932146 -0.575313 0.718826 -0.687153 -0.979285 -0.849833 0.852208 -0.946146 0.131016 -0.0191477 0.184337 -0.531243 0.781288 0.14126 -0.543822 -0.709487 0.749081 -0.802274 -0.592335 -0.261271 0.82537 -0.0113619 -0.960037 0.662093 -0.195665 -0.540725 0.0298224 -0.774996 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.509703 0.499106 0.474338 0.191682 -0.401357 0.389998 0.700922 0.40371 -0.853122 -0.416595 0.293715 -0.425763 0.37358 -0.786583 0.159547 -0.182702 -0.236904 0.546639 -0.430634 0.932556 0.301709 0.158346 -0.012098 -0.291985 0.0836869 -0.66166 -0.928859 0.322102 0.266888 0.350803 -0.389724 0.155124 0.929478 -0.105241 -0.335393 -0.504923 -0.312743 -0.677476 -0.419737 -0.216518 0.112613 -0.628724 -0.651197 -0.204757 -0.221098 0.836168 -0.701368 0.581057 0.347842 -0.925901 0.543163 0.497654 -0.811702 0.510762 -0.547864 -0.182388 0.608957 0.738842 -0.290487 -0.209631 0.732044 -0.529197 -0.212629 0.350669 -0.308136 -0.846463 -0.504774 0.270953 -0.0850213 -0.952657 0.688962 -0.616397 0.215328 -0.983021 0.662647 -0.132503 0.927502 -0.625262 0.199327 -0.0637295 -0.836727 0.890182 0.518294 -0.0392054 0.472588 -0.65473 -0.765123 -0.114388 0.355546 -0.449286 -0.19523 -0.911547 -0.367025 -0.58496 0.574158 -0.119003 -0.0759277 -0.116689 0.812519 -0.00118415 0.0978826 0.63923 -0.776178 0.940188 -0.782595 -0.168162 -0.871618 -0.637453 0.601223 -0.626268 0.309558 0.733732 -0.17207 0.0243947 0.0024717 -0.458141 0.0295077 -0.0641347 0.0879911 0.866313 0.128682 0.764966 0.79093 -0.832086 -0.863384 -0.900319 0.340873 -0.956064 -0.485013 0.883428 0.195231 -0.694508 -0.528374 0.351676 -0.748449 0.415426 0.916983 -0.263198 0.435643 -0.146028 -0.298943 -0.337577 0.34715 0.546207 0.0979233 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.202615 0.651778 0.430925 0.553567 -0.201943 -0.0629263 0.39684 -0.307251 0.0249847 -0.082802 0.347239 0.053456 0.434391 0.803965 0.246084 -0.0578909 -0.972575 -0.0674851 -0.222564 -0.625545 0.458806 -0.84392 0.238629 0.639386 0.157934 0.396837 -0.354601 0.221366 0.504999 -0.486059 0.81167 -0.268687 0.184037 -0.885453 0.198854 0.135405 -0.255054 -0.691615 0.0341106 -0.702462 -0.286812 -0.447541 0.185612 -0.416093 0.73215 -0.750138 0.431221 -0.469911 0.205252 -0.329123 0.421626 0.264933 0.726958 -0.0108681 -0.660704 -0.45815 -0.132639 0.735971 -0.543074 0.55288 0.257058 0.368544 0.120572 0.44871 -0.52632 0.132263 0.944831 -0.22398 -0.424548 0.618824 0.577556 0.977367 0.599087 0.861168 -0.353449 -0.421643 -0.557436 -0.820252 0.0175564 -0.929326 0.815419 0.752009 -0.981457 0.653146 -0.576752 0.530649 0.624812 -0.788061 -0.947556 0.428262 -0.207411 0.0401432 0.686899 0.712537 -0.395355 -0.739341 -0.0981759 -0.0424391 0.725782 0.219895 -0.219723 -0.878698 -0.275575 0.415147 -0.630637 0.887304 0.917272 0.591922 0.428669 0.638017 -0.855004 -0.0507792 0.554225 0.862054 0.540491 0.0399315 -0.871454 -0.521296 0.577645 0.474379 0.884128 -0.464013 -0.673515 0.229995 -0.482193 -0.220152 -0.0971304 -0.471411 -0.996831 0.262387 -0.0566405 0.0426196 0.307406 0.565277 0.618393 -0.676174 -0.453894 -0.592893 -0.757903 -0.0776345 -0.802226 0.986829 -0.363517 0.371142 -0.215457 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.770628 -0.962947 -0.255125 0.114802 -0.530883 -0.55894 -0.101131 0.286616 -0.841976 0.903578 0.431843 -0.886446 0.286994 0.395206 -0.946869 0.807819 -0.101854 0.937848 -0.790183 0.338632 -0.695931 -0.412445 -0.108836 0.784731 -0.876123 0.902782 -0.752131 -0.851824 -0.733629 -0.933057 -0.3996 0.902138 -0.230565 0.566622 0.276634 0.437496 -0.140664 0.601228 0.253636 0.418389 0.996059 0.448671 0.372516 -0.226685 -0.761554 -0.421767 0.0235983 0.95707 -0.160199 -0.694575 0.508364 0.078928 0.394056 0.626245 -0.863697 -0.0750699 0.300188 -0.743321 -0.993222 0.919488 -0.160305 -0.248506 -0.642642 -0.876245 0.94815 -0.434896 0.704487 0.306082 0.328152 -0.751361 -0.122969 -0.742929 -0.40669 0.754174 -0.322187 -0.553309 0.674407 -0.766447 0.850228 -0.108879 0.33218 -0.977278 0.773294 0.717632 -0.645284 0.52275 -0.0571896 0.902183 0.918653 0.101531 0.384526 0.457639 -0.46829 -0.555931 0.473352 -0.37106 -0.402422 0.492375 -0.648364 0.951122 -0.486242 0.285234 0.544028 0.252369 0.100042 -0.262017 0.796289 -0.539442 -0.295421 -0.921472 0.82257 0.941562 0.831058 -0.413905 -0.500803 0.995588 0.849252 -0.616856 0.509391 -0.667306 0.595552 -0.555845 -0.0872534 -0.467216 -0.493985 -0.409962 -0.229128 -0.951339 -0.228756 0.3684 0.0216767 -0.769123 0.268 0.719313 0.618735 -0.175303 0.154663 -0.580714 -0.0673076 0.761177 -0.896118 0.94305 -0.150325 -0.514245 -0.9225 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.458491 0.139226 -0.034247 0.410401 -0.395975 0.850461 -0.297848 0.0718751 0.00470492 -0.924345 0.532338 -0.992688 -0.105529 0.376701 -0.778015 -0.100057 0.346464 -0.977418 0.543283 0.964932 -0.388968 0.622887 0.858026 0.834696 0.73931 -0.424078 0.525836 -0.268932 0.0568014 0.66197 -0.267806 0.988335 0.942297 -0.818525 -0.94425 -0.010903 0.75357 -0.746215 0.365048 -0.639903 -0.843122 -0.352625 -0.56202 0.133134 -0.422441 0.0323781 0.1782 -0.989023 -0.501672 0.399269 0.506685 -0.143645 -0.242349 0.84511 -0.228215 0.388112 0.996222 -0.491436 0.430613 -0.687518 0.887471 -0.279041 0.162995 -0.543129 -0.373324 -0.450942 -0.987706 -0.370641 0.642766 0.967733 0.684202 -0.621222 -0.877832 0.279375 -0.551034 0.76642 -0.785554 -0.802761 -0.00256995 0.806871 -0.924352 0.408415 0.237975 -0.3602 0.110513 -0.614452 0.900187 -0.557989 -0.121344 0.563993 -0.962382 -0.760862 0.184051 -0.647265 -0.580102 0.22778 0.303061 -0.453511 -0.162013 -0.946613 0.281981 -0.740725 0.629207 -0.913866 0.650018 0.849206 0.598833 0.58149 -0.899064 -0.568768 0.708225 -0.863152 -0.996385 -0.242721 0.580024 0.456998 0.771642 0.979116 0.00734291 -0.587635 -0.373244 0.89297 0.155123 -0.847135 0.208819 -0.373328 -0.520159 -0.307904 -0.94411 0.340999 -0.825715 0.209158 -0.683808 -0.757388 0.581961 -0.975006 -0.925954 -0.503948 0.139718 0.241685 -0.00782965 0.407138 0.763263 0.155216 0.711784 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.892587 -0.86041 -0.917681 0.532582 -0.901704 -0.935986 0.879509 -0.0983564 0.924749 0.254423 0.090189 -0.649709 -0.576475 0.412146 0.0617599 -0.854872 -0.62158 0.203715 0.934793 0.351175 -0.405522 0.0369853 0.923774 -0.627434 0.421611 -0.599387 -0.126069 0.959084 0.65351 -0.0899536 0.957308 -0.423107 -0.288389 0.101774 0.730997 0.0726534 -0.963149 0.133119 -0.717203 0.116322 0.577768 0.874596 -0.520713 -0.394123 -0.471526 0.478107 0.444291 0.426943 0.874325 -0.784597 0.344976 0.771296 -0.279253 0.984459 0.33809 -0.844265 0.433294 0.380426 -0.179489 -0.676919 -0.977227 -0.258439 0.408208 0.748369 -0.166102 0.320663 -0.617974 -0.290096 0.357929 -0.280733 -0.278234 -0.285224 0.240081 -0.955442 -0.98061 0.253129 -0.71592 0.935944 -0.116488 -0.907272 0.601345 -0.321701 -0.224231 0.81755 0.242379 0.92212 -0.314526 -0.602295 0.631645 -0.0209497 -0.648146 -0.253009 -0.323022 0.972358 0.41974 0.564115 -0.925445 0.0531064 0.558838 0.38797 0.617665 -0.140681 0.417081 0.950845 -0.403678 -0.1654 0.833662 -0.319241 0.65596 -0.968948 0.895924 -0.200276 -0.035571 0.157622 -0.841305 0.193022 0.112853 0.723603 -0.401455 0.742015 -0.948051 0.102226 0.105899 -0.148242 0.495953 -0.516381 -0.811975 -0.872272 -0.25428 0.5518 -0.703646 -0.164469 -0.210849 -0.376623 0.391848 -0.424729 0.996885 0.64195 -0.75194 0.15236 0.715338 0.689006 0.115588 0.681577 -0.728072 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.707412 0.522029 -0.257312 -0.635982 -0.941086 -0.829112 -0.879213 -0.927203 0.493395 0.488364 -0.0664303 -0.494256 -0.964768 -0.854147 0.352213 -0.34965 -0.573825 -0.283328 0.111217 -0.777507 0.438637 0.177933 0.518782 -0.824386 0.545224 -0.413337 -0.948109 -0.874036 0.0822065 -0.356133 0.478497 0.0984244 0.219122 0.782541 0.16119 -0.881674 -0.295247 -0.213376 -0.208901 -0.993642 -0.132994 0.771119 0.194768 -0.53222 0.976312 0.884085 0.81463 -0.511448 0.0874478 -0.264853 0.623576 0.434666 -0.573687 0.0422153 -0.487339 -0.700859 0.656137 -0.299608 0.489326 0.106965 -0.235076 -0.920713 -0.431624 -0.299726 0.501835 0.348742 -0.695437 -0.204415 0.39397 -0.547176 -0.384363 0.0116226 -0.659106 0.404046 0.808396 0.70397 -0.372078 0.493298 0.865598 0.0993494 -0.235392 -0.235022 -0.00975541 0.040765 -0.862644 -0.457409 0.324108 -0.721985 -0.399266 -0.468445 0.837278 0.129953 0.119434 -0.671063 -0.553527 0.863773 -0.575557 0.611626 -0.402993 0.90368 0.147435 -0.0663139 -0.537539 -0.413128 0.566087 0.223596 -0.0160215 0.726104 -0.37656 -0.847731 0.192695 0.617709 -0.166661 0.922461 -0.192412 0.12601 -0.149189 0.575428 -0.789626 0.75193 -0.308794 0.107352 0.271814 0.385575 0.366881 0.171856 0.379623 0.33001 0.480752 -0.00562256 -0.498439 0.734667 -0.456125 -0.100142 0.915444 -0.135828 -0.867459 0.62291 -0.747259 0.811503 0.938129 -0.863324 0.108688 0.718671 0.704976 

Layer 2: 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.467907 -0.632874 -0.710151 0.486073 -0.573216 -0.0379842 -0.401081 -1.01183 0.150859 -0.886916 -0.438683 0.30386 0.768782 0.925616 0.7868 0.0255647 -0.338183 -0.240844 0.114153 -0.344371 0.102746 -0.981751 -0.351617 0.878416 -0.458956 0.31245 0.213396 0.549989 -0.360537 0.924146 0.118931 0.866973 -0.788521 -0.713543 -0.601994 0.281329 0.297239 -0.345146 -0.53662 0.508139 0.287055 0.538666 -0.648389 0.519796 0.161698 -0.635246 -0.58228 0.380715 0.821385 -0.984875 -0.829523 0.0294661 0.909711 -0.537406 0.747473 0.779407 -0.507098 -0.818401 0.662141 0.559823 0.538226 0.5798 0.699997 0.791681 -0.822172 -0.286916 -0.303351 -0.416885 -0.592776 -0.779021 0.979141 0.49228 -0.285703 0.766928 -0.282797 0.921664 0.403866 -0.225324 0.922654 -0.187608 0.859961 -0.680758 -0.612129 -0.101006 0.792508 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
-0.391023 0.902897 0.994063 -0.786881 0.888925 0.159956 0.374065 0.840908 0.54062 0.0974283 -0.586027 -0.643051 0.193165 0.530826 -0.46717 -0.625952 -0.38856 0.555482 -0.0487579 0.634168 0.404884 0.479129 0.652742 0.921869 -0.14505 0.133949 -0.325318 0.375663 -0.274208 0.733861 -0.00634116 -0.575795 0.61844 0.0774408 0.444979 0.759824 0.368279 -0.390091 0.381188 0.852517 0.252818 -0.894774 -0.470877 -0.0367495 0.297686 0.741317 -0.685014 -0.863493 -0.258581 0.0236226 -1.0176 -0.590917 0.0465677 0.599503 -0.0887415 0.521993 -0.855857 -0.417734 -0.124917 0.46017 0.0850824 -0.487855 0.615236 0.202631 0.703044 -0.00272952 -0.43665 -0.77945 -0.215527 -0.355519 0.774454 -0.694714 -0.104588 0.480608 -0.483439 0.217292 0.0264278 0.172118 0.722743 -0.38181 -0.0995617 0.605203 0.791291 -0.841911 -0.320316 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.460628 0.702648 -0.599138 0.28114 -0.872753 -0.365616 -0.910522 0.872973 0.245928 -0.690165 0.414413 -0.834186 -0.0130092 -0.645818 -0.251556 -0.0229299 0.618961 -0.0725232 -0.890062 0.310737 0.57629 -0.561309 0.0879751 0.999522 0.973808 0.792975 -0.437281 0.612908 -0.8407 -0.652273 -0.759356 -0.490819 0.79833 -0.464671 -0.652532 0.88912 -0.553329 0.207387 0.384161 0.501329 -0.170152 0.263699 -0.01915 0.146473 -0.214392 -0.393252 0.60558 0.601755 -0.223557 0.676865 0.0713222 0.19247 0.34757 -0.378451 -0.141934 0.519965 -0.943498 0.630072 -0.527263 0.312283 -0.0817976 -0.158479 0.447938 0.517895 0.717572 0.254386 -0.366128 0.483837 -0.147004 -0.698912 -0.612876 -0.470982 0.214208 -0.86166 0.090796 -0.212429 -0.29052 -0.76175 -0.717892 0.548033 -0.144835 -0.233126 0.997105 0.359929 0.30491 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.588052 -0.930058 0.509784 -0.0584219 0.102296 -0.708781 -0.487152 0.399754 0.961725 -0.148335 0.901467 0.721539 -0.0289108 0.0958496 0.916327 -0.0540089 0.268814 -0.244327 -0.424648 -0.131564 0.764901 0.164578 0.0212828 -0.217524 0.0795622 -0.807813 -0.21759 0.962442 -0.262434 0.18993 0.159911 -0.369346 0.393592 -0.918643 -0.161303 0.983216 0.910901 -0.511416 0.52518 0.579328 0.765248 -0.477763 0.233132 0.244464 0.670476 0.249974 -0.683027 -0.416988 -0.313443 -0.0308835 0.918451 -0.515218 -0.790739 0.0231349 0.432099 0.293063 -0.48652 -0.960761 -0.330725 -0.536338 0.0347999 0.813233 0.00110095 0.467247 0.293289 -0.727252 0.792554 0.456836 0.044011 -0.307732 -0.0550159 -0.414312 0.626937 -0.32473 0.228287 0.579472 -0.81595 0.327965 0.0679414 -0.287192 0.675393 -0.694024 0.832163 0.119923 -0.324848 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.285813 -0.673808 -0.697942 -0.3028 0.843885 -0.821897 0.375415 -0.400468 0.243416 -0.656534 -0.373976 -0.552291 -0.585831 -0.055611 -0.65432 0.940136 0.86088 -0.722238 -0.656648 -0.0267594 0.254738 -0.113108 0.987116 -0.147976 0.962947 0.254575 -0.00706881 -0.805436 -0.960269 0.135097 0.575833 0.0192994 0.364539 0.810095 0.804826 0.702829 0.439763 -0.911368 -0.882232 0.894108 -0.719907 0.521164 -0.800756 -0.309252 0.401436 -0.94056 0.00865765 -0.46273 -0.729221 -0.0181332 -0.764331 -0.784734 -0.302288 -0.56083 -0.973784 -0.388903 -0.298686 -0.0241536 0.714463 -0.0247126 -0.295652 -0.212043 0.196914 -0.458721 -0.369084 0.8048 -0.7264 -0.598131 -0.779622 0.885148 0.681578 0.262011 -0.388228 -0.871081 -0.263996 -0.383845 0.70974 0.597107 -0.419645 0.143703 0.752889 -0.198102 -0.778865 -0.392506 0.614646 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.336527 0.604871 0.0743317 -0.707081 0.0969867 0.0553164 -0.296822 -0.71592 -0.744052 0.317984 0.341145 0.179294 -0.302866 -0.275865 -0.478848 0.899547 0.688619 -0.896295 -0.0338911 0.764893 -0.463975 -0.239799 -0.332624 0.169689 -0.0378815 -0.681434 0.90762 0.373514 -0.368258 0.228029 0.476598 0.176621 0.465733 -0.442168 0.935607 0.748731 -0.0764825 0.536939 0.324442 0.791052 -0.782313 -0.327443 0.667196 -0.437676 -0.0390468 0.240147 0.150931 0.936506 -0.889561 -0.850369 -0.1685 -0.506056 -0.774227 -0.463115 -0.34021 0.0944788 -0.0954422 -0.110435 0.52185 0.706239 0.604956 -0.00807318 0.314009 -0.473054 0.61655 0.338292 -0.0452647 -0.763187 -0.875604 -0.283423 0.507763 0.15698 0.341652 -0.705617 0.674663 -0.682806 0.0828457 0.386843 -0.359362 0.305602 0.743809 -0.83272 -0.446268 -0.456555 0.862469 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
-0.505236 -0.919587 0.502054 0.0219544 0.986975 0.0862932 0.329587 -0.649171 -0.518354 -0.162293 0.337805 0.0116239 -0.297209 0.802015 -0.540581 0.106912 0.869692 -0.323782 0.188575 -0.325398 -0.969153 -0.424541 0.726603 -0.425129 0.855382 0.39441 0.804296 -0.192388 0.527864 0.747851 -0.862638 -0.364917 0.837688 -0.986701 -0.0720072 -0.225234 0.496942 0.0925637 0.941291 -0.746139 -0.352883 -0.908676 -0.112872 0.960086 0.160425 0.713283 0.144253 -0.423764 0.439626 0.793033 0.499742 0.0616272 0.263893 -0.759585 -0.478066 -0.847419 -0.563012 -0.547545 -0.152365 -0.80914 0.46658 0.297585 -0.492756 0.232181 0.145997 -0.244221 0.763291 0.629948 -0.469063 0.465398 -0.0630372 -0.322594 0.149221 0.730627 -0.3709 -0.359106 0.503326 -0.606235 -0.999437 0.777831 0.425436 0.288224 0.96654 0.628175 0.101779 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.604274 0.720224 0.799108 0.610682 -0.259984 0.454199 -0.284654 -0.181957 0.828242 0.817372 -0.437384 -0.222022 0.894706 -0.680976 0.830697 0.679655 0.966805 0.133713 -0.678802 0.420145 -0.617792 0.846324 0.16693 -0.348324 -0.287503 -0.0672176 -0.706932 0.586257 -0.77316 -0.956834 0.485647 0.27018 0.914706 -0.531484 -0.733262 0.0705668 0.0160039 0.977776 -0.490397 -0.809236 -0.821676 0.0914064 0.267786 0.67283 0.260156 -0.358294 0.145435 0.386078 -0.372583 -0.00339942 0.865457 -0.819319 0.248885 -0.98697 0.949607 0.0531717 -0.342512 -0.60076 0.98163 0.246917 -0.784243 0.00354766 -0.374516 -0.494845 -0.89546 -0.000550166 -0.0893876 -0.33747 0.149281 0.963456 0.801703 0.411362 -0.233609 0.849005 -0.765536 -0.0967784 -0.555333 0.521831 0.414439 0.916012 -0.678345 -0.940931 0.343388 -0.681018 0.345741 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.84879 0.763515 0.388405 -0.0770626 0.809275 -0.507855 0.487828 0.918186 0.966132 0.842991 0.143185 0.0644866 0.596438 0.337078 -0.734579 0.990074 0.179423 0.890386 0.704924 -0.998257 0.293098 0.367947 0.0767834 -0.529661 -0.00678455 -0.0309012 0.441175 0.825556 -0.879647 0.320636 0.934405 0.537649 0.267132 -0.324144 0.632389 0.563073 -0.429699 0.0462849 -0.660307 -0.572186 -0.733537 -0.563833 -0.348321 -0.224376 0.907729 0.00559637 0.0581597 0.527021 -0.832037 -0.0524786 -0.0143135 0.109164 0.701886 0.583738 -0.316976 0.582486 -0.162984 0.725383 -0.247476 0.658179 0.174405 0.898425 -0.177682 -0.309173 -0.849597 0.820089 -0.713107 0.809556 0.204121 0.654709 -0.310492 -0.300302 0.808077 -0.402574 -0.0675103 0.603335 0.248362 0.218111 -0.226365 0.0713196 -0.789473 -0.677332 0.327585 -0.291802 -0.749278 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.846747 0.230695 -0.701895 -0.752212 -0.432531 0.459061 -0.554475 0.906483 -0.219894 -0.712362 -0.703375 -0.107899 0.246443 -0.0364389 -0.459944 -0.444695 0.012403 -0.168425 -0.739417 0.342903 -0.859418 -0.291892 0.13763 -0.774783 0.213741 0.329202 -0.404604 -0.173288 -0.478987 0.644435 -0.985456 -0.552075 -0.720444 -0.53219 0.934382 0.157867 -0.735576 -0.853985 0.171762 -0.49989 0.356826 -0.830919 0.751704 -0.109576 0.328032 -0.385646 0.452597 0.348481 -0.729474 -0.273706 -0.198384 0.297327 -0.394221 0.282778 0.406568 -0.804881 0.369246 -0.106114 -0.678319 -0.550015 0.0549156 0.0429393 -0.319041 -0.155802 0.21019 0.632266 -0.599756 -0.0913972 -0.112589 -0.278492 -0.614534 -0.60959 0.598234 -0.425462 -0.767198 -0.109265 -0.418172 -0.221182 0.558845 -1.01365 -0.906794 -0.523761 0.486735 0.514129 -0.0893433 

Ein = 1
Eout = 1
