training...
iteration = 0, record = 1, loss error = 9.64558
iteration = 0, record = 2, loss error = 9.51777
iteration = 0, record = 3, loss error = 9.45743
iteration = 0, record = 4, loss error = 9.97714
iteration = 0, record = 5, loss error = 9.72556
iteration = 0, record = 6, loss error = 9.97265
iteration = 0, record = 7, loss error = 9.75887
iteration = 0, record = 8, loss error = 9.79817
iteration = 0, record = 9, loss error = 9.9122
iteration = 0, record = 10, loss error = 9.96246
iteration = 0, record = 11, loss error = 9.94343
iteration = 0, record = 12, loss error = 9.79054
iteration = 0, record = 13, loss error = 9.88462
iteration = 0, record = 14, loss error = 9.89778
iteration = 0, record = 15, loss error = 9.79466
iteration = 0, record = 16, loss error = 9.47156
iteration = 0, record = 17, loss error = 9.9414
iteration = 0, record = 18, loss error = 9.93546
iteration = 0, record = 19, loss error = 9.89453
iteration = 0, record = 20, loss error = 9.52309
iteration = 0, record = 21, loss error = 9.93354
iteration = 0, record = 22, loss error = 9.89589
iteration = 0, record = 23, loss error = 9.97521
iteration = 0, record = 24, loss error = 9.96675
iteration = 0, record = 25, loss error = 9.91177
iteration = 0, record = 26, loss error = 9.94239
iteration = 0, record = 27, loss error = 9.86338
iteration = 0, record = 28, loss error = 9.93486
iteration = 0, record = 29, loss error = 9.76192
iteration = 0, record = 30, loss error = 9.90871
iteration = 0, record = 31, loss error = 9.93673
iteration = 0, record = 32, loss error = 9.77039
iteration = 0, record = 33, loss error = 9.90497
iteration = 0, record = 34, loss error = 9.87339
iteration = 0, record = 35, loss error = 9.92542
iteration = 0, record = 36, loss error = 9.93715
iteration = 0, record = 37, loss error = 9.88409
iteration = 0, record = 38, loss error = 9.87443
iteration = 0, record = 39, loss error = 9.93272
iteration = 0, record = 40, loss error = 9.88303
iteration = 0, record = 41, loss error = 9.94707
iteration = 0, record = 42, loss error = 9.89075
iteration = 0, record = 43, loss error = 9.88163
iteration = 0, record = 44, loss error = 9.89642
iteration = 0, record = 45, loss error = 9.96556
iteration = 0, record = 46, loss error = 9.84403
iteration = 0, record = 47, loss error = 9.94931
iteration = 0, record = 48, loss error = 9.75707
iteration = 0, record = 49, loss error = 9.95472
iteration = 0, record = 50, loss error = 9.92325
iteration = 0, record = 51, loss error = 9.91099
iteration = 0, record = 52, loss error = 9.8991
iteration = 0, record = 53, loss error = 9.9385
iteration = 0, record = 54, loss error = 9.97162
iteration = 0, record = 55, loss error = 9.87242
iteration = 0, record = 56, loss error = 9.93638
iteration = 0, record = 57, loss error = 9.92575
iteration = 0, record = 58, loss error = 9.90322
iteration = 0, record = 59, loss error = 9.80428
iteration = 0, record = 60, loss error = 9.61349
iteration = 0, record = 61, loss error = 9.93865
iteration = 0, record = 62, loss error = 9.95341
iteration = 0, record = 63, loss error = 9.72695
iteration = 0, record = 64, loss error = 9.93674
iteration = 0, record = 65, loss error = 9.94354
iteration = 0, record = 66, loss error = 9.89029
iteration = 0, record = 67, loss error = 9.9029
iteration = 0, record = 68, loss error = 9.93305
iteration = 0, record = 69, loss error = 9.94828
iteration = 0, record = 70, loss error = 9.88352
iteration = 0, record = 71, loss error = 9.93173
iteration = 0, record = 72, loss error = 9.95443
iteration = 0, record = 73, loss error = 9.90144
iteration = 0, record = 74, loss error = 9.92134
iteration = 0, record = 75, loss error = 9.90846
iteration = 0, record = 76, loss error = 9.9672
iteration = 0, record = 77, loss error = 9.92089
iteration = 0, record = 78, loss error = 9.95563
iteration = 0, record = 79, loss error = 9.94722
iteration = 0, record = 80, loss error = 9.95131
iteration = 0, record = 81, loss error = 9.89383
iteration = 0, record = 82, loss error = 9.92454
iteration = 0, record = 83, loss error = 9.93609
iteration = 0, record = 84, loss error = 9.96251
iteration = 0, record = 85, loss error = 9.94378
iteration = 0, record = 86, loss error = 9.93577
iteration = 0, record = 87, loss error = 9.94398
iteration = 0, record = 88, loss error = 9.89643
iteration = 0, record = 89, loss error = 9.93841
iteration = 0, record = 90, loss error = 9.93326
iteration = 0, record = 91, loss error = 9.91404
iteration = 0, record = 92, loss error = 9.94368
iteration = 0, record = 93, loss error = 9.91961
iteration = 0, record = 94, loss error = 9.91019
iteration = 0, record = 95, loss error = 9.9118
iteration = 0, record = 96, loss error = 9.81611
iteration = 0, record = 97, loss error = 9.62203
iteration = 0, record = 98, loss error = 9.88667
iteration = 0, record = 99, loss error = 9.87077
iteration = 0, record = 100, loss error = 9.92441
iteration = 0, record = 101, loss error = 9.91248
iteration = 0, record = 102, loss error = 9.82546
iteration = 0, record = 103, loss error = 9.96598
iteration = 0, record = 104, loss error = 9.86446
iteration = 0, record = 105, loss error = 9.9517
iteration = 0, record = 106, loss error = 9.95
iteration = 0, record = 107, loss error = 9.91961
iteration = 0, record = 108, loss error = 9.88133
iteration = 0, record = 109, loss error = 9.91021
iteration = 0, record = 110, loss error = 9.95683
iteration = 0, record = 111, loss error = 9.93302
iteration = 0, record = 112, loss error = 9.96107
iteration = 0, record = 113, loss error = 9.87931
iteration = 0, record = 114, loss error = 9.94983
iteration = 0, record = 115, loss error = 9.93232
iteration = 0, record = 116, loss error = 9.87295
iteration = 0, record = 117, loss error = 9.91109
iteration = 0, record = 118, loss error = 9.94763
iteration = 0, record = 119, loss error = 9.93895
iteration = 0, record = 120, loss error = 9.92499
iteration = 0, record = 121, loss error = 9.86121
iteration = 0, record = 122, loss error = 9.94828
iteration = 0, record = 123, loss error = 9.93553
iteration = 0, record = 124, loss error = 9.81906
iteration = 0, record = 125, loss error = 9.93696
iteration = 0, record = 126, loss error = 9.91334
iteration = 0, record = 127, loss error = 9.94413
iteration = 0, record = 128, loss error = 9.92293
iteration = 0, record = 129, loss error = 9.89329
iteration = 0, record = 130, loss error = 9.89495
iteration = 0, record = 131, loss error = 9.96286
iteration = 0, record = 132, loss error = 9.9439
iteration = 0, record = 133, loss error = 9.89935
iteration = 0, record = 134, loss error = 9.90916
iteration = 0, record = 135, loss error = 9.93281
iteration = 0, record = 136, loss error = 9.8382
iteration = 0, record = 137, loss error = 9.8697
iteration = 0, record = 138, loss error = 9.73487
iteration = 0, record = 139, loss error = 9.55391
iteration = 0, record = 140, loss error = 9.82505
iteration = 0, record = 141, loss error = 9.9017
iteration = 0, record = 142, loss error = 9.95395
iteration = 0, record = 143, loss error = 9.94017
iteration = 0, record = 144, loss error = 9.85547
iteration = 0, record = 145, loss error = 9.95853
iteration = 0, record = 146, loss error = 9.93153
iteration = 0, record = 147, loss error = 9.94811
iteration = 0, record = 148, loss error = 9.8723
iteration = 0, record = 149, loss error = 9.91733
iteration = 0, record = 150, loss error = 9.89763
iteration = 0, record = 151, loss error = 9.91313
iteration = 0, record = 152, loss error = 9.89518
iteration = 0, record = 153, loss error = 9.92415
iteration = 0, record = 154, loss error = 9.86448
iteration = 0, record = 155, loss error = 9.8744
iteration = 0, record = 156, loss error = 9.95595
iteration = 0, record = 157, loss error = 9.94346
iteration = 0, record = 158, loss error = 9.90921
iteration = 0, record = 159, loss error = 9.95685
iteration = 0, record = 160, loss error = 9.87862
iteration = 0, record = 161, loss error = 9.73089
iteration = 0, record = 162, loss error = 9.93101
iteration = 0, record = 163, loss error = 9.93963
iteration = 0, record = 164, loss error = 9.8964
iteration = 0, record = 165, loss error = 9.89906
iteration = 0, record = 166, loss error = 9.93766
iteration = 0, record = 167, loss error = 9.81476
iteration = 0, record = 168, loss error = 9.89554
iteration = 0, record = 169, loss error = 9.71859
iteration = 0, record = 170, loss error = 9.97072
iteration = 0, record = 171, loss error = 9.68648
testing...
record 0, ans = 2, expect = 1, sample error = 1
Convolution Layer 0:
strides = 2
padding = 0
Activation function = Relu
pooling height = 2
pooling width = 2
learning rate = 0.5
Kernel 0:
-0.562744 -0.0296546 -0.405163 
0.424472 0.0984809 -0.831806 
-0.156042 -0.603809 -0.214776 
bias = 0.256548
Kernel 1:
0.0913134 0.703529 0.215114 
-0.575044 -0.760162 -0.042303 
-0.986445 0.819974 -0.69436 
bias = -0.106735
Kernel 2:
0.112197 -0.311343 -0.736603 
-0.09412 0.125441 0.280492 
0.221952 0.354234 -0.38889 
bias = -0.0697182
Kernel 3:
0.245535 0.703769 0.243847 
0.342932 -0.342088 0.534206 
0.407754 -0.873435 0.180461 
bias = -0.989621
Kernel 4:
-0.552749 -0.0574566 0.326814 
0.755231 -0.829133 0.758395 
0.347054 0.944556 -0.847345 
bias = 0.679392
Kernel 5:
0.81958 0.681323 0.994003 
0.211437 -0.369504 -0.254021 
0.66098 -0.908169 0.395487 
bias = 0.951071
Convolution Layer 1:
strides = 1
padding = 0
Activation function = Relu
pooling height = 2
pooling width = 2
learning rate = 0.5
Kernel 0:
0.940231 -0.383068 0.718754 
0.867434 0.524608 -0.217758 
0.80499 0.109443 0.713833 
bias = -0.416932
Kernel 1:
-0.808312 -0.118491 -0.277415 
-0.268516 -0.804383 0.212746 
0.971641 -0.828049 -0.788054 
bias = 0.371486
Kernel 2:
0.217075 0.504146 0.641599 
-0.0152452 0.249121 -0.0688047 
-0.516535 0.0247277 0.350163 
bias = 0.783697
Kernel 3:
0.788904 0.213411 0.564629 
-0.0480587 -0.292422 0.884834 
0.811141 0.586786 0.825895 
bias = 0.411876
Kernel 4:
-0.870122 -0.132527 0.623581 
0.529897 -0.0218809 0.247776 
0.367467 0.0108854 0.951517 
bias = 0.144546
Kernel 5:
0.915201 -0.214369 -0.891918 
-0.467435 -0.173208 0.886605 
-0.824724 0.869917 0.696516 
bias = 0.34129
Kernel 6:
0.064999 0.853816 0.951424 
-0.019657 -0.00934009 -0.928833 
0.35911 0.862101 -0.70315 
bias = -0.488164
Kernel 7:
-0.249108 -0.0210831 -0.14882 
0.548242 0.415405 -0.431744 
0.685028 0.186457 0.27765 
bias = -0.787454
Kernel 8:
-0.405662 0.467095 0.272714 
0.0902048 -0.215685 0.654557 
0.274169 0.535669 -0.139763 
bias = 0.201818
Kernel 9:
0.654899 -0.82061 0.336494 
0.572588 0.429842 0.750533 
-0.437724 -0.313667 -0.0303995 
bias = -0.578566
Kernel 10:
0.112372 0.205099 -1.05462 
0.222668 0.658743 -1.04386 
-0.394525 -0.601088 0.37422 
bias = -4.83608
Kernel 11:
-0.769176 -0.866585 -0.942022 
0.69672 0.500988 -0.0928544 
-0.311711 0.129451 -0.251612 
bias = -0.251546
Kernel 12:
-0.0997947 0.0974584 -0.6521 
-0.386889 0.987038 0.973813 
0.0370284 0.692188 -0.588661 
bias = -1.08346
Kernel 13:
-0.0268067 0.122362 -1.00484 
0.558516 -0.656366 -0.218599 
0.131106 -0.883305 -0.805741 
bias = -2.15522
Kernel 14:
-0.0156636 0.476097 0.480558 
-0.489611 0.652595 0.950235 
-0.998869 0.0714062 0.234388 
bias = 0.309323
Kernel 15:
-0.876301 0.0137759 -0.468347 
0.49628 0.984132 0.313212 
0.149302 -0.68561 0.956254 
bias = -0.249148
NN:
eps: 0
N: 10
Loss function: Scaled Corss-Entropy Error
Layer 1: 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.361151 0.131931 -0.63501 -0.616187 -0.261428 0.172669 0.0445737 -0.850363 -0.0482212 -0.454182 0.556824 0.539424 0.10241 -0.800384 -0.0498158 0.746185 -0.871132 0.88037 0.380568 0.200494 -0.29862 -0.909958 0.329378 -0.14043 -0.200987 0.00759941 -0.276667 0.060448 -0.0498261 0.57269 -0.80082 0.621588 -0.975557 -0.183625 -0.185863 0.204989 -0.743665 -0.783154 -0.473104 0.533546 -0.698803 -0.779345 -0.444372 -0.564836 0.805294 0.582041 0.371051 0.258229 0.055416 -0.624092 0.878847 0.782627 -0.38932 0.705917 0.344056 0.542957 -0.519929 -0.438578 0.812197 0.589871 -0.0350925 0.200265 -0.137924 -0.0873099 0.582522 0.450854 -0.496972 -0.610846 -0.483597 0.184941 0.305327 -0.374343 0.420047 -0.273894 0.664254 0.121835 -0.32555 0.478147 0.214482 0.794618 -0.854739 0.405509 -0.618433 -0.00112015 -0.826292 0.508311 -0.824514 0.400909 0.0742412 -0.227916 -0.589081 -0.682103 -0.107758 0.912279 0.670109 0.514072 0.0147534 -0.0390133 0.304209 0.833433 -0.487651 0.05156 0.569187 0.33186 -0.424128 -0.32572 -0.369509 -0.335885 0.775716 -0.53984 0.915107 0.205785 0.627092 -0.468984 -0.206139 -0.573473 -0.363994 0.349599 -0.292961 0.210215 -0.911861 0.358096 0.524285 -0.345737 -0.804117 -0.800737 0.0192364 -0.694275 -0.673977 0.471996 0.843781 -0.574252 0.538499 0.545763 0.644293 0.62794 -0.211342 -0.0298156 0.888604 0.761937 -0.132249 -0.709023 -0.542464 0.812906 0.509651 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.300692 0.262918 0.855199 -0.667249 -0.445843 0.718598 -0.52497 0.835543 0.968322 0.587016 -0.0163554 -0.885184 0.712399 -0.706795 0.890309 -0.574033 0.227599 -0.750115 0.813805 -0.376675 -0.784178 0.323925 0.215259 -0.134203 0.455977 -0.388049 0.0647986 -0.930625 0.982917 -0.114097 0.366905 0.575931 -0.324375 0.232795 0.587063 0.766845 0.364351 -0.351798 -0.670794 -0.0267085 -0.890339 0.0764324 0.599831 -0.63627 0.210807 -0.964279 -0.640889 0.579376 -0.433958 0.46872 -0.230301 -0.674038 -0.557735 0.153919 0.922296 -0.976659 -0.705197 -0.253771 0.873695 0.20013 -0.416524 -0.525101 0.626597 -0.783155 -0.481541 0.73581 0.75866 0.795813 -0.767454 -0.602839 0.0911981 0.765877 0.0895258 0.659287 0.640176 -0.554942 -0.901796 -0.486108 -0.0209622 -0.310892 0.84502 0.244312 0.158 -0.49451 0.762316 0.248887 -0.951914 -0.810276 -0.305832 -0.116532 -0.55563 -0.473787 -0.944279 -0.494307 0.190548 0.535454 -0.619 0.458911 0.923775 -0.11039 0.679878 0.711331 -0.663852 0.64306 -0.0934369 -0.394591 0.117349 0.287918 -0.955456 -0.356502 0.271482 0.794026 -0.805858 -0.0505865 -0.207129 0.777241 -0.90992 0.968323 0.604594 -0.582483 0.20437 0.840595 -0.11158 0.672642 -0.911825 0.957753 0.949612 0.134049 0.968991 -0.175006 0.672093 -0.13578 -0.0593703 0.162612 -0.986532 -0.645075 0.220926 -0.889418 -0.440599 0.858417 -0.582529 -0.564008 0.723631 0.0690974 -0.68001 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.93366 -0.0172426 0.203282 0.553877 -0.993542 -0.454144 -0.794871 0.603643 -0.575121 -0.0580557 0.257062 0.449344 0.116696 -0.681943 0.577642 0.421222 -0.520529 -0.535362 0.174789 -0.325082 0.347013 0.252815 -0.946287 -0.252599 0.56902 -0.483723 0.0673604 0.125989 -0.506369 -0.546148 0.894679 0.877209 -0.739975 -0.751993 -0.75038 0.357627 0.637512 0.657471 0.111811 -0.794378 0.884286 0.192397 -0.380539 0.277243 -0.371716 0.570036 0.591975 -0.681864 -0.0923609 -0.310136 -0.463286 -0.449243 -0.42642 -0.838876 -0.984996 -0.83493 -0.673672 -0.411249 0.145064 0.0957135 0.656348 -0.758692 0.656967 -0.354693 0.678711 -0.908422 0.148883 0.284166 -0.0188529 -0.86118 0.150245 -0.825488 0.0208501 0.428227 -0.786109 -0.126988 -0.281835 -0.795518 -0.270424 0.980504 -0.671188 -0.657334 0.190942 -0.842216 0.869664 0.435919 0.484803 0.08415 0.309145 -0.204392 0.789515 -0.627363 -0.0913792 0.18929 -0.602927 0.601323 0.443299 0.526761 -0.731727 -0.127741 -0.939406 -0.597206 0.7532 -0.960556 -0.0587203 -0.911464 -0.972773 0.608922 0.151097 -0.515301 -0.658117 -0.975563 -0.283192 0.390397 -0.60592 0.309356 -0.647949 -0.0718729 0.0319381 0.784269 -0.78822 0.392606 0.521734 0.790209 -0.959092 0.544661 0.119308 -0.790444 -0.986557 0.942522 0.968718 -0.756265 -0.55065 -0.778391 -0.417893 0.466986 0.626241 -0.775712 0.612531 0.807869 -0.143552 -0.684666 0.811085 -0.100939 -0.476131 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.340516 0.955419 -0.279422 -0.24292 -0.748876 -0.351962 0.581478 0.897403 0.659513 0.436216 -0.518483 -0.141161 -0.495321 -0.862266 -0.0988285 0.989311 -0.644336 0.652316 -0.529807 -0.458035 -0.189336 -0.168158 -0.230362 0.297937 -0.572358 0.372428 -0.607133 -0.0843619 0.129842 0.247711 -0.722324 -0.0999623 -0.0671778 0.943012 -0.79154 0.594772 0.333453 0.3362 0.519464 0.639617 0.0449942 0.217772 0.0959311 0.313188 -0.253334 0.221341 0.0848479 0.0393226 0.895553 -0.442369 -0.892336 0.509589 0.655677 -0.0380558 0.396695 -0.74504 0.108583 0.949019 0.169547 -0.416722 0.151196 -0.841272 0.748615 -0.0195665 -0.854574 -0.82859 -0.111801 0.964586 -0.200469 0.71215 -0.896392 0.344636 0.2961 0.556278 -0.642112 0.0200984 -0.206538 0.713318 0.730546 0.28359 0.30068 -0.477485 0.904801 0.991735 0.0938261 0.934821 -0.460083 -0.610741 -0.7234 -0.177279 0.47592 0.792228 0.968344 0.960866 -0.719291 0.869847 -0.488099 0.518601 0.132722 0.653194 0.237394 -0.119401 -0.775942 0.750562 0.697083 -0.123421 -0.344165 -0.37882 -0.825187 -0.92427 -0.208243 0.0681801 -0.0970812 0.355931 0.125829 0.812207 0.766105 -0.0671791 0.920911 -0.254253 0.765342 -0.89452 -0.198478 0.178722 -0.214379 0.931034 -0.115278 0.523193 -0.696679 0.914832 -0.424796 0.453208 -0.936335 -0.977793 0.231771 -0.632014 -0.256209 -0.106802 0.981552 0.950555 -0.0150797 0.555922 -0.626279 0.12268 -0.125574 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.515953 0.376545 0.586377 -0.765592 0.698162 0.00415591 -0.151587 0.269344 0.866076 0.140834 -0.999604 -0.344941 0.579694 0.918465 0.63588 -0.772873 0.316584 0.824863 -0.534388 0.547146 -0.112251 -0.610431 0.478992 0.410482 0.979322 -0.54018 -0.797 0.824957 -0.939734 -0.102368 -0.505433 -0.811451 -0.0653168 0.220534 0.508054 0.861341 0.562875 0.241277 -0.857437 -0.938894 0.00769884 -0.605643 0.95667 0.753726 -0.120343 -0.602425 -0.964621 -0.38546 -0.420197 -0.25166 0.354587 -0.448096 0.845279 0.599875 0.0940086 0.00181879 0.568335 0.00292082 -0.909701 0.647718 0.201859 0.63643 0.473591 -0.363614 0.73277 -0.336027 0.399787 -0.781564 0.251395 -0.801264 -0.850842 -0.098769 -0.0107291 -0.32422 0.833122 0.280249 0.146355 -0.212017 0.628367 0.956782 0.641118 -0.73043 -0.334136 0.183893 0.69598 -0.660741 0.933897 0.011978 -0.685458 -0.485322 -0.806122 -0.492536 -0.0572434 -0.0906346 0.703905 0.529523 -0.309116 0.681049 0.387934 0.0139061 -0.280986 -0.533463 0.0932114 0.603982 -0.866583 -0.65846 -0.732139 0.938268 -0.52587 -0.289354 0.826619 0.987976 0.919295 0.593552 -0.176894 0.937872 0.808537 -0.918911 -0.136609 0.00901931 -0.412533 0.557903 0.67619 0.72035 0.928428 0.0967026 -0.719974 -0.604409 -0.302371 0.0445206 0.257008 -0.45911 -0.2636 -0.325322 0.304928 0.931372 -0.427041 0.713767 0.273914 -0.334686 0.934424 0.865668 -0.721092 0.613886 -0.423282 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0964724 0.587719 -0.209917 -0.0810318 0.0987752 0.115117 0.775238 -0.569334 -0.804789 -0.0969424 0.689644 0.852725 -0.259189 -0.185657 -0.335724 -0.515155 -0.208323 0.719806 -0.216449 0.137391 -0.870799 0.475942 -0.83627 0.804072 0.0343003 0.485171 0.265072 -0.933442 -0.367556 0.483102 -0.505013 0.239778 -0.0427869 0.880408 -0.986389 -0.233974 -0.406529 -0.535388 -0.259856 0.592316 -0.95016 0.659088 -0.707584 -0.369971 -0.100786 0.085361 0.662166 -0.97868 -0.677745 -0.853787 0.403218 0.880479 0.214662 -0.18193 0.297426 0.831158 -0.734069 0.506968 0.610733 0.596268 -0.522552 -0.528774 0.895029 0.760651 0.266111 0.526546 -0.348307 -0.00271732 0.329997 0.259532 -0.0527422 -0.438476 0.530038 0.345142 0.799497 -0.847678 -0.925915 0.140334 0.593514 -0.816982 0.988331 0.871656 -0.0786005 0.962112 0.213006 -0.00351472 0.928169 -0.259658 -0.0728371 -0.172481 -0.890703 -0.0517712 -0.119041 -0.715655 -0.0154916 -0.366518 -0.0629676 -0.296013 0.91544 -0.202979 0.538319 -0.470754 0.0346087 -0.331394 0.26831 -0.506131 -0.550583 0.355509 -0.960072 0.0772758 0.774654 -0.392821 -0.142635 0.725956 -0.865643 -0.862796 0.987234 0.447052 -0.393313 -0.41924 -0.168064 -0.650813 -0.219509 0.716188 0.976653 0.60779 -0.86554 0.862464 -0.559672 -0.404512 -0.640932 -0.14389 -0.367111 -0.0415258 0.0764071 0.174484 0.54802 0.572756 0.318351 0.525292 0.585517 0.78524 -0.470913 -0.631366 0.636453 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
1.02879 0.91293 -0.382335 0.0982782 -0.238139 -0.399878 -0.75303 -0.180894 -0.290312 0.732974 -0.900856 0.493701 -0.184005 -0.626623 -0.719304 -0.729069 -0.875164 0.209578 -0.641509 0.460035 -0.0263618 0.720907 0.845554 -0.155635 0.520581 0.640919 -0.661219 0.292542 -0.0543004 0.818713 0.0891412 -0.136882 -0.384705 0.866278 0.317228 0.857897 -0.389136 -0.179289 0.203321 -0.560657 -0.402139 -0.260121 -0.374233 -0.101233 0.0479274 -0.874175 -0.322542 0.0662069 -0.961654 -0.838344 -0.749954 0.833036 0.471267 0.803558 0.0922197 -0.356957 0.622865 0.492127 -0.819975 0.679286 0.764955 0.591953 0.951189 0.626904 0.378727 -0.733371 0.226064 -0.54683 -0.572752 -0.236112 -0.326214 -0.684791 0.710346 0.789533 -0.544874 -0.291071 0.63968 -0.865702 0.135744 -0.25782 0.265906 0.184206 0.0382038 -0.0427525 0.381404 -0.293719 -0.204811 0.439629 0.563818 -0.429075 -0.671352 -0.304046 -0.0979763 -0.687713 -0.390557 -0.0923777 -0.592574 0.601015 -0.73411 -0.192381 0.657284 -0.783841 -0.580759 0.456626 -0.859731 0.948016 0.272813 -0.0414746 -0.635849 -0.981358 0.321822 0.858134 0.652605 0.336739 -0.419838 -0.22152 0.904974 -0.103398 0.185424 0.428628 -0.0425175 -0.591834 -0.955965 -0.909346 0.619692 -0.836597 -0.677627 -0.873474 -0.0603192 -0.707796 -0.564545 -0.44648 -0.224256 -0.856145 -0.472463 -0.0323596 0.656305 0.514786 0.00409373 0.803248 0.186964 0.308929 0.167617 -0.867557 0.96948 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.149943 0.608715 0.676658 0.599031 -0.0848525 -0.115129 -0.970569 -0.350782 0.407158 -0.89305 0.505341 0.363652 0.119396 -0.920219 0.455788 0.449536 0.763245 -0.313861 0.983085 -0.989161 0.574253 -0.734346 0.288885 -0.936426 0.676933 -0.734753 0.118963 0.459119 0.687664 -0.318 -0.129002 0.670931 0.782132 0.609414 0.473651 -0.0816402 0.618554 -0.403686 -0.0423331 0.78805 -0.181922 -0.729267 -0.686057 -0.123277 -0.210578 -0.208106 -0.259272 0.488043 0.518975 0.59831 0.995671 -0.975204 -0.554489 -0.339013 -0.593288 -0.78702 0.557402 0.263641 -0.985049 0.278812 -0.0128017 0.842066 0.604125 -0.466251 -0.281912 -0.0910325 0.0164289 0.12031 0.0551744 -0.683677 -0.56109 -0.231628 -0.964649 -0.857312 0.89972 0.217747 0.277642 0.439295 -0.00160306 -0.239347 -0.424319 -0.511035 -0.900061 -0.959196 -0.0869287 -0.762564 0.406669 -0.610341 0.0457553 -0.295939 -0.822157 -0.0928525 -0.572388 -0.117002 -0.454252 -0.618791 -0.0148084 -0.884248 0.446 -0.0820819 0.448749 0.462754 -0.746706 -0.0912649 0.111056 -0.912824 0.517849 -0.637319 0.713598 -0.780111 0.682158 -0.967948 -0.299499 0.318443 0.0665078 -0.204015 -0.881081 -0.335034 -0.910371 -0.60682 -0.820549 -0.973836 0.741681 -0.568496 -0.708027 0.188608 -0.0712818 -0.0341905 -0.305124 0.472675 -0.138294 0.465798 0.32576 0.346923 -0.877143 0.673172 -0.0609659 -0.653441 -0.380768 0.435905 0.251108 0.365796 -0.065776 0.502669 0.359806 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.748667 -0.843619 -0.711156 -0.393606 0.671451 -0.928735 0.753891 0.643039 -0.450961 0.696172 0.555021 0.232592 -0.828396 -0.850052 -0.820676 0.89603 -0.424269 -0.691459 0.650967 0.798532 0.931139 -0.35483 0.370182 -0.346715 0.758206 -0.827947 0.694662 -0.814453 -0.50611 -0.193293 -0.681387 -0.0659027 0.373098 0.664576 -0.468047 -0.461816 0.25801 0.373876 -0.262711 0.624076 0.84327 0.836667 -0.13325 0.462499 -0.777587 -0.907827 0.153785 0.667941 0.0896177 0.204166 -0.589671 -0.597972 -0.117655 0.569954 -0.791336 0.0140815 0.666941 -0.720954 0.927501 0.514574 0.437664 -0.177582 -0.624728 0.195712 -0.665869 0.744988 -0.979861 -0.524822 -0.687646 0.732136 -0.996669 0.990894 -0.0375602 0.726096 -0.497102 -0.792744 0.359522 0.488377 0.152348 0.513074 -0.773591 0.251641 -0.672432 0.435444 0.511376 0.700968 -0.837054 -0.372294 0.855712 -0.0568023 -0.675932 -0.395608 -0.98823 0.825868 0.361773 0.321062 0.0833077 0.151775 0.881427 0.142826 0.472196 0.204314 -0.0895528 0.885375 0.491309 -0.562704 0.637121 0.0882356 0.975502 -0.74488 0.805753 0.290796 -0.590686 0.343642 -0.406843 0.187276 -0.453477 0.412349 0.348584 0.645367 0.675156 -0.648774 0.0629 -0.839687 -0.626953 0.803464 -0.176263 -0.448601 0.359945 -0.406955 0.314895 0.446088 -0.604933 0.891022 -0.588512 0.879419 0.397243 0.468036 0.28818 -0.555378 -0.233554 0.650884 -0.598005 -0.671778 -0.568523 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.6738 0.667441 -0.319002 0.530736 0.0745841 -0.46511 0.893538 -0.304001 0.661182 0.477737 -0.674431 0.970255 -0.170687 -0.357882 0.593619 -0.314976 0.40817 0.426814 -0.879463 -0.156383 0.777703 0.441649 0.0504917 0.8762 0.853219 -0.258312 -0.361192 0.554101 0.791304 -0.711041 0.313799 0.117554 -0.907715 -0.0129234 0.779143 0.56711 -0.10573 0.895603 0.164262 0.300279 0.559701 -0.779401 -0.735167 -0.154171 -0.120061 -0.891403 0.060637 -0.596646 0.546576 0.520424 -0.414689 -0.51721 -0.0422088 -0.954996 0.571344 -0.60528 -0.94626 0.215277 0.161071 -0.886352 -0.910453 0.0169758 -0.688292 -0.124901 0.785183 0.574943 -0.929269 -0.230797 0.999175 -0.872052 -0.572577 0.700937 0.648769 -0.142348 -0.903098 -0.453534 -0.418302 0.423326 0.274068 0.771412 -0.0537767 0.866829 0.76401 -0.464802 0.120305 0.82436 0.149729 -0.0388218 0.73833 -0.869984 0.850054 0.0359757 0.643571 0.494579 0.388019 -0.56171 -0.66662 0.123966 -0.500079 -0.824343 -0.732543 -0.632338 -0.711368 -0.474381 -0.288127 0.321779 -0.43246 -0.980847 0.974367 0.504207 0.198892 0.783475 -0.136969 -0.0373049 -0.983065 -0.378601 0.847571 -0.87105 0.257357 -0.597911 0.912092 -0.477109 -0.776674 0.446539 0.983436 0.615028 0.775835 -0.539534 0.182566 -0.894982 0.277046 -0.115024 0.768079 -0.464715 -0.819503 0.247896 -0.878586 -0.386712 0.534164 -0.308546 0.262043 0.158953 -0.484295 0.458614 -0.0780261 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.487784 0.340885 -0.753381 -0.074213 0.702914 -0.119481 -0.119682 0.501565 -0.203106 0.400828 0.717592 -0.357648 -0.103788 0.0767763 0.674239 0.905884 0.89694 -0.318939 0.361283 0.987895 -0.276351 -0.412715 0.597936 0.0127247 0.597975 0.693684 -0.035951 -0.575828 0.0296414 0.567324 0.10634 0.0133254 -0.516819 0.952268 0.981138 0.234904 0.438667 0.191894 0.627284 -0.00440066 0.900606 0.0460218 0.735248 -0.19161 0.812129 0.0979853 0.278931 0.133519 -0.580614 0.806991 0.546205 0.856039 -0.6571 -0.208042 -0.661166 0.628531 -0.285049 -0.811585 -0.302782 -0.854643 0.0137022 0.292426 0.802906 0.437416 -0.348677 -0.21507 -0.683173 -0.0882778 0.314741 -0.154051 0.858788 -0.35396 0.995459 0.68542 0.0243775 0.928916 0.420713 0.158005 0.614772 0.522331 0.739243 -0.627128 -0.392231 -0.612039 -0.568955 -0.937189 0.977137 0.659179 0.671509 0.36271 0.570741 0.129078 -0.578033 0.991996 0.476499 0.517728 -0.546917 -0.0406654 0.536344 0.339555 0.896415 0.88725 0.804001 -0.23378 -0.157986 -0.19481 0.134139 0.485531 0.00666712 0.40506 -0.161315 0.772499 -0.612507 -0.398534 -0.167052 0.354228 -0.491885 0.89299 0.479495 0.868033 -0.972997 0.84004 0.550763 0.674532 0.867053 0.568055 -0.706879 -0.509389 -0.0571394 0.973199 0.77123 -0.0998086 0.844484 -0.550131 0.596749 -0.699636 -0.962768 0.750514 -0.11304 0.137052 -0.562276 -0.171276 -0.627466 0.172435 0.109444 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.576392 0.573358 0.424886 -0.941216 0.984702 -0.118801 -0.695484 -0.999856 -0.580666 0.750298 0.250829 -0.319319 -0.794968 0.977433 -0.285968 -0.265533 -0.819249 0.876151 -0.536794 0.105432 -0.00641767 0.138239 -0.618605 -0.898035 0.724502 0.709511 0.746455 -0.326485 0.76934 0.301481 0.9937 -0.888131 -0.813805 0.3853 -0.26118 0.35314 -0.782814 -0.756302 0.837046 0.231216 0.0441194 -0.484736 -0.951346 0.733387 0.0299368 -0.85212 0.422841 0.681927 -0.85745 0.839776 0.11905 0.875845 0.330939 0.0962524 -0.286132 0.975828 0.741186 -0.887817 0.464706 0.309589 -0.740415 -0.148084 -0.854007 0.704836 0.172541 -0.102763 0.863629 -0.991683 0.791822 0.144361 0.269553 0.37697 -0.27048 0.036722 -0.81306 0.896863 -0.428467 0.756624 0.581384 -0.674351 0.188596 -0.26943 -0.307177 -0.719916 0.369207 -0.738451 0.857812 -0.74928 0.850758 0.697098 0.119024 0.433436 0.762851 -0.761401 -0.86079 0.709432 -0.583699 -0.225882 -0.400009 -0.95764 0.939564 -0.753521 -0.422687 -0.104249 -0.119723 -0.182069 -0.0289001 0.275934 -0.371249 0.424455 -0.188449 0.729806 -0.158365 0.365055 -0.527234 0.774876 -0.658406 0.165279 -0.149717 -0.285995 -0.713327 -0.885336 0.162036 -0.662742 -0.704824 0.0247774 0.433478 -0.542246 0.478809 -0.664232 0.254645 -0.180689 -0.839728 0.691464 -0.55943 -0.332562 0.62871 0.726773 0.875427 -0.706642 -0.524375 0.829675 0.356101 0.982564 -0.0535915 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.712819 -0.347925 0.421307 0.914185 0.708885 0.231243 0.499802 0.171441 -0.587066 -0.821332 -0.130432 -0.172455 -0.451425 0.901202 0.496484 0.398949 -0.85599 -0.625307 0.457251 -0.977184 0.464107 0.239885 -0.257076 -0.668623 0.457555 0.132026 0.962962 0.50632 -0.277953 0.439305 -0.606426 -0.201617 -0.572572 0.785978 -0.0616252 0.265532 0.789587 0.595632 0.792623 -0.389432 0.818588 0.0064449 0.31951 0.000758144 0.74212 0.804414 -0.219329 -0.261565 -0.128002 0.67022 0.386703 -0.675602 -0.842361 0.438574 -0.884137 0.31478 0.510971 -0.112278 0.941478 -0.585531 0.983366 -0.575331 0.40441 0.913746 -0.667499 -0.660233 -0.538788 0.587503 0.160604 -0.730283 0.130607 -0.883562 -0.0311116 -0.891994 0.254441 0.39061 0.981438 -0.977768 0.652375 0.471797 -0.514984 0.668588 0.958425 0.255147 0.256685 0.103536 0.121163 0.388293 0.0430748 -0.0412854 0.116175 0.560741 0.369599 -0.154048 0.914355 -0.435664 -0.206753 -0.898395 0.672074 -0.460496 0.4378 0.0977937 -0.380506 0.842245 -0.395714 -0.770544 -0.537702 0.850539 -0.990782 -0.0652027 0.138354 -0.683113 0.923124 0.943102 0.721736 0.215336 -0.843869 -0.908891 0.261422 -0.287951 0.403807 0.783967 0.131778 0.792775 0.174361 0.493379 0.220311 0.764326 0.0234586 0.268214 -0.132028 -0.999918 0.372244 0.309622 -0.185228 0.879531 0.276339 0.427894 -0.385171 0.423997 0.114614 0.313603 0.720259 -0.610987 -0.860074 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.494542 0.749242 0.513099 -0.351593 0.769178 -0.433459 0.850558 -0.679182 0.980294 -0.191348 0.0128852 0.517526 0.583654 -0.244352 0.534864 0.66297 0.953778 -0.98725 -0.244863 0.456841 -0.763285 0.652204 0.274865 -0.685412 0.98775 -0.470312 0.0198411 -0.191171 -0.563987 -0.617106 -0.602297 -0.340344 -0.549307 -0.696084 0.00807483 0.873792 -0.37074 -0.872061 0.576177 -0.582273 0.0652538 -0.915999 -0.293766 -0.988585 0.462328 -0.088392 0.106186 -0.745962 0.0259611 -0.43306 0.958998 0.880719 0.895477 -0.287156 -0.257879 0.192531 -0.132149 0.979172 0.947666 -0.585465 0.0950074 0.789021 -0.926836 0.661184 0.525368 -0.135325 -0.41559 -0.825843 0.0634961 -0.82073 -0.00131022 -0.0209065 0.62472 -0.339126 -0.162456 -0.0538641 -0.303031 0.45657 0.244081 0.60894 0.357256 0.490672 0.0220065 -0.406877 0.108737 0.0124452 0.629472 -0.270947 -0.241064 -0.332317 0.265578 -0.354098 0.667913 -0.38945 0.513078 -0.702653 0.510153 0.134208 -0.35976 -0.486384 -0.65307 -0.424762 0.857345 -0.00174042 -0.000461004 -0.613194 -0.405654 0.881663 0.18746 0.938033 -0.476386 -0.618675 -0.0718652 0.160885 0.000866607 0.565069 -0.887821 0.394738 0.361763 0.148005 -0.480264 0.206891 -0.79029 -0.406328 0.846668 -0.0462394 0.853828 0.282351 0.561223 -0.561053 -0.698523 -0.218358 0.516389 -0.889309 0.0744872 -0.165092 -0.812979 0.256773 -0.422399 0.737409 -0.371693 0.960822 0.536812 0.203084 -0.773974 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.176438 0.606806 0.582534 0.646623 -0.21074 0.100684 0.190803 0.824618 -0.649587 0.399687 -0.457925 -0.353598 -0.927647 -0.957199 0.355581 0.245315 -0.998746 0.083957 -0.934103 0.536202 -0.056003 0.757968 -0.834563 -0.497524 0.108113 -0.937347 0.0127203 -0.209317 0.00736168 -0.272326 -0.978835 0.720191 0.251638 -0.720674 -0.363482 0.96017 -0.418446 -0.814306 -0.0367185 0.872697 -0.578917 0.141022 0.157381 -0.895035 -0.85665 0.29138 -0.781428 0.545789 -0.920217 -0.0833765 0.691206 -0.901875 0.188762 0.526901 -0.381624 0.0392828 0.226743 0.864408 0.0992505 0.103915 0.498637 0.585717 0.151972 0.191715 0.154926 -0.167096 -0.383987 0.337786 -0.823421 0.764451 0.131131 -0.0792882 -0.59634 -0.684791 0.720348 0.894337 -0.881903 -0.136758 -0.484384 0.963542 0.258305 -0.66934 0.406183 0.721256 0.152423 -0.230121 0.353655 -0.112089 0.117653 -0.604969 0.291272 -0.592293 -0.667631 -0.879666 -0.550901 -0.992186 0.321593 -0.994537 0.808712 0.0159932 0.79702 -0.483947 0.304239 -0.662533 0.808981 0.54552 0.554983 -0.392516 0.98539 -0.558346 -0.124013 -0.288757 0.8676 -0.239045 0.368301 0.0360052 -0.859846 0.567237 -0.454288 0.78916 -0.585406 -0.915661 0.48082 -0.858058 0.624361 -0.36815 0.495418 0.494345 0.463017 -0.0778421 -0.291754 0.496305 -0.597313 0.954122 -0.0780673 -0.0765545 -0.65189 -0.308706 -0.415076 -0.183011 0.136774 0.759888 -0.570324 0.560247 0.0712838 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0408358 -0.919979 -0.0878428 -0.374116 0.238423 -0.828588 -0.0775213 -0.899902 -0.649158 -0.400272 0.623953 -0.614289 0.351311 -0.0164367 0.676018 -0.0251838 -0.467616 -0.243086 0.358605 -0.291114 0.46211 -0.391117 0.538591 0.709244 -0.546122 -0.296711 0.127951 -0.546754 0.993865 -0.865893 0.686506 0.739819 -0.225892 -0.874516 -0.642538 0.084198 0.716743 0.945852 -0.323335 0.547617 0.275873 -0.453656 0.18086 -0.171673 -0.5593 0.0597999 -0.314159 -0.808822 0.42716 0.774001 -0.557164 0.432092 0.462755 -0.627159 0.59526 0.294164 0.0132325 0.397952 0.37293 -0.162293 0.345952 0.407018 0.74766 -0.0867426 0.117106 0.202788 0.265266 0.333472 0.662122 0.279114 -0.932345 0.071088 0.776607 0.432007 -0.561085 0.388666 0.840568 0.435521 0.599582 -0.529325 0.278207 0.828377 0.865568 -0.509789 -0.69341 0.979642 0.215995 -0.313591 0.734617 0.132046 0.92627 -0.751417 0.932717 0.170629 -0.233656 0.946692 -0.951373 0.269314 0.365251 0.774695 0.304576 -0.284245 -0.261388 -0.717817 0.15679 -0.683854 0.780951 -0.0429716 0.400595 0.0546649 0.75332 -0.948928 -0.637958 -0.164289 0.787936 0.837488 -0.331323 -0.543506 -0.702211 -0.0617778 -0.298763 0.696378 0.0230258 0.994198 -0.509235 -0.720894 -0.0679685 -0.347638 -0.108366 0.48388 -0.88463 0.0448108 -0.395574 0.388764 0.0720284 -0.822522 0.571004 0.862323 -0.932564 0.390425 -0.129779 0.805311 0.868643 -0.715147 0.525128 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.176753 -0.687858 -0.83575 -0.443527 -0.363388 0.540299 0.797905 0.389035 0.507617 -0.487604 0.842884 0.354947 -0.414013 -0.30929 -0.230345 0.593821 0.34526 0.787239 -0.880246 -0.286184 0.10084 0.816472 0.437162 -0.620043 0.932446 -0.377446 0.263823 0.0706472 -0.633337 -0.493225 0.364974 0.113232 -0.917378 -0.370135 -0.866437 -0.212062 -0.12417 -0.927699 0.166968 0.224785 -0.0350817 0.382291 -0.832047 -0.218726 -0.13271 -0.448738 0.0557835 -0.447162 0.551988 -0.739252 -0.6073 -0.883025 -0.993972 0.318126 0.742401 -0.467458 -0.558454 0.0705217 -0.741103 0.275823 -0.237979 0.294302 0.341311 0.417639 -0.734298 0.65785 0.484996 -0.679662 0.921466 -0.914875 -0.298235 -0.440228 -0.905751 -0.955995 0.599768 0.306544 0.0863848 -0.131201 0.899291 0.380946 0.559153 -0.318039 0.723744 -0.0325385 -0.874118 0.693292 0.158757 0.224388 -0.705888 0.148567 0.97158 -0.658671 -0.287518 -0.311205 -0.422847 -0.788584 0.260473 -0.229107 -0.603048 0.572243 -0.306731 0.779718 0.717771 -0.427247 -0.735972 0.521505 0.928976 -0.705326 -0.408308 -0.427078 0.0997722 0.871358 0.916577 0.914274 0.210358 -0.507177 -0.130346 -0.71805 -0.258103 0.0606465 -0.714901 0.665747 -0.794558 -0.136098 0.603046 -0.608902 0.183731 -0.035047 0.965011 0.945507 -0.868857 -0.878487 -0.73131 0.880961 0.306783 0.103347 0.953941 0.886961 -0.852343 0.671427 0.673936 0.843462 0.0720414 0.799141 -0.830937 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.118528 -0.128484 0.567658 0.630017 0.690383 -0.73744 -0.154646 0.85985 -0.50594 0.658244 -0.888575 0.732722 -0.451702 0.407272 -0.688713 0.243646 0.617169 0.0190577 -0.906286 -0.395625 0.196835 -0.941079 0.21343 -0.792458 -0.51369 0.368657 0.986197 0.158641 0.057288 -0.782669 -0.953345 -0.95971 0.417287 -0.524936 -0.292557 -0.579346 0.0395381 0.644102 -0.280076 -0.091314 -0.707253 0.569948 -0.929712 -0.370012 -0.526173 0.606934 -0.82033 -0.0542728 0.456139 -0.650759 -0.80099 0.307249 -0.839991 -0.481856 0.603554 -0.683203 -0.598181 0.364768 0.647997 0.885393 0.794988 -0.633448 -0.365167 0.630654 -0.590152 -0.690532 0.230951 -0.40046 -0.531547 0.29739 0.240768 0.581345 0.663883 -0.121601 0.766082 0.0714688 0.612666 0.0553245 -0.643898 0.772037 0.663029 0.957559 -0.705372 0.347395 -0.67318 -0.517462 0.735582 -0.191172 -0.998738 0.487604 -0.320438 -0.312245 0.0983035 0.186097 -0.262534 -0.410935 -0.591843 0.89056 -0.365372 -0.800676 -0.965803 -0.243304 -0.663878 -0.605914 0.75439 0.43208 0.225159 -0.700462 -0.61184 0.296544 0.00810815 0.273642 -0.906006 0.764672 -0.158184 -0.593947 -0.467349 -0.732343 -0.480446 -0.862486 0.193805 -0.724008 -0.39667 -0.832477 0.564297 0.137483 0.681874 0.256655 -0.297218 0.402788 -0.274706 -0.202905 -0.554307 -0.963303 -0.754797 0.205843 0.47214 -0.746167 -0.827772 -0.358585 -0.732612 0.987381 0.919778 0.707775 -0.428903 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.576183 0.0923126 -0.502507 0.368592 0.926218 0.948622 -0.514454 -0.423157 0.00425029 -0.565339 0.348245 0.952779 -0.650428 0.264075 0.302944 -0.417492 -0.78072 0.431414 0.783276 0.51765 0.135153 -0.478038 -0.377492 -0.508061 -0.975246 -0.963844 0.678864 -0.336583 -0.955479 -0.739697 -0.0817013 0.846241 0.766383 0.599935 -0.88681 -0.621258 0.515812 -0.7423 0.171023 0.388799 0.53996 -0.884681 -0.831256 -0.915933 -0.092691 0.14161 0.031019 -0.663043 0.239357 0.876712 0.90655 0.389832 -0.0910252 0.139319 -0.47334 0.569944 -0.959306 0.950072 -0.134484 -0.270085 0.677052 -0.787483 0.766111 0.0278643 0.31581 -0.183221 0.612544 -0.969189 0.841881 -0.511458 -0.0812574 0.306586 0.79525 -0.227578 -0.904257 0.157995 -0.581086 -0.308696 -0.257187 -0.539673 -0.281456 -0.432351 -0.524077 -0.157128 -0.850629 -0.517094 -0.794288 0.40664 0.396796 0.944313 -0.933695 -0.619763 -0.364876 -0.477458 -0.632598 -0.0726832 0.41321 0.826819 0.345786 -0.371155 -0.0102244 0.158406 0.327876 0.619921 -0.99086 0.623787 -0.0196134 0.358156 -0.477775 0.037629 0.430516 -0.322415 -0.830321 0.791574 -0.0149633 0.512044 -0.0715109 0.116909 0.888399 -0.672634 -0.964424 0.917753 0.681742 0.0418365 -0.853433 0.35766 -0.802621 0.344683 -0.905861 -0.798541 0.921381 -0.34325 -0.996874 -0.456371 -0.224028 0.76104 0.79659 0.287728 -0.155361 0.840362 -0.0317615 0.183787 0.915919 -0.141427 -0.963004 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.929923 0.602996 0.561503 -0.821812 -0.1992 0.0510274 -0.381659 -0.542608 0.392194 -0.391298 -0.537784 0.860282 0.883504 0.81889 0.560629 0.5042 -0.261497 0.453805 -0.990887 0.064951 0.740824 -0.107441 0.92254 -0.0352962 -0.955809 0.362238 1.00065 0.812816 -0.432573 -0.54975 -0.437253 0.455742 -0.895941 -0.258541 -0.4682 -0.830599 0.6322 -0.58368 0.929511 0.507968 -0.868782 -0.293103 0.0767097 0.730363 0.21288 -0.509086 0.519239 -0.33308 -0.29194 -0.795033 0.802697 -0.389659 0.601956 -0.524922 0.329527 -0.648562 -0.379029 -0.341215 -0.801745 -0.92166 -0.338187 0.0904424 0.065636 -0.856184 0.122695 0.138598 -0.589452 -0.92141 -0.13707 0.25974 -0.553463 -0.0518684 0.248066 -0.759567 0.490284 0.870178 -0.619121 0.0595777 -0.47309 -0.53728 0.136436 -0.796287 0.161255 0.636845 -0.341435 0.368826 -0.786024 -0.292723 0.432482 -0.0722761 0.93333 -0.357257 -0.416346 0.467249 -0.952409 0.866944 0.727199 0.0268966 0.0518789 -0.0715341 -0.273887 0.943535 0.442389 -0.282845 0.784038 -0.38833 -0.989915 0.0735055 -0.270522 0.111699 -0.68105 -0.404151 -0.560203 0.666759 0.210389 0.0130727 -0.287417 -0.609862 0.0507663 -0.770014 0.378051 -0.090435 0.0586311 -0.586816 -0.621389 0.308197 -0.132352 -0.444299 -0.888205 0.754528 0.422185 -0.893972 0.998326 0.0532179 -0.422079 0.0664074 -0.516778 0.520318 0.983208 0.769307 -0.262503 0.117611 0.681141 -0.0596113 0.112638 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.898065 0.224006 0.867959 -0.213899 0.997579 0.304508 -0.138485 0.490493 -0.286774 0.181042 0.774605 0.780965 -0.323854 0.983302 0.35723 -0.0345152 -0.096148 0.0410077 -0.783744 -0.382211 0.172297 -0.19813 0.0329248 -0.63347 -0.731911 0.769902 -0.25555 0.964286 0.758206 -0.827931 0.957738 0.696758 0.41119 0.872241 -0.243468 0.0281865 -0.269172 0.023169 -0.598661 0.305188 -0.703157 0.0358069 -0.193566 0.730999 -0.0973297 0.178966 -0.117854 -0.77067 -0.643903 -0.0728549 -0.472669 -0.154105 -0.0495093 -0.103501 0.464187 -0.414042 -0.809817 -0.598048 0.611045 -0.165277 0.191337 -0.196048 -0.97757 -0.0132627 -0.905867 -0.912305 0.888093 0.177787 0.0648087 -0.760934 0.98524 0.920499 0.819066 0.0351728 -0.851297 0.254164 -0.268146 -0.728484 0.375721 0.740246 -0.685014 0.963926 0.702162 -0.768397 -0.440577 -0.775324 -0.877119 0.25386 0.632505 0.510274 0.171991 0.66029 -0.506223 -0.0835181 0.312021 0.136681 -0.806764 0.721396 0.509271 -0.677524 0.851592 0.705939 0.709062 -0.797679 -0.598912 0.0862742 0.0106151 0.408403 0.0317185 -0.907069 0.887851 0.119971 0.352412 0.991614 0.0648398 -0.236755 0.860138 0.342558 -0.629699 0.653666 0.159167 -0.885621 -0.624869 -0.172406 0.367119 0.175388 -0.254079 -0.301053 0.203836 -0.121928 0.759572 0.125824 0.7166 -0.0995146 -0.541795 0.0508991 -0.538825 -0.040078 0.408448 0.790141 -0.106171 -0.422796 0.0696552 0.694321 -0.549475 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.873948 -0.172502 0.757642 -0.307668 -0.977377 -0.783383 -0.313003 -0.640678 0.128337 0.954529 0.769335 0.175837 -0.976917 -0.886973 -0.900264 0.274456 0.130042 -0.99504 -0.634498 0.459949 -0.59276 0.721189 0.294321 -0.464827 -0.041745 0.352734 -0.837127 -0.827383 0.820156 0.559581 -0.0769718 -0.315666 -0.704489 0.266157 -0.757808 0.0400596 -0.655117 0.387358 -0.581893 -0.173645 0.148247 0.19781 -0.592466 -0.093328 -0.944466 0.174013 0.0434488 0.252 -0.0636704 0.911728 0.913676 -0.312199 0.441971 -0.658644 -0.151931 -0.745514 0.142403 -0.630171 0.713877 0.125398 -0.440145 0.485496 -0.272623 0.024263 -0.211405 0.921576 0.929597 -0.261552 0.0884754 -0.99456 0.429915 -0.412953 -0.500574 0.849331 0.36975 -0.287341 -0.150676 -0.507049 0.608562 0.471165 -0.515296 -0.310954 -0.846387 0.421494 -0.675219 0.27187 0.738377 -0.55584 -0.177073 -0.596843 -0.775101 0.989882 0.94508 -0.0420061 0.0033194 -0.210893 -0.476352 -0.0459257 0.126547 0.869574 0.934891 -0.462912 0.983375 -0.786089 -0.960481 0.417615 0.215288 -0.344 -0.861261 -0.700369 0.902861 0.383136 -0.626624 0.337474 -0.0693423 0.563512 0.950928 0.241085 -0.0823704 -0.399876 -0.721365 0.0209965 0.888822 0.431408 0.6751 0.402342 0.15839 0.0595934 -0.286424 -0.962352 0.773722 -0.232111 -0.55634 0.337781 0.278197 -0.113091 0.315285 0.990529 -0.180337 -0.916137 0.486403 0.974412 0.944688 -0.635707 -0.320116 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.183632 -0.295197 0.622089 -0.550016 -0.125497 0.768589 -0.326287 0.0879086 -0.519439 -0.215162 -0.224592 -0.718728 0.335324 -0.214834 -0.714155 -0.803626 -0.535793 0.921952 -0.761034 -0.705961 0.919859 0.0649925 0.328165 -0.523629 -0.63641 -0.139264 -0.605152 -0.784616 0.952362 0.351061 0.280086 -0.59948 0.54424 -0.965294 0.309898 0.452475 0.752802 0.344533 0.571168 -0.372229 -0.055124 -0.468978 -0.105664 0.108651 0.0971321 0.499992 -0.627167 -0.791751 -0.953078 -0.376669 -0.668457 -0.758339 0.595553 -0.533352 -0.0476502 -0.85752 -0.333506 0.763078 -0.940426 0.255062 0.828623 0.666409 0.329233 -0.583979 -0.929201 0.913904 -0.020856 -0.526417 0.513019 0.302615 0.0572796 0.697757 -0.791527 0.797741 -0.36555 0.204626 -0.848014 -0.574848 0.532532 0.272849 -0.226502 -0.813823 0.0722297 -0.035781 0.629041 0.294609 -0.511333 0.0316744 0.352478 0.0977153 0.300438 -0.536569 -0.116717 0.336221 0.872105 -0.530725 0.109602 0.0754163 -0.477886 0.176205 -0.517016 0.507754 -0.177698 -0.568172 0.73216 -0.579476 0.744229 0.259745 -0.469971 -0.806744 -0.954357 0.119834 0.0509744 0.726558 -0.747415 0.188151 0.26077 0.766308 -0.663632 0.337294 0.899474 -0.547987 -0.0127798 -0.789609 -0.964489 -0.168578 0.710597 -0.999305 0.673656 0.134039 0.78648 0.363774 -0.0440208 0.143143 -0.191347 0.0343864 -0.0669822 0.229727 -0.971258 0.0722491 0.290954 0.0686206 -0.6944 -0.785625 -0.00169807 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.539411 0.116353 -0.455362 0.729782 -0.557697 0.780952 -0.533194 0.610545 -0.573928 -0.00824384 -0.554214 -0.679308 0.866862 -0.655658 0.352034 0.63629 0.119356 0.0174098 0.607011 0.0350897 -0.247365 0.543515 0.854481 -0.739016 -0.644089 0.800589 -0.503655 -0.924269 -0.190711 0.712826 0.45884 -0.267774 -0.475559 -0.719215 0.146046 0.589787 0.54486 -0.542166 -0.190004 0.598153 -0.836103 -0.37975 -0.460317 -0.540533 -0.740658 -0.23287 0.154379 0.641444 0.743787 0.824083 0.371345 -0.800045 -0.354395 -0.311552 -0.254854 0.671674 0.820112 -0.382513 -0.896419 -0.12047 -0.731574 0.44319 0.697848 0.728713 -0.513063 0.945865 -0.841848 -0.943216 -0.62874 0.761054 -0.971358 0.383146 -0.457558 -0.183226 0.516828 0.323662 -0.21121 0.197428 0.175429 0.435737 -0.560406 -0.743065 -0.6993 0.863877 -0.811493 -0.770927 -0.96337 0.643415 -0.117253 -0.665716 -0.681044 -0.305945 -0.0240375 0.00234142 -0.647755 -0.823632 -0.787546 -0.294018 0.445234 -0.958713 0.90451 0.0936333 -0.304732 0.366347 -0.810547 -0.855206 0.545674 -0.862158 -0.291673 -0.14618 -0.841809 -0.280322 0.621915 0.531844 0.694816 -0.231845 -0.614476 0.495767 0.358346 0.729236 0.277076 0.823392 0.742143 -0.799447 -0.302644 -0.542577 0.907075 -0.783291 -0.775121 0.534692 0.574148 -0.294548 -0.468516 -0.344066 -0.709941 0.0296807 0.843424 -0.571411 0.288351 0.321893 0.055803 -0.119675 0.619195 0.80985 -0.851179 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.00585984 -0.865779 0.853047 -0.842386 0.0113483 0.731084 -0.668548 -0.282431 -0.810234 0.397414 -0.657356 -0.884096 -0.0078915 -0.61172 0.302071 -0.568777 0.603155 0.238564 0.223455 0.885221 0.565926 -0.0990937 -0.778342 -0.816392 -0.617484 0.704452 -0.667525 0.312952 0.462978 0.66319 0.291424 -0.644318 0.0946065 0.365353 -0.3393 -0.610879 -0.681305 -0.872173 -0.850048 0.39278 -0.515865 -0.819816 -0.188367 -0.73817 0.486897 -0.540967 0.977698 -0.395704 0.0050809 0.894469 -0.137111 0.0445296 -0.594529 0.793107 -0.575214 -0.817302 -0.40133 0.8477 -0.706151 -0.285838 -0.0761066 0.876984 -0.534965 0.837612 -0.259902 -0.174042 0.869625 -0.214061 0.271498 -0.937858 -0.584312 -0.523459 0.22909 0.316575 0.193188 0.622189 -0.848616 0.753077 0.913012 0.854081 0.0538374 -0.117093 -0.541416 0.445452 -0.582068 0.368726 0.692519 0.877466 0.552541 0.0977396 -0.600703 -0.675557 -0.0930957 -0.65974 -0.253011 -0.35619 -0.484788 0.164384 0.804856 -0.792997 0.103925 -0.816473 -0.640866 -0.240553 0.630775 -0.864772 -0.335794 -0.0349486 -0.682117 0.263272 0.811348 0.324889 0.406139 -0.0196036 0.522322 0.658869 -0.385133 -0.924317 -0.996843 0.0575712 -0.400556 -0.148662 -0.566547 0.0466744 0.456486 0.16622 -0.343534 0.219311 0.3282 -0.327641 0.0704597 0.622929 0.883738 -0.72068 -0.470289 0.837922 -0.42448 -0.242705 0.853446 -0.138835 0.599178 0.380125 0.763549 0.970499 -0.822532 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.289281 0.0543573 -0.416122 0.237399 -0.0429532 0.085173 -0.496651 0.791572 -0.0530464 0.449167 -0.847009 0.325367 0.443022 -0.128035 0.116473 -0.437959 -0.774569 -0.173795 -0.974542 0.877594 -0.279995 0.116794 0.949823 -0.319682 -0.891522 0.197376 -0.69743 0.289301 0.28922 0.925021 0.836246 0.783745 0.396549 0.804931 0.46708 0.214117 0.663049 -0.13486 -0.584165 -0.0642883 -0.493271 -0.400821 -0.596263 0.613056 -0.368244 0.924916 -0.930526 0.654222 -0.482515 0.372249 0.394303 -0.94636 0.529117 0.870766 0.969403 0.753225 -0.553256 -0.56915 0.300714 0.0973928 0.881491 -0.774928 -0.219384 0.819478 0.96799 -0.995502 0.605513 0.860916 -0.592101 0.553827 0.178538 0.6894 0.740515 -0.159213 0.109902 -0.874541 -0.404708 0.0664049 0.0671087 -0.104633 -0.573128 -0.559114 0.979367 0.219354 0.682264 0.810266 0.138269 -0.107512 -0.954318 0.774463 0.397726 0.578127 0.584219 0.970958 0.882952 -0.233813 0.296746 -0.594136 0.352062 -0.900217 0.0502455 0.475801 0.785124 -0.423576 0.953568 0.619776 0.580743 0.55273 -0.261405 0.560622 0.372732 0.505458 -0.761182 0.817776 0.36369 0.54105 -0.573575 -0.0775464 0.677036 0.944166 0.598431 -0.167423 0.120086 0.293743 0.939963 -0.0349897 -0.0715313 -0.226622 -0.831273 0.787353 -0.953315 -0.367366 -0.312782 -0.934548 -0.941315 -0.678777 -0.212596 0.904494 -0.168096 0.808557 -0.586838 -0.988258 0.34284 0.112565 -0.128214 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.885534 0.823416 -0.841635 0.643202 0.299601 -0.611261 0.534295 -0.0958439 -0.848342 -0.0819352 0.915603 0.543044 0.938969 -0.742566 -0.310904 0.643663 0.040099 -0.0557295 -0.645105 -0.273168 0.866941 0.684201 -0.641711 0.756239 0.104641 0.70292 -0.0182079 -0.0207036 0.0344338 0.729601 0.40888 0.049646 0.399977 0.405913 0.172523 -0.399273 -0.577013 0.145081 0.372923 -0.275196 0.78182 0.0446398 0.260856 0.21309 -0.588116 -0.462845 0.962861 0.803521 0.782405 -0.121856 -0.0329288 0.565005 0.0393404 -0.805261 -0.0158037 0.387921 -0.213168 -0.718371 0.333719 0.818284 0.895356 0.251585 0.389045 0.686966 -0.167651 0.294448 0.78137 0.48 -0.640576 -0.15592 -0.542328 -0.898304 0.209642 -0.546638 0.659398 0.502711 -0.929044 -0.436009 -0.0104128 0.991732 0.0341891 0.616876 -0.172638 0.475254 -0.409749 -0.646279 -0.00405527 -0.156915 0.729732 0.600999 0.994878 0.917091 -0.444036 -0.920881 0.755063 0.337721 0.0790873 -0.77958 -0.4032 -0.587288 -0.546042 0.66851 -0.346183 -0.30491 -0.616893 -0.121555 -0.98071 -0.794313 -0.0121804 -0.716399 -0.518899 0.863145 0.874294 0.253226 -0.0230499 0.600944 0.0594548 -0.742423 0.0966441 0.298051 -0.650687 -0.102147 -0.787532 -0.0482697 0.731781 -0.951596 0.518652 0.984888 -0.986281 -0.432704 -0.458437 -0.948063 -0.0973938 -0.896925 -0.61759 0.165688 0.722462 0.415018 -0.792014 0.622504 0.417863 -0.980411 0.231782 -0.444635 -0.978485 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0238429 -0.0169891 0.463754 0.305759 0.898123 0.752772 -0.162772 0.291741 -0.709214 0.243325 -0.442157 0.959104 0.675782 0.0854486 0.506268 0.578408 0.602853 0.477034 0.448797 0.364262 -0.144647 -0.573914 -0.439605 0.952734 0.137036 0.949445 -0.680954 0.449426 0.786561 -0.0676538 0.126214 0.803139 0.248933 0.0413366 -0.166904 0.802336 0.475203 0.834988 0.0984046 -0.593417 -0.131221 -0.935204 -0.835001 -0.894224 -0.839485 -0.10133 0.362781 -0.37876 -0.575752 -0.753479 -0.249447 0.571896 -0.599693 -0.0885479 -0.766933 -0.698647 -0.159827 -0.22053 -0.441076 0.83905 -0.0925277 0.886552 0.279454 0.791611 0.600127 0.32989 0.461971 0.348077 0.131122 -0.232262 0.366053 0.253582 -0.0551302 -0.575835 -0.660013 0.327538 0.423998 -0.565908 0.749367 -0.602741 -0.107919 0.671121 0.403111 0.805829 0.8309 -0.400901 -0.354047 -0.850065 -0.21 -0.776062 -0.329848 0.982872 -0.862627 -0.170228 0.971706 -0.540292 -0.691325 0.892564 -0.674339 0.3851 0.380931 -0.569263 -0.932946 -0.911332 0.888462 0.0537054 0.185866 0.624625 0.965957 -0.910815 -0.0602939 0.640761 -0.72485 -0.546057 0.421886 0.635037 -0.939823 0.40015 -0.682741 -0.82259 0.735741 -0.397138 -0.70474 -0.561436 -0.0543211 -0.974423 0.87324 0.538395 -0.0842816 0.145218 -0.00410491 -0.490761 0.102365 -0.985557 0.0776925 -0.370992 0.119761 0.816959 0.63735 -0.0609873 0.987251 0.719379 0.595563 -0.376449 -0.978074 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.48202 0.684339 -0.319346 0.753341 -0.594472 0.708467 -0.799247 -0.947589 -0.134329 0.330226 0.107163 -0.919184 -0.727557 -0.0575055 -0.494533 0.390517 -0.585276 -0.73835 0.556557 0.0537876 0.00836216 0.542832 -0.621027 0.400665 -0.0150211 -0.459146 -0.858717 -0.458733 0.0762287 -0.824659 -0.0477743 -0.942762 -0.998703 0.792243 -0.764276 0.81786 -0.219064 0.192954 0.9718 -0.959757 -0.63501 -0.612619 -0.280197 0.728696 -0.810966 0.0914974 -0.202832 0.998163 0.119135 0.298585 0.32237 0.0765636 0.80405 -0.333617 0.89375 -0.741124 -0.0761442 0.244613 -0.788247 -0.0724216 0.809439 0.233175 0.96737 0.580949 0.00237476 -0.0874499 0.229696 0.50868 -0.613773 0.317294 0.767354 0.922674 -0.623557 -0.116446 0.900153 0.870185 -0.798297 -0.983267 0.224379 -0.866297 0.150062 0.0848961 0.848225 0.115184 -0.098688 -0.649301 -0.799821 -0.598661 0.305298 -0.861628 0.614281 0.227536 0.18974 0.968099 0.837591 -0.613748 0.73948 0.441798 -0.703826 0.79916 -0.520591 0.4345 0.644962 -0.120011 0.982049 -0.702043 0.769771 -0.453164 -0.320473 -0.193845 0.0496251 0.0485413 -0.166926 0.471136 0.375203 0.0429584 0.00177792 -0.118523 -0.0164422 -0.343988 0.59484 -0.516431 0.340319 -0.256018 -0.888896 0.321601 -0.85396 -0.509538 0.19879 -0.92931 -0.918829 -0.750857 0.352864 0.577025 0.0675617 -0.49122 0.0718 0.742265 -0.758799 0.860236 -0.0108679 -0.657527 0.946192 0.643122 0.947924 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.239576 -0.54969 -0.642828 -0.0123809 -0.0850875 -0.065974 -0.824477 -0.98469 0.316762 -0.187703 -0.719124 -0.322897 -0.935794 0.10283 0.265842 -0.000883807 -0.854144 0.408078 0.567081 0.936964 -0.438686 -0.996242 0.153165 0.243108 -0.0857181 -0.663473 -0.986495 -0.0169465 -0.819273 0.482531 -0.0983107 -0.308643 0.643847 -0.857199 -0.951922 -0.959963 -0.0975679 0.176076 -0.698053 -0.17997 -0.757677 -0.269636 0.223973 0.312396 0.444672 -0.401823 0.566243 0.846401 -0.546308 0.204099 0.29025 0.23994 0.671054 0.397673 -0.307286 -0.548829 -0.170353 0.876227 0.743084 -0.993922 -0.845658 -0.971087 0.938798 0.373542 0.11877 0.172119 0.804887 -0.25844 0.39808 0.538471 0.0806109 0.827392 -0.0187793 0.376717 -0.517804 -0.731677 0.712216 0.222169 -0.0116071 0.919959 -0.249568 -0.483007 0.104927 -0.4959 -0.583618 -0.868539 0.461664 -0.815401 -0.450757 0.133998 0.106916 0.93763 0.745853 -0.447812 -0.370571 -0.191762 -0.951008 0.406362 -0.278176 0.688095 0.805566 -0.854966 0.584597 -0.681982 -0.075469 -0.407198 0.215334 -0.888871 0.748827 -0.469181 0.47379 0.992192 -0.231354 -0.374765 -0.679347 0.220028 0.00922731 -0.916635 0.120186 -0.0272816 -0.521422 0.46357 -0.77603 -0.736714 0.0450512 -0.825219 0.536665 -0.268014 -0.515202 0.999132 0.414152 0.654993 0.473132 -0.0778631 -0.64502 -0.856376 0.889653 0.404467 -0.12563 0.543693 -0.151776 -0.904296 -0.496243 -0.350948 -0.38 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.656315 -0.684117 0.044322 0.920001 0.458781 0.739122 0.431428 -0.989759 -0.886494 0.689497 0.375788 -0.127607 -0.691657 -0.681376 0.112945 0.274633 -0.242601 0.604768 0.335093 -0.086664 -0.562554 -0.846201 -0.0944579 0.445328 0.626142 -0.430316 -0.317412 -0.735717 0.797457 0.862603 -0.226334 0.00856897 0.0186166 0.889141 -0.208484 0.0123677 -0.135804 -0.456559 0.619863 0.0433665 0.86073 0.283628 0.931876 0.0451285 0.474036 -0.875125 -0.228477 -0.00680144 -0.311785 -0.171326 0.531731 0.804779 -0.0815302 -0.277365 0.323508 -0.79842 0.961575 -0.809561 -0.290273 -0.622681 0.604955 -0.52035 0.481234 0.0998507 0.190305 0.453862 0.0568027 0.682491 0.624275 0.18549 -0.477057 0.0971718 -0.833264 -0.659919 0.736858 0.368961 -0.870179 0.902545 -0.933395 0.438513 0.086054 0.309541 0.451466 -0.213937 0.362844 0.326814 0.758675 -0.952506 -0.775263 0.153113 -0.63786 -0.505303 -0.62096 -0.479945 -0.428259 0.258877 0.952352 0.1737 -0.629269 -0.127291 0.61495 -0.536428 0.256817 0.327383 0.320588 0.129384 0.560761 0.703691 0.931052 0.194349 0.421167 0.561078 0.0313508 0.91265 0.916537 0.242772 0.268136 0.556178 -0.311665 -0.147019 -0.95629 -0.367425 0.692392 -0.965874 0.55497 -0.614347 0.678322 0.564402 -0.103352 0.956666 0.688423 0.328353 0.626766 0.0586782 0.204711 0.584352 -0.791937 -0.0926101 -0.497307 -0.232245 0.65854 0.0838 0.426971 0.0986446 -0.080962 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.728115 0.577258 -0.0318072 -0.58376 0.741961 0.133415 0.301258 -0.757135 0.837675 0.801901 -0.442325 -0.156313 0.849337 0.802597 -0.745049 -0.0412297 -0.947321 0.37247 0.102453 -0.0792621 -0.158016 0.220572 -0.847977 0.0536253 -0.720004 0.891432 0.296392 -0.539125 0.93281 -0.25901 0.823535 -0.84541 -0.802403 0.015501 0.525988 0.276939 0.510058 0.539648 -0.131792 0.974062 -0.948146 0.512862 -0.325041 -0.965863 0.744462 0.17858 -0.605617 -0.598604 -0.743 0.396486 -0.267329 -0.999122 -0.248656 0.843075 -0.442988 0.693553 0.541023 0.96733 -0.0841989 0.868836 0.527427 0.472285 -0.313293 0.482899 0.0894516 -0.587203 0.879734 -0.303397 0.808993 0.741524 0.78735 0.987173 -0.580707 0.0643476 -0.510151 -0.103388 0.35557 0.0601426 0.817187 0.462034 -0.596224 -0.736635 -0.630351 -0.317652 -0.773764 -0.650486 -0.725805 -0.5965 0.621357 -0.849406 0.0312266 0.825389 0.314591 -0.674236 0.112552 -0.334971 0.149178 -0.757985 0.53918 -0.00167574 -0.164184 0.564068 0.286205 0.251707 0.434733 0.560182 0.973886 0.10053 -0.387047 0.907959 0.0693889 0.219234 0.669416 0.869609 -0.483335 0.582359 -0.294574 -0.90075 -0.913029 0.719325 -0.299805 -0.825564 0.750646 0.108287 -0.0186902 -0.126099 0.661068 0.566459 0.482453 0.594686 0.880737 0.555041 0.570769 0.91943 0.85592 -0.548476 -0.231641 0.802172 0.106408 0.395383 -0.803772 -0.988828 0.769938 0.351619 -0.33411 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0118629 -0.750697 -0.959984 -0.449567 0.132516 -0.803024 -0.428304 -0.496946 -0.178001 0.345314 -0.3079 0.40878 0.849573 0.176083 -0.425019 -0.044567 -0.711907 -0.200963 0.443287 -0.946855 0.160811 -0.812616 -0.848633 0.977142 0.583644 0.92629 -0.308966 -0.0507817 -0.122535 0.722913 -0.288213 0.128775 -0.579137 0.212712 -0.88013 0.309599 -0.227766 0.060601 0.163546 0.428005 0.0574432 0.583562 -0.204518 -0.109694 -0.960319 -0.38648 -0.013994 -0.950791 0.395285 -0.299928 0.914627 0.011398 -0.909547 0.590966 0.719205 -0.593686 -0.0760513 -0.194793 0.109784 -0.859965 0.563044 -0.914151 -0.132958 -0.628489 0.984648 0.974467 -0.137467 -0.410064 0.0496501 0.46924 0.515338 -0.720375 0.654395 0.41123 -0.0680139 0.716111 -0.324371 0.553078 0.0751761 0.252445 -0.953686 -0.546286 -0.502011 0.0959202 0.647947 0.451978 0.0045483 -0.806701 0.116436 0.787744 -0.869024 0.427486 0.750899 0.363813 0.60131 0.223002 0.00110012 0.489664 -0.211654 0.728395 0.139289 0.540859 0.354934 -0.894146 -0.647328 0.2105 0.0767564 0.138322 0.348661 0.50378 -0.976605 0.203945 -0.298149 -0.989657 0.834055 -0.0431576 0.64982 -0.482605 0.857816 -0.693854 0.401374 -0.106011 0.279258 -0.508988 -0.568191 0.408571 0.859135 -0.515638 0.909245 -0.265876 0.104355 -0.0632546 -0.222474 -0.14051 0.911961 0.97389 0.398832 -0.83243 -0.652174 0.911605 -0.6469 -0.442961 -0.837194 -0.716276 -0.448762 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.339589 0.526857 0.882321 -0.826616 -0.942599 -0.263199 0.406106 -0.569641 0.0465709 0.716825 -0.316404 0.194238 0.551542 -0.238056 0.987142 0.899936 -0.783274 -0.479332 -0.126143 -0.078305 -0.0714621 0.936455 0.999423 -0.705715 -0.95721 0.171786 -0.788102 0.365868 -0.855741 -0.439906 0.49867 -0.85177 0.298957 0.568643 -0.825493 -0.0546743 -0.911428 -0.377468 -0.100761 0.514324 0.248334 -0.250971 -0.0640139 0.118496 -0.44378 -0.604106 0.789793 0.0540736 0.815052 0.580025 0.477284 -0.282412 -0.491889 0.828485 0.345045 -0.831033 0.832616 -0.227531 -0.110851 0.932806 -0.335943 -0.192922 -0.445727 0.6668 0.913557 0.157186 -0.171639 -0.730109 -0.944021 -0.162959 -0.85136 -0.811083 0.12351 -0.168888 -0.493735 -0.208438 0.780135 -0.278787 0.425549 0.197805 0.509357 0.756908 -0.639522 -0.439399 -0.977459 -0.152872 0.678677 0.517623 -0.306348 -0.787742 0.415072 0.120697 0.559357 -0.889463 0.797974 -0.452991 0.575675 -0.635342 -0.200897 -0.47014 0.349278 0.318036 -0.764566 -0.0685645 -0.363242 0.98762 0.927333 -0.315504 -0.678831 0.893069 -0.181633 -0.699474 -0.0593184 -0.964592 0.107602 0.460456 0.883639 -0.687101 -0.112139 -0.725983 0.410696 0.571171 -0.324614 0.220779 0.633803 0.321739 -0.535477 0.244822 0.719437 -0.414229 0.0475825 -0.281499 0.849971 -0.539249 0.834827 0.932274 0.727236 0.648326 0.415333 0.502259 -0.536102 -0.272253 0.239731 -0.846195 0.000303735 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.895133 -0.504617 0.905482 0.428299 0.422111 0.41367 0.556595 0.694548 -0.729847 -0.538229 -0.0174261 -0.880073 0.611482 -0.822327 -0.846618 0.896606 -0.746995 -0.742571 -0.39056 -0.147945 -0.51087 -0.196772 0.849953 -0.839766 0.0468376 -0.800888 -0.52053 -0.548056 0.820496 0.0830854 0.416499 0.104355 -0.0980876 -0.558966 -0.549551 -0.302493 -0.00451683 0.0856191 -0.999725 -0.371939 0.818716 0.162437 0.0863119 0.643706 0.763162 0.457442 0.219402 -0.50478 0.166471 -0.114493 -0.283709 -0.290299 0.940984 -0.88981 0.971727 -0.180921 -0.73917 0.777749 -0.377581 -0.00889217 0.549273 -0.37406 -0.822335 -0.978633 0.117195 -0.29757 0.747004 0.891679 0.4485 -0.0594566 0.713184 0.478179 0.760465 -0.866206 -0.316252 0.756012 0.289583 -0.970364 -0.899776 -0.531311 0.25135 0.446715 -0.0538289 -0.702968 -0.784605 -0.862529 -0.517174 -0.142834 -0.606559 -0.445061 -0.142619 -0.990839 0.960759 -0.528607 -0.299092 -0.837695 0.863803 -0.0627577 -0.769419 0.368928 0.577624 0.122364 0.577493 -0.0801951 0.160851 -0.57481 -0.828476 -0.1929 -0.0743657 0.134848 0.386095 -0.894054 -0.366223 0.883282 -0.676982 -0.0321436 -0.236903 0.366829 -0.702913 0.137967 0.811938 0.238206 -0.465283 -0.00461333 0.463823 -0.523259 -0.418015 0.421079 -0.930034 0.925803 -0.0357554 -0.941197 -0.702369 -0.71188 -0.572281 -0.332981 -0.415445 -0.385596 -0.717236 -0.59248 0.192523 -0.261816 -0.338902 0.0786874 0.49915 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.792582 -0.926778 -0.362038 -0.769445 -0.0574836 -0.127225 -0.27801 -0.516295 0.629642 0.388543 0.24632 -0.0937097 -0.978276 0.117892 -0.592342 0.50448 0.790028 0.00690662 0.0795584 -0.862315 -0.935186 0.335119 0.348513 -0.535382 -0.167865 0.687478 0.434797 -0.367261 -0.561476 -0.723695 0.861633 -0.538757 -0.88788 -0.598381 -0.994326 0.36625 -0.430104 -0.758934 0.60272 -0.0858578 0.987286 -0.684362 -0.0665098 0.170628 -0.259123 0.922729 0.308908 -0.178215 0.740661 0.281503 -0.778563 0.690028 -0.691867 -0.20847 0.241039 -0.86471 0.819745 -0.540582 0.436509 0.410236 0.833224 0.00117377 -0.272486 0.33107 0.288575 0.0790824 -0.861319 -0.18386 -0.129273 -0.68802 0.447483 0.844075 0.361119 -0.679996 -0.693218 -0.913315 -0.0900099 -0.79677 0.681526 0.409979 0.509828 0.685474 0.769059 -0.422907 0.207887 -0.0408738 -0.96594 -0.557564 -0.974007 -0.129438 0.530848 -0.031685 -0.529589 -0.797861 0.351121 -0.715916 -0.405866 0.617392 0.50823 -0.177818 -0.587266 -0.175651 -0.174128 -0.568705 -0.228766 -0.874615 0.340897 -0.547203 -0.842722 0.369522 0.559594 -0.89958 0.762369 -0.859736 0.412929 0.10229 -0.807707 0.875206 -0.418062 -0.374268 -0.326216 -0.70946 0.103238 -0.878932 -0.21072 0.426042 0.479732 0.849072 0.353698 0.599281 0.113369 -0.614813 0.836363 0.752984 -0.591349 -0.80632 0.178674 0.975326 0.297676 -0.956706 0.640434 -0.219837 -0.805566 0.857909 0.873612 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.820989 0.527919 0.72768 0.113321 0.577646 0.504307 -0.11537 0.970739 -0.795411 -0.46809 0.817823 -0.32139 -0.118381 -0.841879 -0.73119 0.774436 0.191668 -0.345839 0.511192 -0.997322 0.192018 -0.200816 0.984064 -0.41132 0.846888 0.388698 -0.583325 -0.766389 -0.374165 0.11344 0.760287 0.491736 -0.376764 0.526502 -0.532268 0.536027 0.0864857 -0.480842 -0.209142 -0.0648374 0.0712709 -0.358151 -0.372629 0.0140087 -0.549494 -0.270053 0.0801641 -0.648307 -0.22918 0.616904 0.289774 0.675451 0.708068 0.734318 -0.377757 0.20014 -0.250699 0.497554 0.392164 -0.90416 -0.209315 0.0430499 -0.460012 0.581434 0.164793 -0.329759 -0.266784 0.159968 0.583279 -0.826835 -0.6147 0.732755 -0.588646 0.623191 -0.210069 -0.0574531 0.53787 -0.415338 -0.604775 -0.405984 -0.653487 0.815943 -0.39969 0.424826 -0.111377 0.709877 -0.677762 0.978385 -0.0901323 -0.816057 0.293657 -0.837762 -0.273024 -0.715712 -0.9761 0.685366 0.939786 0.986795 -0.93528 0.746491 0.282183 -0.326066 -0.806238 -0.537445 -0.776677 0.328417 0.762895 0.974658 -0.84119 0.675546 -0.100748 0.731803 -0.579609 0.509722 0.905852 0.654489 -0.00590994 0.671689 -0.917454 0.342599 0.0612445 -0.664246 0.0194313 0.582626 0.197919 0.420399 -0.345983 -0.931887 0.749935 0.126732 -0.698693 0.0332344 -0.295767 0.290073 0.523744 -0.0475962 -0.789571 -0.322429 0.928486 -0.939981 -0.259783 -0.167721 -0.892233 0.232705 -0.932583 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.262311 0.47894 -0.447914 -0.0852818 0.668082 0.456531 0.914358 -0.38329 0.0441252 -0.387579 -0.0409661 0.818203 -0.287033 0.920704 0.582591 0.694093 0.569395 -0.37434 -0.60298 -0.328462 0.366776 -0.299039 0.893153 0.649574 0.44032 0.76157 0.0309153 0.0323449 -0.960211 0.523498 0.743213 0.261639 0.612059 0.213699 0.15819 0.661051 0.542465 0.360705 0.849986 -0.899952 -0.343746 0.128353 0.411641 0.61774 0.2716 0.331962 0.661759 0.0641064 -0.49682 0.471897 -0.927246 0.386767 0.529097 -0.786529 -0.819138 0.36411 -0.394947 0.118625 -0.269786 -0.300391 -0.675018 0.970419 -0.167274 0.624885 0.436687 -0.599089 -0.894868 -0.0482665 0.785126 -0.390032 0.724528 -0.855813 0.355209 -0.00639659 0.198147 0.194316 -0.0125818 -0.0296191 -0.667005 0.508232 0.582789 0.0589319 -0.396484 -0.939878 0.973036 -0.50866 -0.406204 -0.846979 0.606905 -0.360464 0.448727 0.318902 -0.220715 0.444671 -0.414533 0.948875 -0.256643 0.605878 0.990105 0.700532 -0.160381 0.194919 -0.779505 -0.248435 0.64392 0.29759 -0.611431 0.598085 0.184481 0.921228 -0.917687 0.436943 -0.293475 -0.433023 0.174897 -0.513998 -0.756508 -0.630787 0.363441 0.348276 -0.52359 0.016826 0.793761 0.748671 0.907295 0.9026 -0.00149307 0.906812 -0.476341 0.698526 0.112562 -0.305043 0.0599298 0.107086 -0.0592337 0.800529 -0.415892 0.0993674 0.0678328 0.0650421 -0.837152 -0.0185238 0.671202 0.897306 -0.979282 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.787394 0.260681 -0.726885 -0.758232 0.397872 -0.959196 0.790787 0.764061 -0.431937 0.43618 0.870152 0.65298 0.63933 -0.775971 0.255654 0.773512 0.418424 0.456093 -0.447845 -0.928294 0.162379 -0.897478 0.0806606 -0.337049 -0.781442 0.312125 -0.11242 0.564124 -0.767133 0.799485 0.943295 -0.0371611 -0.566611 0.96579 0.0356415 -0.973618 0.404046 0.802541 0.313705 0.435141 -0.577 0.355704 0.317878 0.575235 -0.0258299 -0.123467 0.890479 0.277802 -0.980855 0.762029 -0.581924 -0.388569 -0.68419 0.817539 0.37171 -0.675473 -0.669057 -0.833036 -0.842216 0.869914 0.645128 0.664173 0.760954 -0.642304 0.802302 0.294942 -0.903692 -0.353894 0.0994627 -0.330861 -0.777353 -0.96581 -0.366932 0.979046 0.822665 0.537374 -0.350864 -0.977499 -0.821604 -0.699169 -0.934737 -0.12552 0.38289 -0.771563 0.34642 0.284759 -0.050156 -0.971213 0.828496 0.524347 0.699694 -0.249453 -0.553008 -0.413442 -0.712236 -0.543785 0.597741 0.234931 0.481046 0.946153 -0.0137297 -0.755559 -0.683057 -0.137962 -0.73153 -0.818971 -0.445637 0.176069 -0.813226 0.10994 -0.245598 0.235022 0.0213071 0.10901 0.1361 -0.574996 0.0403347 -0.0942561 -0.16288 0.472768 -0.195783 -0.523239 -0.0703677 -0.670372 -0.941622 0.164663 -0.51507 -0.774141 -0.980517 0.458843 -0.225934 0.725456 0.746837 0.0896509 0.763438 -0.89933 0.958352 -0.979228 0.116739 0.0321189 -0.177644 0.339609 -0.199793 0.0818452 -0.426969 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0683878 0.606051 -0.10171 0.564152 -0.290053 -0.920025 -0.867474 0.357581 -0.141353 0.27987 -0.218643 -0.738207 0.954353 -0.187908 -0.166656 -0.98165 -0.591432 -0.197582 -0.767773 0.0396203 -0.101675 -0.857432 -0.858282 0.846917 0.129176 -0.946971 0.256272 -0.840724 -0.0428784 -0.658037 0.36752 0.916631 -0.180262 0.34322 0.494969 0.938017 -0.745284 0.00599991 0.840475 -0.140347 -0.815876 -0.434655 0.753255 -0.0392041 -0.904149 -0.0305138 -0.844642 0.0991791 0.902348 -0.234901 0.0118114 0.514518 -0.49671 -0.211033 -0.832934 0.873762 -0.680809 -0.354349 0.457498 -0.82564 -0.526946 -0.383325 -0.542696 0.909066 0.671698 -0.769035 0.825213 -0.639425 -0.823144 -0.582678 0.924636 0.352021 0.41089 -0.168942 0.584131 -0.516788 0.338652 -0.271931 -0.341432 -0.449365 -0.475504 0.200508 -0.0592429 0.30483 -0.726237 0.132505 -0.982264 -0.906728 0.629965 -0.183322 0.910043 -0.910395 0.993722 -0.509256 0.930519 -0.761052 0.991707 -0.384897 -0.968604 0.673569 0.67799 0.970222 0.527212 0.850836 -0.00477386 -0.234208 -0.334193 -0.774367 -0.7908 -0.97639 -0.188255 -0.00857073 -0.0482316 -0.628131 0.997945 0.455533 0.144578 -0.0850025 -0.636691 -0.867455 0.681671 0.838454 -0.103738 0.48332 -0.846906 0.0542589 -0.0703504 -0.37873 0.682516 -0.958611 0.623446 0.264194 0.314603 -0.470578 0.988875 0.0267236 -0.857089 0.911067 0.295127 0.193327 -0.746521 -0.78486 0.864743 -0.257233 0.687567 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0595818 0.609346 -0.720803 -0.528616 -0.442768 0.39159 -0.538702 0.0381204 0.689636 0.716186 0.932559 -0.476108 0.0540744 0.827621 -0.170287 -0.0205682 0.3097 -0.867705 0.476938 -0.101301 -0.574297 -0.217357 0.88926 -0.206514 -0.884501 0.194403 -0.670113 -0.586341 -0.634689 0.779468 0.520473 -0.406103 0.618524 -0.461546 0.794017 -0.954872 -0.530073 -0.932464 0.0787292 -0.798121 -0.0145847 0.875102 -0.166692 0.400803 0.287857 0.00886446 0.984917 -0.492015 0.704768 -0.959919 0.642368 0.284718 -0.748472 0.438102 -0.811983 -0.992324 0.0101683 0.898188 -0.155935 -0.796669 0.386657 0.547881 0.241375 0.789717 0.767074 0.215019 -0.181578 0.21499 -0.658001 0.983675 0.623616 -0.884456 0.950806 0.194036 -0.843162 0.983261 -0.33257 0.487913 0.361964 -0.46432 0.177485 0.993024 -0.246087 0.0234549 0.206307 -0.595933 0.161983 0.449701 0.120774 -0.152391 0.756617 0.456428 -0.806676 0.194022 0.922564 -0.468889 -0.622285 -0.745136 0.50748 -0.788603 -0.0560566 -0.143411 -0.304699 0.926308 0.45512 -0.805614 0.0453126 -0.431856 -0.199809 -0.197979 0.570954 0.0189224 0.0292342 -0.661516 -0.102596 -0.323261 0.950888 -0.431169 -0.652221 0.125368 -0.933097 -0.553628 -0.829447 -0.512946 0.91138 -0.441734 -0.2226 0.765391 -0.0749427 0.438696 -0.831937 -0.372564 0.316136 -0.709286 -0.964597 0.0164714 0.834451 0.615267 0.790763 0.346148 -0.286748 0.623185 -0.129592 -0.0519631 0.656699 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.864388 0.237502 -0.295967 -0.312833 0.212159 -0.243281 -0.815846 0.080821 0.358134 -0.850263 -0.37186 0.150811 0.683206 0.645781 -0.35194 0.943573 0.62471 -0.50465 0.34322 0.490523 0.224554 0.0708926 -0.507275 0.228684 -0.509165 0.462782 -0.0298142 0.912897 -0.944769 -0.733329 0.940987 -0.832959 0.46222 0.536139 0.895389 0.798961 0.141948 -0.2768 -0.177424 0.0350322 0.786861 0.780458 -0.842278 -0.165295 -0.121185 -0.763004 0.190704 -0.830331 0.632808 -0.390534 0.302478 -0.248087 0.400731 -0.917655 0.980281 -0.414071 0.710865 -0.498345 0.318693 0.266044 -0.605351 -0.132455 -0.178045 -0.403983 0.265054 0.755976 -0.313141 -0.958504 0.423151 -0.095271 0.780863 -0.0381421 0.946187 0.567456 -0.759412 0.568169 -0.779166 0.563521 -0.909794 -0.912437 0.669943 -0.262129 0.404392 0.618676 0.0948122 -0.492091 -0.566062 0.197118 0.961361 -0.406404 -0.426948 0.283345 0.177326 0.31268 -0.781619 -0.664869 -0.456273 -0.588332 -0.104314 0.797718 -0.752 -0.868277 0.872386 0.198938 -0.448116 0.506147 0.804439 0.204187 -0.225698 0.698403 0.0634589 0.552989 0.081807 0.930001 0.523863 0.561569 0.286151 -0.657608 -0.41472 -0.199783 0.249658 0.00628434 -0.379069 0.98218 -0.506605 -0.512974 0.440608 -0.702766 0.60606 0.0426555 0.910193 -0.39428 -0.659692 0.556987 -0.721268 -0.356362 0.618438 0.0828587 0.606951 -0.966326 0.966491 -0.179881 0.735501 -0.438112 0.652184 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.746234 0.0403631 0.383418 0.114481 0.0880024 -0.943631 0.39233 -0.115389 0.650734 0.887508 0.341496 -0.468859 -0.108343 -0.921664 -0.402222 -0.15174 -0.29711 0.468437 -0.978841 0.614535 0.491498 0.607477 -0.140263 0.602465 -0.367461 0.0833754 -0.710396 0.371218 -0.933012 0.862976 0.0363582 -0.927208 0.419858 0.559307 0.265962 0.0291042 -0.845731 -0.194662 0.320999 -0.96253 0.757145 -0.657778 0.725697 0.786261 0.688245 -0.661618 0.19326 0.112597 0.425612 -0.745494 0.478436 -0.923699 -0.61601 0.727462 0.453961 -0.28288 -0.364981 -0.240254 0.0590763 0.895756 0.974796 -0.600201 0.416576 -0.606422 -0.141322 0.794548 -0.0306194 -0.621009 0.704329 -0.348841 -0.972644 0.766402 0.910079 -0.307342 0.50645 -0.0967598 -0.242215 -0.914341 0.67285 0.590961 0.27329 -0.821175 0.504393 -0.660699 -0.363655 0.054615 -0.0853693 -0.801381 -0.815495 -0.0297266 0.38524 0.733163 0.273514 0.955705 0.536347 0.378107 0.851609 0.999114 0.114606 0.17769 0.43503 -0.453012 0.221735 0.699727 0.304012 -0.463707 0.483733 0.107794 -0.31029 0.95348 -0.8639 0.436094 -0.570619 -0.401515 -0.255643 -0.596057 0.0693841 0.138983 -0.119064 0.892635 0.518212 -0.412894 0.49793 0.703755 0.0081641 -0.78602 -0.64076 0.744134 0.655167 -0.610372 -0.521112 -0.321704 -0.884715 0.600675 -0.454748 -0.949397 -0.519566 -0.346141 0.403377 -0.447066 0.160103 0.856229 0.640673 -0.205818 0.821368 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.738544 -0.812127 0.581376 -0.808761 -0.841378 0.964767 0.835458 -0.464451 -0.035859 -0.68269 0.0351492 -0.985701 0.435095 0.432501 -0.337644 -0.565448 -0.978496 -0.911482 0.0681233 0.389877 -0.792312 0.993691 -0.348534 -0.861679 0.305076 0.161601 0.261011 -0.174384 0.405402 0.41282 -0.433206 -0.0970987 -0.618508 0.574571 -0.177601 -0.637942 0.686168 0.894701 0.378201 -0.159899 0.747783 0.0892018 -0.476063 -0.931814 0.968143 0.144887 0.0289263 0.15723 0.987772 0.330168 0.473404 -0.0631746 -0.450639 -0.445579 -0.310633 0.281187 -0.0898034 0.67471 -0.154089 0.217902 0.279645 -0.0131645 0.743665 0.781151 0.799431 0.0314919 -0.715631 0.390932 0.390821 0.521414 -0.594662 -0.481921 0.347567 -0.434811 0.973878 -0.103066 0.270582 -0.468859 0.786017 -0.520223 -0.314814 -0.697393 -0.591963 -0.438134 -0.626367 0.631706 -0.157029 -0.819312 -0.756187 0.543912 0.0138965 -0.946689 0.99218 -0.431287 -0.639101 0.627093 -0.456242 -0.0626196 -0.448009 0.318421 -0.305384 0.172508 0.798746 0.279837 0.252575 0.204271 -0.0043687 0.805673 0.010783 0.302632 0.341267 -0.322062 -0.896806 -0.623572 -0.373573 -0.642339 0.21293 0.710268 -0.518085 0.539271 -0.470118 0.728654 0.480779 0.447822 0.53793 0.995824 0.815218 -0.631952 0.972799 -0.46499 -0.803625 -0.30184 -0.510229 0.154841 0.883869 -0.39313 -0.852372 0.178882 0.474777 -0.421885 -0.615361 -0.374178 -0.80837 -0.270828 0.199425 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.272347 0.667304 -0.629362 0.3126 -0.127739 -0.901354 0.93952 0.506277 0.996386 0.255588 -0.3319 -0.241849 -0.750825 0.890222 -0.0384406 -0.0710164 0.426838 -0.129679 0.479998 -0.67545 -0.288304 0.480357 -0.643292 0.198832 -0.228772 -0.971412 -0.518467 0.126172 0.572446 -0.89567 0.472378 -0.747393 0.563551 -0.397684 0.131192 0.948596 -0.949396 -0.504195 -0.00592537 0.41223 0.341793 0.514958 0.892071 -0.963701 -0.915514 0.959509 0.474825 0.385953 0.715131 -0.792821 -0.941753 -0.036582 -0.833363 -0.327061 -0.916621 0.345648 -0.686681 0.9567 -0.743429 -0.817455 -0.960474 -0.693645 -0.0904559 -0.292475 0.364932 -0.587354 0.345979 0.863843 0.608353 0.595914 -0.474693 -0.173564 0.912972 0.32772 -0.00435471 0.810323 -0.908009 -0.912649 -0.889755 -0.120461 -0.586723 0.944573 -0.558849 -0.574645 -0.0570332 -0.557514 -0.140091 -0.515036 -0.210861 0.0571717 0.885092 -0.258639 -0.950933 -0.322605 -0.0152309 0.0148403 -0.578409 0.675459 0.432293 -0.448131 0.270009 0.046295 0.0804059 -0.617478 0.0453161 -0.373111 -0.877172 -0.62443 -0.801156 0.969806 -0.463113 0.455373 -0.544031 0.475561 0.755765 0.135425 0.087068 -0.648744 0.565165 0.729404 -0.899796 -0.865669 0.693965 -0.523859 -0.504765 0.415115 0.841036 -0.702622 -0.975608 0.956116 -0.55646 -0.420816 -0.648866 0.507644 -0.0289473 -0.516579 -0.150752 0.318319 -0.0181083 -0.346189 -0.403491 0.533127 0.273806 -0.137772 0.469565 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0559259 0.709615 0.501127 0.445617 -0.517424 -0.338942 -0.591672 -0.238556 0.589151 -0.145178 -0.00703879 0.500376 0.382921 0.394281 -0.732391 -0.701641 0.142663 0.298576 0.740525 0.666569 -0.181338 -0.822632 0.778144 -0.876139 -0.294288 0.701716 0.735723 0.307616 0.859312 0.727451 0.769547 -0.0930478 0.671226 -0.0874493 0.425755 -0.14656 0.817993 -0.0346462 0.712847 -0.0642621 0.754306 0.827148 0.981742 0.782438 -0.746368 0.522536 0.733913 0.551826 0.233243 -0.625146 0.761403 0.333931 -0.299341 0.21826 -0.390674 -0.560755 -0.603044 0.644903 0.890095 -0.180471 0.825596 -0.216215 0.081114 -0.716278 -0.490993 -0.117494 -0.719462 0.0062094 0.36137 -0.446369 -0.115949 -0.747906 -0.0530467 0.443607 -0.660489 0.912761 0.305125 0.000326033 -0.717129 0.724803 -0.622229 -0.322767 0.609648 -0.807032 -0.832786 0.102808 0.818316 0.36393 -0.622439 -0.265062 -0.0709229 0.665177 -0.366662 -0.480189 -0.531107 -0.321952 0.951876 0.180441 0.670793 0.0226232 0.22759 -0.502437 -0.0152333 0.531749 -0.507516 0.406968 0.273497 0.827896 0.524257 -0.656804 -0.905045 0.910127 0.511093 -0.0608928 0.574203 0.63668 0.686744 0.110801 0.234657 -0.127809 -0.0788315 -0.920707 -0.314447 -0.915962 -0.575281 -0.741483 -0.104358 0.0523981 0.745833 -0.584734 0.0413014 0.233537 -0.866106 -0.894164 0.0214407 0.317504 0.0555224 -0.835407 -0.685824 -0.643407 0.263731 0.526958 0.590254 0.401814 -0.704347 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.238723 -0.865208 0.455673 0.499078 0.00625809 -0.820351 0.355533 -0.557092 0.957987 0.892694 -0.497305 0.0426384 0.934741 -0.53814 -0.11834 -0.0406188 -0.215534 0.128845 0.329964 0.238666 -0.531773 0.521061 0.980323 0.459557 0.988455 -0.79244 0.570482 -0.205792 -0.476726 -0.232604 0.0320802 0.767131 -0.477578 -0.650482 0.462731 0.355801 0.87727 0.738291 0.1029 0.29048 0.733527 0.385758 0.149202 -0.803342 0.447464 -0.572007 0.906515 0.131002 -0.723589 -0.615145 -0.460449 0.511042 0.306165 -0.394931 0.669517 0.329663 0.63915 0.189307 -0.310925 0.276199 0.0778701 0.763183 0.813901 -0.760499 0.295225 -0.15462 -0.697898 0.431392 0.403791 0.513378 0.344291 0.494366 0.8047 0.599433 -0.0740341 0.244246 0.955387 0.274853 -0.203736 -0.200209 0.0710912 0.514119 0.519315 0.497679 0.422538 0.109839 -0.541486 0.211988 -0.888203 0.154178 0.241144 0.110563 0.228557 -0.638501 0.713686 0.918966 -0.945796 0.00741375 0.602928 -0.581836 -0.914139 0.930587 0.770709 0.718232 0.147859 -0.261638 -0.380062 0.408632 -0.55591 -0.168363 0.319539 0.49479 -0.0665416 -0.365228 -0.388401 0.137529 -0.548324 0.314574 -0.956909 -0.76928 0.712002 0.623714 0.754934 0.171288 0.840876 0.599972 -0.263518 -0.951052 0.924272 0.154636 -0.245395 0.299067 -0.826274 -0.0978806 0.335131 0.0269042 0.0127602 0.461481 0.111183 0.65984 -0.0760278 0.20011 -0.756502 -0.526618 -0.868599 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.544885 0.109666 -0.851244 -0.859469 0.912512 0.596676 0.337762 0.760952 -0.681326 0.954891 0.846806 0.26675 -0.73134 0.36896 -0.895317 0.403169 0.0623106 -0.745711 0.837687 -0.987366 -0.655841 -0.727407 0.462789 0.093232 0.950002 0.682107 0.164045 -0.892506 -0.356631 0.0976764 -0.352782 0.793481 0.0406712 -0.43839 -0.0125983 0.259748 -0.422246 -0.689312 0.726898 0.968339 0.865588 -0.0603242 0.130654 -0.0948051 0.610253 0.523587 -0.0679634 -0.261669 0.126154 0.272743 -0.00372927 -0.67783 -0.295545 0.774962 0.779235 0.604659 0.503128 0.0740386 0.366048 0.165519 -0.118322 -0.645171 0.610557 -0.367781 0.697096 0.0899723 0.165167 -0.0441049 0.72931 -0.492775 -0.0670681 0.786686 -0.171711 0.0517322 -0.53767 -0.620148 -0.827094 -0.966052 -0.435924 -0.569312 -0.429186 0.664586 -0.299733 0.389856 0.306069 0.103613 -0.570503 -0.439663 0.584786 0.501268 0.815254 -0.0320808 0.818091 -0.339329 0.894519 0.17575 -0.164459 -0.0634766 -0.851017 0.959221 -0.38067 0.0791136 -0.337969 -0.251967 -0.801378 -0.753698 0.592649 0.644864 0.234605 -0.996379 -0.14256 0.000636277 0.693912 0.57603 -0.665779 0.24701 -0.510636 -0.262597 0.528372 0.354805 -0.787547 -0.300451 0.321172 -0.0662882 -0.105899 0.158964 -0.289183 -0.304328 -0.837344 0.763148 0.228113 -0.100866 0.748069 0.800306 0.739916 -0.225786 -0.791644 0.84705 0.366907 0.60049 0.441204 -0.677704 -0.168823 0.590436 -0.541722 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.725792 -0.393312 -0.394587 0.175969 -0.494048 0.528407 0.932986 0.69809 0.798332 -0.441682 0.646143 -0.27705 -0.372968 -0.47936 -0.60305 0.535037 0.362625 0.632016 0.295044 0.797307 0.332056 0.871399 -0.393888 -0.080439 0.061665 0.404046 0.794339 0.462103 0.560764 0.757661 0.0156392 0.848651 -0.727523 0.523947 -0.0261003 -0.667676 0.367625 0.670787 -0.0896539 -0.813495 -0.416363 0.190007 -0.547016 0.304011 -0.495075 -0.719721 -0.358338 -0.580019 -0.377608 -0.452319 -0.118728 0.539595 0.978491 -0.50477 0.327616 0.248565 -0.370125 -0.684083 0.618402 -0.520163 -0.379625 -0.356401 -0.0261734 0.104476 -0.0698058 0.774209 0.125749 -0.534304 -0.0472691 -0.451652 -0.916986 0.208084 -0.724747 -0.826651 0.484714 0.590691 -0.25774 0.165606 -0.66326 0.597325 -0.759151 0.947445 -0.283659 0.543976 0.606124 -0.873674 0.15849 -0.258947 -0.127825 -0.360252 -0.756493 -0.370623 0.942594 0.180397 -0.075905 0.265332 -0.564967 0.605803 -0.271787 0.0737228 -0.940246 -0.717917 -0.0379813 -0.351915 -0.641943 0.86597 0.353213 0.454206 -0.156583 0.303061 -0.446233 0.16813 -0.233663 0.826604 0.732805 0.261251 0.837627 -0.00579551 0.594863 -0.136774 -0.761578 0.158162 0.229003 0.860288 0.856169 -0.375205 -0.0737943 -0.260663 -0.966446 0.934922 -0.758927 0.705965 -0.839357 0.932696 -0.171821 0.198886 0.680214 0.353454 0.506074 -0.412906 0.290468 -0.0999332 0.422283 -0.683717 0.765311 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.723415 -0.40352 0.0437133 0.689763 0.83901 -0.757785 -0.0885157 0.315857 0.613097 0.319412 0.361493 -0.42433 -0.510243 0.578329 -0.997653 -0.0774143 0.823316 0.228668 0.727588 0.996761 0.754168 -0.613426 -0.924486 -0.345394 -0.324021 0.751949 -0.38057 0.214158 -0.153689 0.956254 -0.397385 0.450019 0.733704 -0.983847 0.62453 0.582268 0.625689 0.108221 -0.74854 0.539514 0.894374 -0.234509 0.488583 -0.833901 -0.132568 -0.417969 0.692141 -0.511363 0.336475 0.507487 -0.391093 -0.0278806 0.749673 0.0740234 -0.752608 0.350597 0.485272 -0.0272611 -0.177296 0.180115 -0.810013 0.109587 -0.17952 0.810203 -0.91156 -0.586414 0.147763 -0.554233 -0.999501 -0.607127 0.0194001 0.0578368 0.0630726 0.0613415 -0.671574 0.893997 0.660976 -0.40272 0.706791 0.492234 0.807063 0.941971 -0.421431 0.402384 -0.987556 0.861459 0.412078 -0.190417 -0.453551 0.279568 -0.931281 0.128173 0.209962 0.834711 0.990223 0.67741 -0.767534 0.0542973 0.574433 0.493484 -0.0173617 -0.608816 -0.814882 -0.564217 0.132371 0.47802 -0.497435 -0.364378 0.345097 -0.451704 0.206131 0.451225 -0.256257 -0.904731 0.1779 -0.0344637 0.76937 0.804998 -0.391162 -0.264122 0.901083 0.498286 0.697032 -0.984432 0.65761 0.457264 -0.760801 -0.778651 -0.783582 0.501922 -0.719622 0.241629 0.821958 0.21521 -0.30629 0.111707 -0.495257 0.217429 0.328273 -0.72286 0.893264 -0.91068 0.203703 -0.37096 -0.728456 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.93544 0.26279 0.710539 0.0326666 -0.972284 0.822947 -0.731038 -0.550287 -0.667859 -0.711347 0.389597 -0.779371 -0.361516 -0.374939 -0.543542 -0.369435 0.135775 -0.49388 -0.251843 0.0899362 -0.174453 -0.454156 0.534362 -0.459891 -0.81306 0.0996871 0.952257 0.776855 -0.155517 0.473428 0.0636088 -0.682137 0.459307 -0.895512 0.593692 0.0666066 -0.154003 -0.376488 -0.617124 0.808017 -0.864894 0.320706 0.534078 -0.890887 -0.418416 0.936165 -0.275549 0.467008 0.704143 0.174555 -0.941939 -0.491307 0.878707 -0.68159 -0.405344 0.301893 -0.0874768 -0.221901 0.515229 -0.552074 -0.712618 -0.967779 0.539704 0.807999 0.0316617 0.138943 -0.779296 0.364827 -0.346768 -0.138023 0.253782 -0.693204 -0.67566 0.186824 -0.08521 0.0516817 0.420255 -0.575179 -0.757549 -0.824659 -0.907853 -0.907517 -0.616131 -0.367708 0.53665 0.843199 -0.712837 -0.592492 0.0910991 -0.765964 0.00231486 0.0825051 0.663184 0.134318 -0.517871 0.142829 0.525979 0.131994 0.430221 0.729081 -0.332119 0.124963 -0.072166 -0.753403 -0.899577 0.464789 0.232099 -0.279924 -0.196855 -0.0768143 0.981513 0.287005 -0.31491 -0.685715 -0.819064 -0.0147772 -0.361227 0.853306 -0.48961 -0.880096 0.231919 -0.141976 -0.193533 -0.717492 -0.892475 0.17481 0.0396425 0.27163 0.972383 -0.932941 -0.233448 0.50558 -0.110458 0.521178 0.697293 0.0521806 -0.582333 0.736451 -0.475731 0.38952 0.667123 0.338029 -0.738776 -0.611615 0.593627 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.906236 0.887003 -0.133773 -0.318092 -0.179012 -0.653325 -0.436823 0.317875 0.523456 -0.279836 0.791721 0.461206 -0.510241 0.385168 -0.485152 0.0491097 -0.61359 -0.61239 -0.432206 -0.0870079 -0.342203 0.60186 -0.535214 0.661305 0.545589 -0.286072 -0.0137721 0.532711 -0.729511 -0.885963 -0.374527 -0.671541 -0.594042 -0.0613298 -0.770578 0.894793 0.782445 0.556095 0.296431 0.120435 0.148368 -0.376087 -0.895247 -0.419244 -0.235934 0.653488 -0.828863 -0.697756 0.81917 -0.206273 -0.836452 -0.25236 0.581897 -0.0613061 -0.370948 -0.522669 -0.498593 0.149132 0.457108 0.614407 0.340561 -0.185914 -0.662172 0.869408 0.147147 -0.907722 -0.0763597 0.623352 0.677179 -0.655001 -0.606602 0.832424 0.551856 -0.962974 -0.70212 -0.53443 -0.173255 0.0974255 -0.569129 0.651648 0.251813 0.224139 -0.903013 -0.936458 0.949393 0.448581 -0.701597 0.256351 0.49037 -0.358947 -0.816049 0.664658 0.902836 -0.0397693 -0.402544 0.448284 0.312129 -0.0469285 -0.727665 0.138203 0.783789 -0.860462 0.21331 -0.897263 -0.294259 0.387966 0.536535 -0.450569 -0.721257 -0.168279 -0.265438 0.789962 0.886922 0.495924 0.993657 0.396336 -0.787623 0.413113 -0.808141 -0.424308 0.654617 0.142616 0.951442 0.878016 0.811415 -0.545672 0.887422 0.895653 -0.75984 -0.635565 0.0529647 0.178338 -0.671822 0.68049 -0.999357 -0.196856 -0.551061 0.317703 -0.373099 -0.678304 -0.249234 -0.869919 -0.730341 -0.847611 0.208298 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.739665 0.428017 -0.322563 0.681911 0.874857 -0.278729 -0.60539 -0.793267 -0.439649 0.816243 0.599665 -0.913227 0.0866199 0.876098 -0.840285 0.191779 0.9207 -0.652816 0.544095 0.838712 0.178468 0.587951 0.513998 0.735768 -0.898903 -0.22997 0.911946 -0.273429 -0.563579 0.963997 -0.380779 0.252027 0.728807 -0.766941 -0.0328434 -0.896604 -0.754062 0.253981 0.74782 0.356444 -0.4007 0.997117 -0.585093 -0.793392 -0.867563 -0.45302 0.24233 0.650183 0.221309 -0.909507 0.704985 0.186583 -0.355858 0.758176 0.412299 0.705069 0.102834 0.332914 -0.722039 0.683468 -0.960291 0.382306 -0.582809 0.733675 0.874381 -0.276637 0.561226 0.527086 0.734836 0.386521 0.266041 -0.65306 0.0131881 -0.348502 -0.335611 0.515686 -0.0196473 0.902506 0.681915 -0.568047 0.0164669 0.951948 -0.400834 -0.619078 -0.1846 -0.662096 -0.48481 -0.106326 -0.365115 -0.21212 -0.383189 -0.324557 -0.828583 0.00277728 0.677805 -0.138552 -0.649919 0.815964 -0.0928762 -0.970718 -0.864362 0.257137 -0.0760129 0.26387 0.968968 0.0631107 0.419207 0.979019 0.333379 0.531784 -0.306819 -0.701047 -0.494822 -0.465417 -0.258232 -0.105348 -0.586996 0.359197 -0.970469 -0.665655 0.334474 -0.488707 0.300149 0.608859 -0.902098 0.444549 -0.466325 0.475703 -0.770579 -0.947564 0.599507 -0.51602 0.434566 0.304855 0.15702 0.922765 0.205154 0.0236919 0.189506 -0.964808 0.468293 0.599743 -0.124814 0.249653 -0.0741394 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0613803 0.381889 0.404639 0.770894 0.416009 -0.133243 0.592229 -0.407211 0.00599383 0.738372 -0.182331 -0.44291 0.0157239 0.271876 -0.580749 -0.648212 -0.49961 -0.945553 0.0956586 -0.265755 -0.540891 -0.762094 -0.513236 0.0427988 -0.679755 -0.647799 0.443225 -0.721389 -0.37818 -0.0645245 -0.462445 -0.316229 -0.857835 0.36405 0.596234 0.897733 0.204183 -0.302396 -0.371921 -0.868699 -0.218304 0.96288 -0.870025 -0.513376 -0.312657 -0.818626 -0.647988 -0.735079 -0.480229 0.789266 -0.800399 -0.303093 -0.079715 0.229431 0.0448008 0.967231 0.243306 -0.75649 -0.329926 0.939093 -0.671928 0.904781 0.654967 0.0228023 -0.762193 -0.175259 0.415033 -0.537187 -0.507114 0.927153 0.667884 -0.866968 0.866472 0.794219 0.431003 -0.126015 0.0644454 -0.866598 -0.904802 0.984441 -0.494853 -0.997422 0.329081 0.86727 0.211636 0.973467 -0.940118 -0.570487 -0.173519 -0.34119 -0.384145 -0.32836 -0.749405 0.744182 -0.54011 0.368081 0.329327 -0.99784 -0.691829 0.422132 0.76678 -0.721479 0.0954749 0.646805 0.853988 0.983143 -0.321079 -0.370222 -0.327088 0.627461 -0.256662 0.28088 0.751915 -0.566078 -0.065895 0.502453 0.721139 0.176718 0.107564 -0.16509 -0.668692 -0.709294 0.900116 0.254266 -0.559149 0.389086 -0.623703 -0.582347 0.500016 -0.232311 -0.447263 0.846638 -0.560213 0.504205 0.17053 0.0905307 -0.450657 -0.185383 0.268466 0.113307 0.357882 0.923216 0.487182 0.0750342 -0.899437 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.842042 -0.195088 -0.842789 -0.761529 0.981527 0.530467 -0.437396 0.684647 0.86924 -0.691556 -0.978859 0.317227 -0.365998 0.672497 0.658526 -0.15935 -0.189031 0.952495 0.576739 -0.740647 -0.0467433 0.386056 0.447216 0.361224 -0.905476 -0.341285 0.0150179 0.406302 0.715572 0.611597 -0.881919 -0.419728 -0.364652 -0.702487 -0.695865 0.598424 -0.282158 -0.223888 -0.88028 -0.870971 -0.40269 -0.0132029 0.0993046 -0.988023 0.302044 0.44883 -0.507822 -0.956797 -0.886522 0.231545 -0.426347 0.38257 -0.145476 0.976494 -0.0648833 -0.49404 0.667356 0.254877 -0.28502 -0.327226 0.307851 0.0475369 0.953067 0.191215 -0.250971 -0.0653757 -0.769079 0.0808943 -0.409229 0.0882939 -0.0448248 0.629289 0.457564 0.27971 -0.918976 0.77875 0.450036 -0.242925 -0.84658 -0.469709 -0.395364 -0.890843 -0.406679 0.949734 0.176528 0.911713 -0.831652 0.431621 0.261236 0.595322 -0.415716 -0.945912 0.0551416 0.764752 -0.818247 -0.272315 -0.791346 -0.160556 -0.467264 0.701887 0.608458 0.346438 0.58238 0.0688515 -0.81202 0.375712 0.596851 -0.720369 0.763213 -0.685555 -0.12972 -0.210789 -0.726783 0.963538 0.185113 -0.810735 -0.01479 -0.574778 -0.286781 0.0635683 0.392405 -0.854921 -0.662334 0.147068 -0.220157 -0.174205 0.144452 -0.198044 -0.524112 -0.748395 -0.267447 -0.987975 -0.894454 0.907388 0.468187 0.817647 0.194675 -0.104632 -0.543779 0.707592 0.499325 0.157349 0.559404 -0.0927854 0.55558 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.364824 0.407204 -0.127177 0.530516 0.389522 0.704267 0.616372 -0.635917 0.141912 -0.893064 0.274062 0.160752 -0.241826 -0.37735 -0.126528 -0.552465 0.713279 0.0794075 0.602692 -0.550916 0.748839 -0.263817 0.0253511 0.0758463 0.748107 -0.562456 0.809703 0.670757 -0.580602 -0.178946 0.461776 -0.932768 0.964181 0.994252 0.39615 0.0965894 -0.621876 0.134619 0.537071 0.558662 -0.57489 -0.168898 -0.669876 -0.597898 -0.873247 -0.658656 -0.0338965 0.302358 -0.276776 0.227591 -0.884431 -0.637715 -0.075215 -0.137742 0.972597 0.437704 0.486094 -0.220294 -0.472966 0.865318 -0.593279 0.75914 0.858633 -0.959656 -0.932649 0.960907 -0.0329344 0.470791 0.587447 -0.782129 0.753908 0.935917 -0.0438532 0.958539 0.160258 -0.55185 -0.937725 -0.346424 -0.345241 -0.473871 -0.346717 0.723285 0.250442 -0.816286 0.688659 0.286477 0.810817 -0.594464 0.839731 -0.647464 0.0648745 0.345683 -0.0976682 0.490636 0.113119 -0.808526 -0.898187 0.174718 0.48736 -0.933884 0.212435 0.399995 0.712331 0.140005 -0.939698 0.492952 -0.95204 -0.937013 -0.384382 -0.306785 -0.142479 -0.642882 -0.913572 -0.398317 -0.507614 0.530132 -0.0665434 -0.395626 0.718829 -0.633542 0.0545634 -0.953376 0.605611 0.509431 0.00144205 0.236473 0.407726 0.649219 -0.572313 -0.869432 -0.541596 -0.596801 -0.431879 -0.590001 -0.145944 -0.88799 -0.442055 0.385846 0.90929 0.441018 0.197415 -0.0507217 -0.480189 -0.531796 0.102723 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
1.12853 -0.180771 -0.212724 0.754215 0.0876871 -0.242506 0.206716 0.278797 -0.255685 0.698349 -0.850694 -0.213663 -0.179435 0.730343 0.034368 0.233649 0.771244 0.0577414 -0.163764 0.204011 0.860112 0.235515 -0.224438 -0.493983 -0.1686 -0.462159 -0.919008 -0.617646 -0.680507 0.188349 0.802476 -0.121253 -0.0257702 0.533344 0.372103 -0.327614 -0.0749085 0.957508 0.283626 -0.145757 0.462811 0.870518 -0.0186376 0.961359 0.680806 0.673408 0.593931 -0.000539744 -0.154455 -0.00081053 0.212482 0.265353 0.885534 -0.644736 0.367825 -0.63822 -0.567405 -0.371674 -0.716778 -0.895543 0.608726 0.859561 0.63714 0.411527 0.538454 -0.200231 0.725403 -0.160161 0.175383 -0.337351 0.136881 0.563208 -0.159331 0.118274 0.402293 0.163774 0.782086 -0.253382 0.920248 1.00111 -0.628326 0.938767 0.946216 -0.934519 -0.429591 -0.956314 0.789173 -0.0887166 -0.227623 -0.219847 -0.500784 0.980852 -0.821681 0.000902291 -0.835196 0.852885 0.430578 0.721372 0.101408 0.362185 -0.763689 0.613626 0.0779152 0.363605 -0.28168 -0.269191 -0.842087 -0.176871 0.204823 0.228117 -0.0401958 0.429003 0.252763 0.195739 -0.214162 0.579969 -0.463085 0.926192 0.506228 0.180534 0.230401 0.346893 0.233799 -0.538721 -0.291198 -0.157413 0.355438 -0.145121 -0.253645 0.691306 -0.712991 0.562646 0.547002 0.304506 0.134259 0.476708 0.538865 0.700436 0.223964 0.164525 -0.830297 -0.80878 0.83065 0.742217 0.438826 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.65688 -0.17971 -0.386352 0.583478 0.509421 -0.160219 -0.808079 0.624191 0.772094 0.587631 0.309615 -0.295188 0.773608 0.0215621 0.39354 0.235143 0.0474289 -0.862244 0.264331 0.605757 0.953825 0.935737 0.935544 -0.313871 0.774946 0.512434 0.481461 -0.0823055 0.691041 0.330924 -0.153143 0.130711 0.856631 -0.603918 -0.0486041 -0.888726 -0.814151 0.556518 -0.607353 0.222171 0.0276343 0.450429 0.355518 -0.811245 -0.600145 -0.634539 -0.701912 0.959151 0.453843 -0.265221 0.42866 0.487688 0.567161 0.282192 0.802491 -0.531042 0.77244 0.406943 -0.504935 -0.446659 0.996499 0.166474 -0.0655469 0.353618 -0.734614 -0.661091 -0.963507 0.342478 0.0361088 0.88077 -0.902529 -0.80821 0.4131 0.979264 0.483215 -0.608355 -0.629567 0.862204 -0.929322 0.89146 0.773159 0.479854 0.897828 -0.210273 -0.0618962 -0.289697 -0.938472 -0.903677 -0.0955614 -0.101226 0.689614 0.346202 0.615163 -0.962109 -0.172262 0.78924 0.753138 -0.00775516 -0.340925 0.0740052 -0.195025 0.221487 0.536129 0.726871 0.527307 0.448151 0.0685594 0.27842 -0.594168 -0.177815 -0.534626 0.547512 0.0272691 0.312082 -0.836327 -0.155128 0.762985 -0.503117 0.104904 -0.88606 -0.00543256 0.694939 -0.164713 -0.327721 -0.00411342 0.865791 -0.656949 0.653206 0.435605 -0.793379 -0.315552 0.523803 -0.439862 -0.763068 -0.892215 0.549 -0.964413 -0.891988 0.365372 0.807219 0.931274 -0.0707982 0.0951984 -0.000696412 0.295407 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
1.17357 -0.694318 0.592254 0.0151313 0.311193 0.223979 0.413388 -0.19171 -0.0707451 0.987545 -0.324857 0.903612 -0.731844 0.360883 -0.118707 -0.0513528 -0.891106 0.241971 0.228467 -0.0507592 0.746384 -0.00432267 -0.480765 0.493167 0.625781 -0.527695 -0.386133 0.235051 0.327739 -0.841631 0.680136 -0.111939 -0.745327 0.251873 0.88422 0.145622 -0.842312 0.886089 -0.03771 -0.805271 0.623192 -0.476838 0.488386 0.471716 -0.136136 0.435408 -0.705224 0.245962 0.341986 -0.233846 0.381198 -0.511547 0.74926 0.368325 -0.0122584 0.198632 0.400802 0.280124 0.0495298 0.446859 0.361655 0.330738 0.708405 0.162288 -0.433622 0.106679 0.961521 0.287965 -0.1757 -0.983594 0.740943 -0.97603 -0.14046 -0.708108 0.942828 -0.572464 0.750301 0.291744 -0.315667 -0.0897126 0.944513 -0.6702 0.379421 -0.236188 -0.955034 -0.0551537 -0.580818 -0.238758 -0.0670807 0.365159 -0.405669 -0.886938 -0.759735 -0.86942 -0.340536 0.608977 -0.931152 0.131888 0.644385 0.173507 0.134339 0.420628 0.0342089 0.701643 0.365967 -0.243945 -0.980363 -0.37413 -0.467743 0.456574 -0.353094 -0.44632 0.702283 -0.735231 0.972178 -0.602303 -0.911248 0.657864 0.725766 -0.0511475 0.363598 0.997784 -0.246944 -0.379819 0.374822 -0.361845 0.474398 -0.800258 0.145187 -0.804987 0.71822 -0.0415608 -0.746267 -0.620362 -0.0356857 0.795207 0.524961 -0.972113 -0.302725 0.100111 0.571553 0.0968912 0.449799 -0.221758 0.920381 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.41834 -0.618633 0.638863 -0.629498 0.0313858 -0.499151 0.770543 0.516367 0.577451 -0.789327 -0.215619 -0.462339 -0.200448 0.832625 0.471433 -0.484293 -0.188705 -0.583291 0.979408 0.524684 0.0421113 -0.14222 -0.749056 0.312595 0.219867 0.632283 -0.707655 -0.289233 -0.908786 0.423945 -0.639843 -0.521023 0.589751 0.92965 -0.894573 0.169072 -0.32678 0.188198 -0.180705 0.937667 0.186799 -0.674766 0.919363 0.706256 0.635368 -0.7082 -0.650079 -0.178485 -0.946008 0.378164 -0.418393 0.392826 -0.993347 0.841945 -0.693103 0.783979 0.329269 0.0173213 -0.880938 0.0708079 0.0687797 -0.0195664 -0.852696 0.740479 -0.766523 -0.959382 -0.336332 -0.737645 0.394316 -0.727832 -0.672762 0.882573 -0.601614 0.678807 -0.776154 -0.990436 -0.439977 -0.589668 -0.624472 -0.631078 0.923396 -0.967035 0.289196 -0.240978 0.893167 0.692732 0.355312 0.284416 0.546222 -0.268507 0.807005 -0.753391 -0.242292 -0.202624 0.500619 -0.0899154 0.792374 -0.570591 0.0706503 -0.580885 -0.927162 0.431585 -0.0138107 -0.311443 -0.905748 0.426436 -0.460824 0.520311 -0.615987 0.397891 -0.646689 -0.905332 0.0845759 -0.532169 -0.168031 -0.0895374 -0.855494 -0.292525 -0.470486 0.542989 0.0114663 0.714161 0.902363 0.0165285 -0.205207 -0.908901 0.0974278 -0.532356 -0.55154 0.228202 0.525457 0.720392 0.400481 -0.439386 0.241955 -0.791793 0.120927 0.417553 -0.179891 0.576078 0.137144 0.971771 0.550578 -0.428263 0.184793 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.184351 -0.38628 -0.211418 0.698039 -0.0527078 0.139235 0.123407 0.107605 0.517635 -0.101281 -0.234617 0.785724 -0.328546 0.126512 0.279137 -0.538992 -0.83968 -0.4999 0.187917 0.320538 -0.72236 -0.696723 0.176476 0.037195 -0.864099 -0.907081 0.695495 -0.815786 -0.915197 0.288672 -0.288321 0.184364 0.597561 -0.794453 -0.376761 -0.228331 0.445106 0.898787 -0.0911457 0.114261 0.387053 -0.795964 0.236359 0.492926 0.613972 -0.970442 -0.210708 0.626099 0.848672 -0.367682 0.36837 -0.804596 -0.851911 -0.0603334 -0.0237444 0.92771 0.0284568 0.273785 -0.500023 0.111503 0.0299655 -0.370391 0.836776 -0.299282 -0.0245297 -0.271227 -0.505113 0.566062 -0.188008 0.148624 -0.0690013 0.295702 -0.142281 0.691167 0.447253 0.980149 -0.634114 0.438804 0.984751 0.704971 0.445945 0.993937 -0.90238 -0.301361 -0.981055 -0.591195 -0.210329 0.999926 -0.250513 -0.370865 0.870409 0.964621 0.385272 -0.73671 0.117132 0.637809 -0.338317 -0.100299 0.271055 -0.386762 -0.304933 0.999036 0.793029 0.443709 -0.590887 0.968411 0.0804911 0.813605 0.256029 -0.917526 -0.865949 -0.0040006 0.761901 -0.73394 0.665825 0.520366 -0.209236 -0.635562 0.117063 -0.527177 -0.264234 -0.974929 0.364317 -0.92112 0.744346 0.219734 -0.935535 0.456514 0.632781 -0.849832 0.875843 0.297975 0.0590887 -0.895749 -0.858528 0.725582 0.85609 0.312782 0.931401 0.063124 0.925438 -0.164757 0.923076 0.146503 0.279508 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.316778 -0.0888969 -0.0893842 -0.2804 -0.677168 0.837465 -0.721405 -0.649942 0.41732 -0.101653 -0.48341 -0.667387 -0.774736 -0.98102 -0.000695199 0.315786 -0.578515 0.901941 0.917198 -0.658983 0.480914 0.72816 0.17711 0.696131 -0.130444 -0.373045 0.235065 0.736794 -0.706398 -0.425345 -0.779936 -0.378821 -0.845442 0.655934 0.285184 -0.918361 -0.898692 -0.310444 0.374362 -0.0896801 0.747007 0.947606 0.417534 -0.503824 0.227026 -0.367142 -0.55719 -0.685378 0.851015 -0.991872 -0.394982 -0.464518 0.849619 -0.452948 -0.696348 0.483559 -0.816247 -0.669469 0.226633 -0.974288 -0.862545 -0.78806 -0.928757 0.382029 0.756573 -0.28224 0.393803 0.652502 0.605813 -0.106291 -0.428209 -0.910103 -0.102228 -0.141979 -0.240961 0.163512 0.139273 0.755011 -0.529816 -0.621653 -0.118335 -0.853024 -0.77002 0.266072 -0.133108 0.857681 -0.952904 0.544978 -0.559841 0.753279 0.359002 -0.261488 -0.83172 -0.72593 -0.703781 -0.454251 -0.604828 0.648606 -0.884353 0.677835 0.37467 -0.927923 0.390572 0.348175 -0.226358 -0.396665 -0.744978 -0.843232 -0.195015 0.390349 0.595446 -0.332697 0.362553 -0.565935 0.331964 -0.686941 0.590963 0.321437 0.399297 0.988336 0.954913 -0.77961 -0.908471 -0.66689 -0.425643 0.215993 0.200969 -0.309979 0.182684 0.372324 -0.356671 -0.567675 -0.906303 -0.23738 0.358356 0.887689 -0.608865 0.808745 0.572714 -0.393958 0.745042 -0.0772772 -0.797867 0.251741 -0.98275 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.700832 0.678017 -0.570151 -0.521566 0.0401975 -0.399826 0.120111 0.700902 0.0618538 -0.423708 0.742714 0.455881 0.300987 0.236097 0.304577 -0.651434 0.150222 0.377201 -0.824295 -0.538669 0.365864 0.191708 0.95351 0.682862 -0.0973941 -0.173552 -0.257674 -0.598015 0.53439 0.0342027 -0.149239 0.143656 -0.415291 0.680269 0.867828 0.483879 0.642847 -0.317933 0.508265 0.769786 -0.163559 0.862585 -0.68538 0.0774817 0.142481 -0.231086 0.322524 -0.694658 -0.0773203 0.551035 -0.732492 -0.0398685 0.166013 0.268702 0.705898 -0.554897 -0.153736 0.158758 0.246944 0.386018 -0.196894 0.80126 0.776507 0.752857 -0.728621 0.0652671 0.943657 0.0453992 -0.97612 0.354936 -0.585629 -0.669908 0.85615 -0.68698 -0.17551 -0.550453 -0.475377 -0.432442 0.488737 0.869932 -0.997113 -0.382734 -0.477037 -0.476101 -0.0442069 0.803441 0.401545 0.699601 0.825259 0.39534 0.448869 0.0778279 0.0537381 -0.823518 -0.871745 0.578066 -0.439157 -0.91022 -0.0689787 0.674936 -0.347419 0.302401 0.797792 0.749279 -0.747919 0.0325777 0.0533986 0.691508 -0.0752352 -0.0293962 -0.0626551 0.95545 0.245133 -0.054207 0.942239 0.21448 0.772798 0.417908 -0.22213 0.664999 0.643822 0.715496 -0.652079 0.500656 0.522529 0.150447 0.568292 -0.722888 0.585752 -0.495232 -0.139718 -0.134994 -0.650902 0.551417 0.997455 -0.052534 0.882536 0.790027 -0.0153203 0.51224 -0.78143 0.49844 -0.723835 0.504424 -0.142092 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.143661 -0.514315 -0.0930275 0.486839 0.296028 -0.665278 0.676839 -0.3698 0.763571 -0.662632 -0.857175 -0.534198 -0.262059 -0.419101 0.168217 -0.779524 0.547641 0.201669 -0.544238 0.990338 0.611024 -0.515444 0.92762 0.510626 0.0982278 0.915001 0.422218 0.217476 -0.877069 -0.902003 0.0352585 0.589115 -0.74208 -0.131017 -0.00630364 0.0546976 -0.697347 -0.311579 -0.700393 0.48847 -0.27967 -0.417223 -0.269711 0.970971 -0.887485 0.0325883 -0.287944 0.531533 -0.519331 -0.389364 -0.0370717 0.935676 -0.0927002 -0.0115525 -0.163495 0.140802 0.456275 0.621876 -0.124726 -0.273307 0.526466 0.308656 -0.413314 -0.565713 0.062293 0.958249 -0.710687 -0.514283 0.444268 0.81907 0.112607 0.583579 0.213222 -0.383741 0.470563 0.75791 0.199679 0.00249435 -0.0774348 0.553674 -0.398842 0.665008 0.79581 -0.820658 -0.796722 -0.513782 0.86228 0.337846 0.174739 0.830875 0.522713 -0.758763 -0.528415 0.931915 0.696611 -0.0574033 -0.776895 0.725805 0.603575 0.288803 -0.0833826 0.588493 0.796194 -0.375486 -0.797431 -0.418848 0.418921 0.813199 -0.556137 -0.98678 -0.805651 -0.582628 -0.23475 0.56277 0.467336 0.524427 0.0475666 -0.548503 -0.693209 -0.770421 -0.473074 -0.954798 0.715635 -0.325801 0.266652 -0.373923 -0.51894 0.170871 -0.169219 -0.059943 0.538181 -0.792274 0.243587 -0.0269056 -0.203022 -0.186231 0.0238951 -0.394909 0.756693 -0.256995 0.690317 0.152937 0.417751 -0.862731 0.0783554 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.884254 -0.921714 0.747552 0.109107 -0.236892 0.552705 -0.680445 -0.235631 -0.247429 -0.539905 -0.18448 -0.694952 -0.499144 0.76643 0.538145 0.595406 -0.791118 0.352734 -0.948217 0.772758 -0.322783 -0.91404 0.25941 -0.21155 -0.912453 0.906184 0.134577 -0.397181 0.0592318 0.201753 0.219535 0.244817 -0.925823 -0.807956 0.349559 -0.242555 -0.566125 -0.798891 -0.84534 -0.333405 -0.953402 -0.204406 -0.862368 -0.615888 0.699642 0.195309 -0.313127 0.592071 0.705555 0.35599 0.296345 -0.595929 0.931757 -0.0736179 -0.894202 0.599488 -0.405963 0.974935 -0.275065 0.978055 0.178749 0.226371 0.613111 0.554047 -0.135978 0.623063 -0.179631 0.939811 -0.601397 0.320056 -0.812665 -0.465234 0.820396 0.387929 0.855907 -0.273347 -0.453538 0.43338 0.0867715 -0.19077 0.409837 -0.985596 -0.224868 -0.815902 -0.952936 -0.0319391 -0.781808 -0.90203 -0.0522056 -0.311752 -0.885381 -0.231276 0.945199 -0.0421496 -0.408752 0.105877 -0.525442 0.900716 0.329511 0.0862663 -0.121955 0.788871 -0.810518 0.732587 0.466062 -0.669543 0.357483 0.600479 0.369492 0.759446 0.00498706 -0.182458 -0.563355 -0.306444 -0.411698 0.587108 -0.472448 -0.425717 0.974309 -0.795271 -0.116767 -0.495346 0.719039 0.892581 -0.384215 0.490907 0.670649 -0.408646 0.748831 -0.0941406 0.832452 -0.431379 -0.296372 -0.30966 -0.611898 -0.14596 -0.174913 0.228899 -0.902038 -0.55989 -0.0704464 0.00679945 0.278351 0.241895 -0.477668 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.158142 0.0998919 0.883721 0.701891 0.688349 -0.915821 -0.198491 -0.0306018 -0.324061 -0.488914 0.828294 -0.869339 -0.979077 0.659526 0.659487 -0.0084627 -0.23253 -0.124358 -0.0785168 0.368839 -0.921877 0.00830726 -0.379819 0.389129 0.0892319 -0.279074 -0.388764 0.0428067 -0.548538 0.714757 0.922057 -0.993277 -0.00267715 -0.994806 0.28759 -0.470386 0.225705 -0.574856 0.392065 -0.567373 0.169176 -0.666391 -0.0341474 0.0847428 0.272269 0.0306704 -0.523225 0.163578 -0.742809 -0.387331 0.134406 0.963191 0.353857 -0.722849 -0.91704 -0.697771 0.565502 0.390937 0.483845 -0.0204361 0.530198 -0.966453 0.818951 0.114128 0.146301 0.882989 0.387772 -0.709044 -0.908237 -0.737161 0.539313 0.226742 0.85331 -0.421333 0.655568 0.13275 -0.878225 -0.332154 -0.517551 -0.475243 0.5906 0.221487 0.531841 0.644163 0.45559 -0.892122 0.112113 0.288786 -0.374617 -0.19568 -0.789056 0.335805 -0.131869 -0.32809 -0.205337 0.899355 -0.533991 -0.778823 0.315041 0.895334 -0.117209 0.0653926 -0.947027 -0.679167 -0.763314 0.986592 -0.356405 -0.103764 0.0388445 0.85903 -0.283199 0.271357 0.704323 -0.447594 -0.716455 0.538446 -0.337286 -0.764343 -0.320563 0.294273 -0.157213 -0.27639 0.717889 -0.438253 0.277507 0.0580873 0.273503 0.76039 -0.120694 -0.508313 0.778917 -0.740063 -0.230848 0.132248 0.687156 -0.974116 0.0258239 0.0218807 -0.250969 -0.0348841 -0.297857 -0.0807704 0.491685 -0.250549 -0.979835 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0848864 -0.685499 0.818507 0.644547 0.902844 0.0962217 -0.801937 -0.153637 -0.183179 -0.683411 -0.0928431 -0.414545 0.737109 0.593886 -0.56293 0.834836 -0.915378 -0.75818 -0.738472 0.498801 -0.650698 -0.276581 -0.501754 -0.979691 0.337641 0.732216 0.356307 0.454482 0.476909 -0.590997 -0.893702 -0.442366 -0.849494 0.547441 0.839211 0.612766 0.764553 -0.162454 -0.369188 -0.94552 0.638073 0.0921903 -0.558431 0.443949 -0.54708 -0.771833 -0.205584 0.750268 -0.240072 -0.895543 0.616803 0.606558 0.421832 -0.261537 0.354243 -0.23435 -0.724554 0.428227 -0.790726 0.265717 -0.0889748 0.600904 -0.603094 -0.205416 -0.427512 0.812483 -0.593938 -0.311025 0.603438 -0.0197409 0.215249 -0.313395 0.76678 -0.727506 0.811378 0.830707 -0.306613 0.75237 -0.919652 -0.594577 0.94708 -0.430771 0.0298081 0.98428 0.801308 -0.409394 -0.68642 -0.663006 0.85199 -0.608307 0.179961 0.604859 -0.137215 -0.173494 0.0851278 0.742251 -0.99525 0.840581 -0.358862 0.604687 0.982415 -0.551816 -0.364021 -0.100402 0.547297 0.4154 -0.377146 -0.69252 0.808989 0.68292 -0.167608 -0.985479 -0.952894 0.703274 -0.076538 -0.373474 -0.98343 -0.511344 -0.163218 0.798478 0.013982 0.994853 0.493685 -0.638375 0.831188 -0.217074 -0.369823 0.387107 0.106683 -0.984383 -0.522844 0.568287 -0.793882 -0.771912 0.469866 -0.968073 -0.396011 0.23883 0.0240088 -0.484054 0.496895 -0.683949 0.871927 0.470555 0.616848 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.637415 0.972167 -0.787413 -0.043013 -0.919216 0.732846 0.938153 -0.459077 0.298521 -0.755227 0.90159 -0.981553 -0.952982 -0.761635 -0.793571 0.444738 0.719477 0.248226 -0.0678779 -0.824607 0.831737 -0.989206 0.416194 0.976769 0.55233 -0.986698 0.560817 -0.347894 0.943295 -0.0414969 0.561454 0.360442 -0.0565316 -0.126667 -0.899343 0.739824 0.222652 0.104933 -0.396865 -0.104447 0.561208 0.220433 0.821221 0.258787 -0.563428 0.461043 0.754349 0.349758 0.387477 0.324201 0.843727 0.524478 0.909892 0.54807 -0.587599 0.218414 0.886679 0.40627 0.185539 0.346433 0.50324 -0.0412622 0.506962 0.505578 -0.745453 -0.835661 -0.951947 0.634428 0.825024 0.174647 -0.69979 0.625184 -0.536467 -0.403916 -0.618844 -0.903133 -0.949353 0.219509 -0.706656 -0.763627 -0.280508 -0.498599 0.0480307 -0.748039 -0.295145 -0.501843 -0.473087 0.823059 -0.852944 0.572734 -0.0586922 -0.439189 0.543515 0.856484 0.934658 0.790874 0.215023 -0.115242 -0.870717 -0.14729 0.502193 0.35872 -0.986393 -0.299027 0.251376 0.873174 -0.559753 0.231038 -0.938917 -0.375762 0.568889 -0.681696 0.731863 0.416093 -0.726719 0.0373629 -0.0411273 0.773103 -0.464789 0.286799 0.227338 0.867181 0.704747 0.687738 0.811146 0.933113 0.822589 -0.742926 -0.354551 -0.940946 -0.479385 0.973997 -0.0301101 -0.0601974 0.261587 0.487999 -0.195041 -0.0530931 -0.33563 -0.930253 -0.753921 0.842393 0.104466 -0.234895 0.116106 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.612917 0.699813 -0.239375 0.823271 0.723879 0.235747 0.196868 0.761403 0.891892 0.0217385 -0.640751 0.901506 -0.382989 -0.898553 0.0157412 0.561906 -0.053396 0.573818 0.156979 0.342731 0.285186 -0.886367 0.827786 0.604114 -0.663898 -0.137214 -0.147839 -0.734003 -0.383503 0.459883 -0.748415 -0.610649 0.816939 0.300957 0.181803 -0.440708 -0.980592 -0.805836 0.319804 0.950232 0.554719 -0.833777 0.710601 -0.932953 -0.148976 0.15596 -0.777702 -0.835587 0.291961 0.9874 -0.776277 -0.890685 0.25939 -0.43966 0.640745 0.996453 -0.606693 -0.683638 0.103839 -0.781147 -0.736475 0.0584759 0.804843 0.990729 -0.811163 0.786281 -0.978445 -0.730296 -0.0872788 -0.895584 -0.0832815 0.288333 0.0145515 0.566863 -0.740678 -0.571486 -0.959563 0.621574 0.787179 0.11679 0.88319 -0.23241 -0.115235 -0.749847 -0.67769 0.070789 -0.248642 -0.929178 -0.693353 0.808429 -0.740138 0.493939 -0.371877 -0.132832 -0.509312 -0.00230559 -0.750021 0.393354 -0.894121 0.504369 0.928151 -0.569817 -0.915381 -0.8114 0.804568 0.38261 0.528405 0.906204 0.575779 -0.883081 0.0575663 -0.483344 0.444615 0.640355 0.445579 0.844649 0.0159468 0.0185155 -0.810809 0.731629 0.491544 -0.613659 0.237338 0.932919 -0.423632 0.0133081 -0.330091 0.157335 0.325881 -0.917308 0.803976 0.43254 -0.301626 0.568621 0.813258 0.424101 -0.14189 -0.750257 0.429095 -0.203798 0.762939 0.711428 0.972486 0.563805 -0.132672 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.316914 -0.908653 0.274596 -0.867098 0.678501 -0.435986 0.384709 -0.191496 -0.475515 0.0274358 -0.885712 0.849029 0.685033 0.518112 0.954511 0.748848 0.215744 -0.143735 -0.888266 0.325048 0.620491 -0.476464 0.403659 0.989137 -0.797782 -0.181688 0.79429 -0.179753 0.529149 0.685837 -0.764131 0.221879 0.323194 -0.368521 -0.836473 -0.485437 0.44569 -0.385944 -0.316624 -0.843178 0.704584 -0.51358 -0.63228 0.741083 -0.427059 -0.254269 0.102336 -0.667898 -0.417645 -0.178991 -0.220403 -0.428517 -0.557463 0.372837 0.554595 -0.348886 0.269074 0.333184 -0.178378 -0.00132359 -0.245649 -0.614405 -0.300991 -0.759029 -0.997319 0.0656586 -0.475994 -0.0346324 -0.0660608 -0.283344 -0.154551 0.462283 -0.406894 -0.662788 0.809519 -0.239868 -0.995287 0.699152 -0.495099 0.825188 -0.880774 -0.696944 0.558892 0.100414 0.770492 -0.774977 -0.727897 -0.295036 -0.32239 -0.0406142 0.803988 -0.421408 -0.601832 -0.991369 0.0595002 0.0203506 0.0325521 -0.896037 0.30847 0.458345 -0.58707 -0.985637 0.245115 0.634903 -0.442105 -0.135453 0.372235 -0.887973 -0.991184 -0.470188 -0.457151 0.664346 -0.336965 0.621842 -0.699385 -0.566939 -0.549922 -0.53593 0.619512 0.137072 -0.235697 0.637548 -0.728582 0.72514 -0.579273 0.152535 -0.348897 0.0924331 0.739758 -0.149781 0.656602 -0.488309 -0.477518 0.0448757 -0.402226 -0.419122 -0.59782 0.434946 0.145708 0.906919 0.589209 0.832492 -0.306496 0.717258 0.957439 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.322387 -0.3508 0.111854 -0.0768724 0.00562725 0.577125 -0.253745 -0.687965 -0.631432 -0.473639 -0.448512 -0.14597 0.682953 0.393324 0.590872 0.791758 -0.924471 0.416902 0.869328 0.798303 -0.919357 0.368781 0.107716 0.37488 0.605072 -0.558029 -0.786069 0.533495 0.455182 0.248833 0.131509 0.273204 -0.267535 -0.468082 0.942128 0.340065 -0.527462 0.943242 -0.928725 0.911639 -0.0813036 -0.470087 -0.751769 -0.988542 -0.426048 -0.597111 0.347181 -0.92232 0.566041 -0.556395 0.664937 -0.411517 -0.366008 0.503854 0.282267 0.0571677 0.817926 0.884063 0.444192 -0.458037 -0.223662 0.907103 -0.315306 0.658458 0.710538 0.0174365 -0.94482 0.41499 0.735806 0.684669 -0.762436 -0.26017 -0.681186 -0.690264 0.725729 -0.670276 0.672254 0.571956 0.85842 -0.530437 0.95151 0.0326557 0.844375 -0.581278 0.458685 -0.888277 0.726837 -0.049246 0.322374 0.135684 0.440502 -0.491013 -0.463153 -0.217413 -0.0584507 -0.380356 -0.644176 -0.667372 -0.520426 -0.792132 0.638644 -0.306827 -0.839902 -0.238259 -0.415043 0.371127 -0.461674 0.63912 -0.306384 0.611725 -0.742487 -0.986885 -0.582566 0.814876 -0.378311 -0.280483 -0.07178 -0.407155 0.943812 0.64845 0.492217 0.685098 0.448249 -0.286745 0.681523 0.353081 0.230109 -0.565218 0.3826 0.359277 0.374603 -0.0552337 -0.312432 0.957566 -0.19136 -0.189542 0.373823 0.850249 0.131168 0.536052 -0.569285 0.0280614 -0.371679 -0.814389 0.565163 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
1.25027 0.575115 -0.035845 -0.447445 -0.201999 0.999021 0.540629 0.350041 -0.862527 -0.498344 0.337715 -0.619399 -0.932182 -0.304091 -0.174378 0.150898 0.820551 0.0886323 0.0340621 -0.42758 -0.34423 0.535851 -0.447616 -0.790782 0.583696 -0.634305 0.444478 0.661526 0.249937 -0.354781 0.184434 -0.994127 0.767878 0.265832 0.898879 0.903539 0.214335 0.218433 -0.966409 -0.00412041 0.216343 0.760018 0.338326 -0.174228 -0.0293815 -0.336367 -0.079224 0.901289 0.482937 -0.0408578 0.438764 -0.2079 -0.498553 -0.480803 -0.057568 -0.989237 -0.106529 -0.432101 -0.327139 -0.22901 -0.96297 -0.631949 0.833378 0.584063 0.354508 0.221922 -0.160287 0.0538422 0.92519 -0.331438 -0.479953 -0.57098 -0.464227 -0.264636 0.231527 -0.171081 0.934591 0.711029 -0.311914 0.609141 -0.730741 0.778008 0.054831 -0.920749 0.249034 0.00715336 0.584171 -0.656633 0.179375 0.0659541 -0.0200582 -0.357693 0.255589 -0.309923 -0.88374 0.98892 0.779792 -0.0280379 0.766379 0.528121 0.122796 -0.0552611 -0.0573209 0.585763 -0.998194 0.707696 -0.722542 -0.108287 0.426964 0.0690036 -0.257321 -0.796406 0.797333 0.772994 -0.289617 0.409964 0.267994 0.167821 0.564603 -0.711983 -0.299749 0.120269 -0.644581 0.522685 0.767053 -0.139923 0.316654 0.00441782 0.643077 0.925578 0.388675 -0.449867 -0.920305 0.74545 0.966577 0.398579 -0.903877 0.547537 0.447608 0.943608 -0.785683 -0.973843 0.625772 -0.643138 0.777151 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.419846 -0.354068 -0.819006 0.964865 0.48679 -0.517304 -0.335297 0.660546 -0.20881 0.526725 0.660806 0.172219 0.486696 -0.103146 0.425767 -0.13468 0.432258 0.966942 -0.601201 -0.384275 -0.513154 -0.575268 -0.526352 -0.393638 0.131619 0.12079 0.121187 0.791539 -0.603929 -0.232665 -0.394427 0.859881 0.0227151 -0.227242 0.740027 -0.36765 0.910017 0.662645 -0.918772 0.197997 -0.268778 0.655078 -0.107744 -0.85689 0.245632 0.337445 -0.558256 -0.602113 0.28645 0.367344 -0.0516916 -0.780246 0.40146 -0.657866 -0.757651 0.166199 -0.699681 0.461579 -0.246782 0.340094 -0.0345887 0.666988 0.0720451 0.862347 -0.53176 0.703631 -0.0700187 -0.804133 0.944405 0.622703 -0.225987 -0.156873 -0.560323 0.656837 -0.535135 -0.0121415 -0.0623963 -0.695171 0.266289 -0.486082 0.414654 -0.917604 -0.162747 0.710655 -0.0175657 0.773801 -0.734345 -0.140972 0.686035 0.196312 -0.580199 0.598737 0.975535 -0.190115 0.730328 0.618455 0.365265 -0.983501 0.296121 0.897852 0.193114 -0.34122 -0.88018 0.806627 0.985274 -0.50118 0.672383 0.734851 0.641552 0.556405 -0.498031 -0.413613 0.405109 0.668859 -0.488162 -0.53356 0.455559 0.584889 0.230958 -0.281264 0.788967 0.166447 -0.517723 0.626371 -0.587709 0.368887 -0.123415 -0.243471 -0.0136376 0.792888 0.0683272 0.375034 -0.802929 -0.821049 0.629378 -0.0466133 0.571006 0.903834 0.743864 0.121054 0.550521 0.602739 0.228167 0.809497 -0.776414 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
1.16653 0.923262 -0.740731 0.54091 -0.923192 -0.0892272 0.358417 -0.0811398 0.28395 0.343576 0.479989 0.886791 -0.0677424 0.333793 -0.297528 -0.370421 0.41506 -0.381968 0.90224 0.101522 0.563135 -0.0670301 0.780686 0.0802293 0.984827 -0.624014 0.443801 -0.973483 0.882921 -0.490795 0.828461 -0.129204 -0.621837 -0.92227 0.125698 -0.411508 -0.468483 0.598746 0.358125 0.711888 0.418998 -0.891265 0.656598 -0.328868 -0.976609 -0.342399 -0.401754 0.707948 -0.959056 0.430593 -0.166586 0.350993 -0.712982 0.30846 -0.844184 -0.316738 0.591309 0.122859 0.889363 -0.476902 0.703603 -0.540603 0.091742 -0.0924075 0.907571 -0.454438 0.265172 0.740994 -0.120859 0.730575 0.773411 0.724688 -0.16279 -0.0170737 0.763034 -0.125554 -0.729898 0.968126 -0.165061 -0.0327782 -0.315268 0.669894 -0.408981 0.700135 0.912265 -0.901473 -0.573265 -0.687883 0.972063 -0.477454 -0.568067 0.59437 -0.427231 -0.477483 0.951571 -0.938443 -0.408768 -0.17199 -0.643072 -0.110643 0.415456 0.718541 -0.0485435 0.517112 0.776901 0.993276 -0.870271 -0.527037 0.998849 0.00695671 0.921441 0.657555 -0.470677 -0.67019 0.120242 0.904291 0.421501 0.165071 0.349173 0.547555 0.757 0.895449 -0.196086 0.383172 -0.0197982 -0.748584 0.544919 0.461379 -0.407219 -0.538477 -0.429814 0.056208 -0.794167 0.370652 0.107047 -0.0998309 0.404176 0.985504 -0.640275 0.894029 -0.0476037 -0.075368 -0.710035 0.447768 -0.363542 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.0527654 -0.828214 0.211264 0.711307 0.940228 0.409433 -0.655476 -0.587464 0.488343 -0.4194 -0.848502 -0.764799 0.0249033 0.549806 0.591046 -0.286017 0.917942 -0.156686 0.572886 0.494943 0.499553 -0.0183273 -0.0265707 -0.574516 0.107944 0.214669 -0.0622338 0.0363574 -0.941045 -0.138951 0.649097 -0.627471 0.0966285 0.0344279 0.630457 0.08818 0.0414244 0.220105 -0.689451 0.397551 -0.360471 -0.435246 0.818212 -0.316682 -0.479514 0.815218 -0.624365 0.30136 0.961098 -0.830165 -0.583243 -0.557762 -0.305942 0.02494 -0.83418 -0.069649 -0.591107 -0.730175 -0.0474296 0.850442 -0.623315 -0.0585826 -0.598224 -0.348731 0.874003 -0.629411 -0.502939 -0.891414 0.00165176 -0.238827 0.0290696 0.573334 0.0184 -0.750856 0.355478 0.510647 0.439739 0.697924 0.0160573 -0.125367 0.954103 -0.398948 0.874132 -0.4701 -0.964114 0.12819 0.49035 -0.692491 -0.693504 0.277036 0.151513 0.486107 -0.00514662 -0.49917 0.455626 -0.301152 0.530496 0.0466649 0.296844 -0.941583 0.819104 0.674775 0.942901 -0.656485 0.455235 -0.858773 0.596264 -0.585538 0.855107 -0.216604 -0.45561 0.555384 0.343014 -0.963379 0.494041 -0.647477 -0.148895 -0.477462 -0.701439 0.920932 0.108796 0.540259 0.125166 -0.336158 0.185331 0.864356 -0.763309 -0.938792 -0.275133 -0.162622 0.809202 0.261871 -0.726317 0.794728 -0.999467 -0.035661 0.645615 0.847253 -0.221595 -0.340734 -0.710061 -0.0024987 0.00443041 0.461838 0.112396 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.953439 -0.448601 0.369368 -0.0354576 0.0637033 0.660846 0.846821 0.517883 0.053206 0.232538 0.270116 -0.161717 0.0246815 0.821934 0.248722 0.275705 -0.230197 -0.912745 -0.504664 0.109258 0.299885 0.159052 -0.816151 0.94893 0.662768 -0.860922 0.480936 -0.91657 -0.796535 0.644126 -0.166356 0.0629302 -0.331631 0.280102 -0.32144 -0.444299 0.669383 0.314485 -0.458648 -0.503144 -0.348431 -0.0809001 0.311885 -0.155303 -0.174173 0.68037 0.983537 0.305931 -0.221961 -0.498098 0.461268 0.532686 0.84774 -0.031127 0.84839 0.882933 -0.549138 0.639261 0.0674325 -0.661754 -0.0922125 0.184628 -0.951786 -0.674319 0.724233 0.176791 -0.678926 -0.704887 0.958935 0.828262 0.591346 0.751942 -0.103226 -0.921104 -0.998793 -0.710059 0.031139 -0.646156 0.0535129 -0.609337 0.880147 0.637982 0.567128 -0.274905 -0.320344 -0.0290868 -0.86125 0.96945 -0.457736 0.823469 0.0482233 0.489714 0.624734 -0.0912614 0.169189 -0.436358 0.124522 0.836373 0.916947 -0.874688 -0.87482 0.898938 0.448949 -0.50737 0.628004 0.856253 -0.960135 -0.989396 -0.773568 0.646606 -0.486416 0.813634 0.748934 -0.667629 -0.842757 -0.218692 0.442513 -0.684385 -0.464246 -0.579766 -0.121597 0.323025 -0.922097 0.315936 -0.0667355 0.376592 -0.621908 -0.402943 -0.267445 -0.948499 0.582149 0.180633 -0.100548 0.0955926 0.62481 -0.811587 -0.350147 -0.921337 -0.909708 0.541828 0.495585 -0.70358 0.937306 -0.704337 0.214979 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.849684 -0.639832 0.338065 -0.143487 0.415627 -0.554356 0.940098 0.228615 0.339858 -0.0104939 -0.370917 -0.0101045 0.174228 0.252893 0.371548 0.60632 0.415592 0.860091 -0.454135 -0.650381 -0.945712 -0.589663 -0.45932 0.2058 0.873842 0.654401 0.518459 -0.252114 0.721467 -0.305175 0.929699 -0.542991 -0.0547774 -0.64428 -0.422216 -0.186359 -0.128685 -0.811236 -0.442334 -0.306579 -0.676196 -0.819589 -0.827582 0.827812 -0.963699 -0.884161 -0.100111 -0.570254 -0.261618 0.980684 0.357679 -0.48102 -0.504526 0.428039 0.05268 -0.607299 -0.872365 0.160496 -0.547425 -0.576119 -0.83848 -0.336042 0.145289 -0.127359 -0.522472 0.813746 0.624132 -0.21359 0.192441 0.352917 -0.527403 -0.0633411 -0.574201 -0.593604 -0.702758 0.740892 0.17567 0.478683 -0.769807 -0.145726 0.785849 -0.23662 -0.87502 -0.463083 0.97207 -0.419258 -0.461068 0.837474 -0.571561 -0.227451 -0.763181 -0.786227 -0.121882 -0.474806 -0.0585135 0.562849 -0.191709 -0.0540279 -0.0477392 -0.3522 0.579714 -0.741354 0.057379 0.368061 0.00321804 0.085604 0.745605 -0.611565 -0.578468 -0.312855 -0.159594 -0.288217 -0.06865 0.199555 -0.0856436 0.588386 -0.99113 0.0767599 0.103929 0.733224 -0.700621 0.665899 -0.229231 -0.6799 0.915555 -0.26866 0.62881 0.407048 -0.750686 -0.777598 0.907048 0.758944 -0.42035 -0.820603 0.127932 0.149736 0.608676 0.0163321 0.49277 -0.0170967 0.655941 0.392076 -0.375251 -0.841201 -0.0669418 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.807437 0.454887 -0.717625 0.881909 0.247845 -0.468251 0.0984008 -0.178332 0.767508 -0.499492 -0.970116 -0.346627 0.163214 0.677294 -0.459483 0.478264 -0.673035 0.425319 -0.57323 -0.768527 -0.826708 -0.18165 -0.8066 0.436584 0.789824 -0.757564 -0.0822901 -0.182142 0.976334 0.92229 0.0117291 0.916174 0.148739 0.143722 -0.513983 -0.346912 -0.184335 -0.164847 0.234828 0.0888781 -0.0893656 0.121735 0.748432 0.476837 -0.097404 0.772972 0.652293 -0.282222 0.570008 -0.777775 0.280936 0.908321 -0.786649 -0.0721637 -0.8677 0.461656 -0.951846 0.319445 0.910811 0.000516071 0.673613 -0.588601 -0.623651 0.301955 0.954698 -0.386956 0.431143 0.216793 -0.36175 0.0753909 -0.905111 -0.208574 0.499656 -0.285842 -0.875834 0.887626 0.6604 -0.446885 -0.688217 -0.756242 0.918488 -0.707837 0.309589 0.897787 -0.31249 -0.547334 0.550287 -0.0401398 0.367421 -0.0175632 -0.387715 0.788472 -0.157507 0.784639 -0.570999 -0.77772 0.856054 -0.296892 0.137705 0.408525 0.0802255 -0.7325 0.00250911 -0.629065 0.718121 0.493257 -0.66545 -0.901158 -0.815744 -0.87763 -0.329945 0.617225 -0.295003 -0.1197 0.209641 -0.562604 0.32231 -0.932146 -0.575313 0.718826 -0.687153 -0.979285 -0.849833 0.852208 -0.946146 0.131016 -0.0191477 0.184128 -0.531488 0.781148 0.141078 -0.543932 -0.709723 0.748712 -0.802619 -0.592595 -0.261271 0.82537 -0.0113619 -0.960037 0.662093 -0.195665 -0.540725 0.0298224 -0.774996 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
0.585854 0.499106 0.474338 0.191682 -0.401357 0.389998 0.700922 0.40371 -0.853122 -0.416595 0.293732 -0.425554 0.373786 -0.786397 0.159844 -0.182579 -0.2367 0.546914 -0.430327 0.932583 0.301874 0.158559 -0.0117876 -0.291599 0.0839721 -0.661502 -0.928696 0.32223 0.267073 0.350874 -0.389632 0.155156 0.929488 -0.105168 -0.335124 -0.504793 -0.312597 -0.67744 -0.419623 -0.216408 0.112547 -0.628863 -0.65126 -0.204671 -0.221047 0.836337 -0.701126 0.581263 0.347969 -0.925875 0.543272 0.497844 -0.811401 0.511107 -0.547719 -0.182388 0.608957 0.738842 -0.290487 -0.209631 0.732044 -0.529197 -0.212629 0.350669 -0.308136 -0.846463 -0.504774 0.270953 -0.0850213 -0.952657 0.688962 -0.616397 0.215328 -0.982707 0.662947 -0.13213 0.927732 -0.624979 0.199546 -0.0634379 -0.836436 0.890532 0.519364 -0.0380979 0.47358 -0.65368 -0.764057 -0.113342 0.356551 -0.448287 -0.194218 -0.911547 -0.367025 -0.58496 0.574158 -0.119003 -0.0759277 -0.116689 0.812519 -0.00118415 0.0980241 0.639387 -0.776054 0.940258 -0.782537 -0.168063 -0.871549 -0.63737 0.601338 -0.626268 0.309558 0.733732 -0.17207 0.0243947 0.0024717 -0.458141 0.0295077 -0.0641347 0.0879911 0.866313 0.128682 0.764966 0.79093 -0.832086 -0.863384 -0.900319 0.340873 -0.955819 -0.484632 0.883746 0.195563 -0.693991 -0.527972 0.351929 -0.748134 0.415654 0.916983 -0.263198 0.435643 -0.146028 -0.298943 -0.337577 0.34715 0.546207 0.0979233 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.202615 0.651778 0.430925 0.553567 -0.201943 -0.0629263 0.39684 -0.307251 0.0249847 -0.082802 0.347239 0.053456 0.434391 0.803965 0.246084 -0.0578909 -0.972575 -0.0674851 -0.222564 -0.625545 0.458806 -0.84392 0.238629 0.639386 0.157934 0.396837 -0.354601 0.221366 0.504999 -0.486059 0.81167 -0.268687 0.184037 -0.885453 0.198854 0.135405 -0.255054 -0.691615 0.0341106 -0.702462 -0.286812 -0.447541 0.185612 -0.416093 0.73215 -0.750138 0.431221 -0.469911 0.205252 -0.329123 0.421626 0.264933 0.726958 -0.0108681 -0.660704 -0.45815 -0.132639 0.735971 -0.543074 0.55288 0.257058 0.368544 0.120572 0.44871 -0.52632 0.132263 0.944831 -0.22398 -0.424548 0.618824 0.577556 0.977367 0.599087 0.861168 -0.353449 -0.421643 -0.557436 -0.820252 0.0175564 -0.929326 0.815419 0.752009 -0.981457 0.653146 -0.576752 0.530649 0.624812 -0.788061 -0.947556 0.428262 -0.207411 0.0401432 0.686899 0.712537 -0.395355 -0.739341 -0.0981759 -0.0424391 0.725782 0.219895 -0.219723 -0.878698 -0.275575 0.415147 -0.630637 0.887304 0.917272 0.591922 0.428669 0.638017 -0.855004 -0.0507792 0.554225 0.862054 0.540491 0.0399315 -0.871454 -0.521296 0.577645 0.474379 0.884128 -0.464013 -0.673515 0.229995 -0.482193 -0.220152 -0.0971304 -0.471411 -0.996831 0.262387 -0.0566405 0.0426196 0.307406 0.565277 0.618393 -0.676174 -0.453894 -0.592893 -0.757903 -0.0776345 -0.802226 0.986829 -0.363517 0.371142 -0.215457 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
1.00691 -0.962947 -0.255125 0.114802 -0.530883 -0.55894 -0.101131 0.286616 -0.841976 0.903578 0.432127 -0.88611 0.287058 0.395229 -0.946767 0.808196 -0.101557 0.937896 -0.790167 0.339917 -0.694661 -0.411123 -0.107649 0.785873 -0.874981 0.903892 -0.750846 -0.850505 -0.732401 -0.931857 -0.398505 0.903294 -0.229178 0.567759 0.277535 0.438477 -0.139693 0.601671 0.253959 0.418715 0.996582 0.449363 0.373048 -0.226527 -0.760979 -0.421491 0.0242612 0.957843 -0.159197 -0.693954 0.509168 0.0793352 0.394783 0.626669 -0.863226 -0.0750699 0.300188 -0.743321 -0.993222 0.919488 -0.160305 -0.248506 -0.642642 -0.876245 0.94815 -0.434896 0.704487 0.306082 0.328152 -0.751361 -0.122969 -0.742929 -0.40669 0.754946 -0.321567 -0.552722 0.674995 -0.765726 0.851002 -0.108319 0.332742 -0.976708 0.773699 0.718087 -0.644842 0.523266 -0.0566493 0.902599 0.919197 0.102108 0.384966 0.457639 -0.46829 -0.555931 0.473352 -0.37106 -0.402422 0.492375 -0.648364 0.951122 -0.486148 0.285343 0.544162 0.252394 0.100097 -0.261892 0.796363 -0.539451 -0.295486 -0.921472 0.82257 0.941562 0.831058 -0.413905 -0.500803 0.995588 0.849252 -0.616856 0.509391 -0.667306 0.595552 -0.555845 -0.0872534 -0.467216 -0.493985 -0.409962 -0.229128 -0.950617 -0.22808 0.369352 0.0224977 -0.768451 0.268617 0.720158 0.61978 -0.174635 0.154663 -0.580714 -0.0673076 0.761177 -0.896118 0.94305 -0.150325 -0.514245 -0.9225 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.458491 0.139226 -0.034247 0.410401 -0.395975 0.850461 -0.297848 0.0718751 0.00470492 -0.924345 0.532338 -0.992688 -0.105529 0.376701 -0.778015 -0.100057 0.346464 -0.977418 0.543283 0.964932 -0.388968 0.622887 0.858026 0.834696 0.73931 -0.424078 0.525836 -0.268932 0.0568014 0.66197 -0.267806 0.988335 0.942297 -0.818525 -0.94425 -0.010903 0.75357 -0.746215 0.365048 -0.639903 -0.843122 -0.352625 -0.56202 0.133134 -0.422441 0.0323781 0.1782 -0.989023 -0.501672 0.399269 0.506685 -0.143645 -0.242349 0.84511 -0.228215 0.388112 0.996222 -0.491436 0.430613 -0.687518 0.887471 -0.279041 0.162995 -0.543129 -0.373324 -0.450942 -0.987706 -0.370641 0.642766 0.967733 0.684202 -0.621222 -0.877832 0.279375 -0.551034 0.76642 -0.785554 -0.802761 -0.00256995 0.806871 -0.924352 0.408415 0.237975 -0.3602 0.110513 -0.614452 0.900187 -0.557989 -0.121344 0.563993 -0.962382 -0.760862 0.184051 -0.647265 -0.580102 0.22778 0.303061 -0.453511 -0.162013 -0.946613 0.281981 -0.740725 0.629207 -0.913866 0.650018 0.849206 0.598833 0.58149 -0.899064 -0.568768 0.708225 -0.863152 -0.996385 -0.242721 0.580024 0.456998 0.771642 0.979116 0.00734291 -0.587635 -0.373244 0.89297 0.155123 -0.847135 0.208819 -0.373328 -0.520159 -0.307904 -0.94411 0.340999 -0.825715 0.209158 -0.683808 -0.757388 0.581961 -0.975006 -0.925954 -0.503948 0.139718 0.241685 -0.00782965 0.407138 0.763263 0.155216 0.711784 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.00647233 -0.86041 -0.917681 0.532582 -0.901704 -0.935986 0.879509 -0.0983564 0.924749 0.254423 0.0890875 -0.650905 -0.577567 0.411221 0.0607412 -0.856197 -0.622692 0.202805 0.933749 0.346759 -0.410037 0.0325884 0.918991 -0.632101 0.417256 -0.604022 -0.130745 0.954731 0.649675 -0.0939968 0.953704 -0.427159 -0.292896 0.0982148 0.727267 0.0689716 -0.966434 0.131513 -0.719027 0.114917 0.575992 0.872889 -0.521954 -0.39546 -0.472771 0.477199 0.441492 0.424409 0.872071 -0.78715 0.342434 0.769289 -0.281602 0.98239 0.335861 -0.844265 0.433294 0.380426 -0.179489 -0.676919 -0.977227 -0.258439 0.408208 0.748369 -0.166102 0.320663 -0.617974 -0.290096 0.357929 -0.280733 -0.278234 -0.285224 0.240081 -0.958025 -0.98324 0.250765 -0.718508 0.933269 -0.118824 -0.909772 0.599013 -0.323754 -0.227596 0.813999 0.238999 0.918507 -0.318214 -0.605655 0.62822 -0.0244695 -0.651497 -0.253009 -0.323022 0.972358 0.41974 0.564115 -0.925445 0.0531064 0.558838 0.38797 0.617172 -0.141331 0.416375 0.950517 -0.404104 -0.165818 0.833476 -0.319598 0.655578 -0.968948 0.895924 -0.200276 -0.035571 0.157622 -0.841305 0.193022 0.112853 0.723603 -0.401455 0.742015 -0.948051 0.102226 0.105899 -0.148242 0.495953 -0.516381 -0.811975 -0.875359 -0.257198 0.549137 -0.707038 -0.167545 -0.213259 -0.379814 0.388758 -0.42722 0.996885 0.64195 -0.75194 0.15236 0.715338 0.689006 0.115588 0.681577 -0.728072 
Neuron:
learning rate: 0.5
Activation function: Relu
weights:
-0.707412 0.522029 -0.257312 -0.635982 -0.941086 -0.829112 -0.879213 -0.927203 0.493395 0.488364 -0.0664303 -0.494256 -0.964768 -0.854147 0.352213 -0.34965 -0.573825 -0.283328 0.111217 -0.777507 0.438637 0.177933 0.518782 -0.824386 0.545224 -0.413337 -0.948109 -0.874036 0.0822065 -0.356133 0.478497 0.0984244 0.219122 0.782541 0.16119 -0.881674 -0.295247 -0.213376 -0.208901 -0.993642 -0.132994 0.771119 0.194768 -0.53222 0.976312 0.884085 0.81463 -0.511448 0.0874478 -0.264853 0.623576 0.434666 -0.573687 0.0422153 -0.487339 -0.700859 0.656137 -0.299608 0.489326 0.106965 -0.235076 -0.920713 -0.431624 -0.299726 0.501835 0.348742 -0.695437 -0.204415 0.39397 -0.547176 -0.384363 0.0116226 -0.659106 0.404046 0.808396 0.70397 -0.372078 0.493298 0.865598 0.0993494 -0.235392 -0.235022 -0.00975541 0.040765 -0.862644 -0.457409 0.324108 -0.721985 -0.399266 -0.468445 0.837278 0.129953 0.119434 -0.671063 -0.553527 0.863773 -0.575557 0.611626 -0.402993 0.90368 0.147435 -0.0663139 -0.537539 -0.413128 0.566087 0.223596 -0.0160215 0.726104 -0.37656 -0.847731 0.192695 0.617709 -0.166661 0.922461 -0.192412 0.12601 -0.149189 0.575428 -0.789626 0.75193 -0.308794 0.107352 0.271814 0.385575 0.366881 0.171856 0.379623 0.33001 0.480752 -0.00562256 -0.498439 0.734667 -0.456125 -0.100142 0.915444 -0.135828 -0.867459 0.62291 -0.747259 0.811503 0.938129 -0.863324 0.108688 0.718671 0.704976 

Layer 2: 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.427798 -0.632874 -0.710151 0.486073 -0.573216 -0.0379842 -0.401081 -1.04197 0.150775 -0.886916 -0.466038 0.276135 0.768782 0.925616 0.746344 0.0255647 -0.347497 -0.240844 0.0973489 -0.344371 0.0893176 -0.981751 -0.371324 0.878416 -0.458956 0.30041 0.213396 0.549989 -0.378606 0.924146 0.118931 0.866973 -0.788521 -0.74277 -0.601994 0.281329 0.297239 -0.374279 -0.541237 0.508139 0.287055 0.538666 -0.648389 0.519796 0.129392 -0.635246 -0.58228 0.381045 0.821385 -0.984875 -0.83942 0.0058514 0.909711 -0.594083 0.747473 0.779407 -0.507098 -0.832341 0.662141 0.516026 0.490287 0.5798 0.699997 0.744031 -0.822172 -0.301513 -0.303351 -0.416885 -0.592776 -0.779021 0.980945 0.49228 -0.325138 0.766928 -0.317731 0.921664 0.403866 -0.225324 0.892564 -0.212603 0.859961 -0.725946 -0.612129 -0.128293 0.792508 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
-0.588469 0.902897 0.994063 -0.786881 0.888925 0.159956 0.374065 0.616975 0.540435 0.0974283 -0.774544 -0.74311 0.193165 0.530826 -0.598376 -0.625952 -0.398495 0.555482 -0.13249 0.634168 0.246296 0.479129 0.442556 0.921869 -0.14505 0.110026 -0.325318 0.375663 -0.315818 0.733861 -0.00634116 -0.575795 0.61844 0.00436344 0.444979 0.759824 0.368279 -0.5455 0.336258 0.852517 0.252818 -0.894774 -0.470877 -0.0367495 0.166966 0.741317 -0.685014 -0.885485 -0.258581 0.0236226 -1.14783 -0.741821 0.0465677 0.420994 -0.0887415 0.521993 -0.855857 -0.580722 -0.124917 0.252025 -0.0649394 -0.487855 0.615236 0.0371004 0.703044 -0.155971 -0.43665 -0.77945 -0.215527 -0.355519 0.70194 -0.694714 -0.298536 0.480608 -0.691635 0.217292 0.0264278 0.172118 0.537065 -0.513932 -0.0995617 0.448671 0.791291 -0.946836 -0.320316 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.248624 0.702648 -0.599138 0.28114 -0.872753 -0.365616 -0.910522 0.642337 0.245681 -0.690165 0.169479 -0.972765 -0.0130092 -0.645818 -0.37694 -0.0229299 0.582383 -0.0725232 -1.02196 0.310737 0.453428 -0.561309 -0.142894 0.999522 0.973808 0.746505 -0.437281 0.612908 -0.898042 -0.652273 -0.759356 -0.490819 0.79833 -0.599364 -0.652532 0.88912 -0.553329 0.0928842 0.317478 0.501329 -0.170152 0.263699 -0.01915 0.146473 -0.335373 -0.393252 0.60558 0.542351 -0.223557 0.676865 -0.0834938 0.0134004 0.34757 -0.604069 -0.141934 0.519965 -0.943498 0.491497 -0.527263 0.12532 -0.294493 -0.158479 0.447938 0.344321 0.717572 0.114035 -0.366128 0.483837 -0.147004 -0.698912 -0.713487 -0.470982 0.0434002 -0.86166 -0.055693 -0.212429 -0.29052 -0.76175 -0.911543 0.466322 -0.144835 -0.347726 0.997105 0.185347 0.30491 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.336421 -0.930058 0.509784 -0.0584219 0.102296 -0.708781 -0.487152 0.151567 0.961455 -0.148335 0.648753 0.541087 -0.0289108 0.0958496 0.768477 -0.0540089 0.232113 -0.244327 -0.521104 -0.131564 0.580351 0.164578 -0.235967 -0.217524 0.0795622 -0.848987 -0.21759 0.962442 -0.342543 0.18993 0.159911 -0.369346 0.393592 -1.04869 -0.161303 0.983216 0.910901 -0.701229 0.45775 0.579328 0.765248 -0.477763 0.233132 0.244464 0.504965 0.249974 -0.683027 -0.460149 -0.313443 -0.0308835 0.750094 -0.758481 -0.790739 -0.187074 0.432099 0.293063 -0.48652 -1.14558 -0.330725 -0.778012 -0.157637 0.813233 0.00110095 0.264528 0.293289 -0.929955 0.792554 0.456836 0.044011 -0.307732 -0.141385 -0.414312 0.399784 -0.32473 0.0205624 0.579472 -0.81595 0.327965 -0.164911 -0.404992 0.675393 -0.897793 0.832163 -0.0554895 -0.324848 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.309863 -0.673808 -0.697942 -0.3028 0.843885 -0.821897 0.375415 -0.368191 0.243415 -0.656534 -0.31776 -0.535822 -0.585831 -0.055611 -0.632867 0.940136 0.866591 -0.722238 -0.615386 -0.0267594 0.254199 -0.113108 1.0256 -0.147976 0.962947 0.251327 -0.00706881 -0.805436 -0.956818 0.135097 0.575833 0.0192994 0.364539 0.829546 0.804826 0.702829 0.439763 -0.906837 -0.862029 0.894108 -0.719907 0.521164 -0.800756 -0.309252 0.416903 -0.94056 0.00865765 -0.458761 -0.729221 -0.0181332 -0.747586 -0.759599 -0.302288 -0.518151 -0.973784 -0.388903 -0.298686 -0.0134228 0.714463 -0.0116247 -0.260663 -0.212043 0.196914 -0.441799 -0.369084 0.809139 -0.7264 -0.598131 -0.779622 0.885148 0.69542 0.262011 -0.375951 -0.871081 -0.238602 -0.383845 0.70974 0.597107 -0.398091 0.149973 0.752889 -0.205414 -0.778865 -0.3571 0.614646 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.200032 0.604871 0.0743317 -0.707081 0.0969867 0.0553164 -0.296822 -0.878274 -0.743736 0.317984 0.18073 0.0984966 -0.302866 -0.275865 -0.554889 0.899547 0.664411 -0.896295 -0.0849762 0.764893 -0.563576 -0.239799 -0.477118 0.169689 -0.0378815 -0.693443 0.90762 0.373514 -0.380754 0.228029 0.476598 0.176621 0.465733 -0.495427 0.935607 0.748731 -0.0764825 0.454519 0.267938 0.791052 -0.782313 -0.327443 0.667196 -0.437676 -0.107238 0.240147 0.150931 0.896798 -0.889561 -0.850369 -0.244676 -0.619447 -0.774227 -0.581037 -0.34021 0.0944788 -0.0954422 -0.247114 0.52185 0.555026 0.482054 -0.00807318 0.314009 -0.574857 0.61655 0.244165 -0.0452647 -0.763187 -0.875604 -0.283423 0.436995 0.15698 0.194867 -0.705617 0.560475 -0.682806 0.0828457 0.386843 -0.495801 0.243625 0.743809 -0.932871 -0.446268 -0.505847 0.862469 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
-0.513386 -0.919587 0.502054 0.0219544 0.986975 0.0862932 0.329587 -0.656284 -0.518399 -0.162293 0.325262 0.00569573 -0.297209 0.802015 -0.548232 0.106912 0.865358 -0.323782 0.180163 -0.325398 -0.972955 -0.424541 0.717652 -0.425129 0.855382 0.389348 0.804296 -0.192388 0.518578 0.747851 -0.862638 -0.364917 0.837688 -1.00105 -0.0720072 -0.225234 0.496942 0.0902366 0.93964 -0.746139 -0.352883 -0.908676 -0.112872 0.960086 0.155088 0.713283 0.144253 -0.425805 0.439626 0.793033 0.494693 0.0569427 0.263893 -0.770885 -0.478066 -0.847419 -0.563012 -0.543407 -0.152365 -0.813123 0.453219 0.297585 -0.492756 0.222943 0.145997 -0.250773 0.763291 0.629948 -0.469063 0.465398 -0.0656705 -0.322594 0.149911 0.730627 -0.372322 -0.359106 0.503326 -0.606235 -1.00657 0.777948 0.425436 0.286697 0.96654 0.608708 0.101779 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.567584 0.720224 0.799108 0.610682 -0.259984 0.454199 -0.284654 -0.219272 0.828239 0.817372 -0.501975 -0.232679 0.894706 -0.680976 0.836928 0.679655 0.964025 0.133713 -0.695253 0.420145 -0.655345 0.846324 0.10004 -0.348324 -0.287503 -0.0684134 -0.706932 0.586257 -0.774657 -0.956834 0.485647 0.27018 0.914706 -0.545023 -0.733262 0.0705668 0.0160039 0.952159 -0.538373 -0.809236 -0.821676 0.0914064 0.267786 0.67283 0.217222 -0.358294 0.145435 0.369524 -0.372583 -0.00339942 0.835771 -0.885087 0.248885 -1.02613 0.949607 0.0531717 -0.342512 -0.637986 0.98163 0.175024 -0.811779 0.00354766 -0.374516 -0.504995 -0.89546 0.00202597 -0.0893876 -0.33747 0.149281 0.963456 0.751141 0.411362 -0.295116 0.849005 -0.829964 -0.0967784 -0.555333 0.521831 0.364685 0.886745 -0.678345 -0.9488 0.343388 -0.691515 0.345741 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.380418 0.763515 0.388405 -0.0770626 0.809275 -0.507855 0.487828 0.341239 0.966078 0.842991 -0.305609 -0.181174 0.596438 0.337078 -1.01906 0.990074 0.166626 0.890386 0.552957 -0.998257 -0.0425177 0.367947 -0.417623 -0.529661 -0.00678455 -0.0511204 0.441175 0.825556 -0.892784 0.320636 0.934405 0.537649 0.267132 -0.405513 0.632389 0.563073 -0.429699 -0.321548 -0.790406 -0.572186 -0.733537 -0.563833 -0.348321 -0.224376 0.613191 0.00559637 0.0581597 0.43515 -0.832037 -0.0524786 -0.326426 -0.308951 0.701886 0.186472 -0.316976 0.582486 -0.162984 0.201634 -0.247476 0.116137 -0.127595 0.898425 -0.177682 -0.625124 -0.849597 0.529473 -0.713107 0.809556 0.204121 0.654709 -0.572025 -0.300302 0.25531 -0.402574 -0.57737 0.603335 0.248362 0.218111 -0.683718 -0.235023 -0.789473 -1.05923 0.327585 -0.391557 -0.749278 
Neuron:
learning rate: 0.5
Activation function: Sigmoid
weights:
0.755671 0.230695 -0.701895 -0.752212 -0.432531 0.459061 -0.554475 0.825962 -0.220032 -0.712362 -0.784505 -0.162075 0.246443 -0.0364389 -0.511796 -0.444695 0.00229802 -0.168425 -0.7755 0.342903 -0.928732 -0.291892 0.0502598 -0.774783 0.213741 0.315063 -0.404604 -0.173288 -0.508325 0.644435 -0.985456 -0.552075 -0.720444 -0.566502 0.934382 0.157867 -0.735576 -0.910078 0.15221 -0.49989 0.356826 -0.830919 0.751704 -0.109576 0.264425 -0.385646 0.452597 0.325741 -0.729474 -0.273706 -0.257695 0.208411 -0.394221 0.204282 0.406568 -0.804881 0.369246 -0.18418 -0.678319 -0.629403 -0.00392583 0.0429393 -0.319041 -0.223221 0.21019 0.559063 -0.599756 -0.0913972 -0.112589 -0.278492 -0.637794 -0.60959 0.517453 -0.425462 -0.848055 -0.109265 -0.418172 -0.221182 0.483964 -1.06728 -0.906794 -0.582 0.486735 0.452032 -0.0893433 

Ein = 0.901599
Eout = 1
